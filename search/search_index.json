{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>to the the tutorials website from the Remote Sensing Lab at FU-Berlin. If you re-distribute a tutorial, please acknowledge the original author of the tutorial.</p>"},{"location":"#related-links","title":"Related links","text":"<ul> <li>Staff</li> <li>Research profile</li> <li>Studium</li> <li>News</li> <li>Contact</li> <li>Research projects</li> </ul>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/","title":"Getting started with processing laserscanning data","text":""},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#overview","title":"Overview","text":"<p>In this lecture you will learn how to load, visualize and process airborne laserscanning data in R using the lidR package. The focus will be on established procedures to create standard products such as digital terrain models, canopy height models as well as grids with LiDAR point metrics. You will also get to know a comparably simple method to identify trees from a LiDAR point cloud of a forested area.  Most of the contents of this tutorial base on the official documentation of the lidR package which can be found here:</p> <p>https://r-lidar.github.io/lidRbook/</p> <p>Some of the contents are directly copy &amp; pasted while other parts are amended by information I deemed relevant. For anyone interested in this topic, I highly recommend to have a closer look at the link above and complete also the additional pratical parts provided there which are not covered in this tutorial.</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#learning-objectives","title":"Learning Objectives","text":"<p>Getting familiar with the lidR package and acquire skills to process airborne laserscanning data in R. After completing the tutorial you will be able to</p> <ul> <li>load and visualize LiDAR data saved as .laz or .las file</li> <li>filter the LiDAR point cloud data according to attributes</li> <li>classify a LiDAR point cloud into ground and other returns</li> <li>calculate digital elevation models (digital terrain model / canopy height model)</li> <li>create height-normalized point clouds</li> <li>extract tree tops from a point cloud</li> <li>calculate point clouds metrics</li> </ul>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#dataset-used-in-the-tutorial","title":"Dataset used in the tutorial","text":"<p>The dataset used in the tutorial originates from an airborne laserscanning survey conducted in Southern Germany in summer 2019. The dataset was collected in July 2019 under leaf-on conditions using a RIEGL VQ-780i airborne laser scanner mounted on a Cessna C207. Laser scanning was performed with a beam divergence of 25 mm/rad, a pulse repetition frequency of 1000 kHz and a scan frequency of 225 lines per second. The flight altitude was around 650 m above ground, the flight speed was approximately 51 m/s and the swath overlap was 76 percent. The resulting mean point spacing was 28 cm. Point densities in the study sites were between 136 and 164 pts/m\u00b2. Pulse densities were between 70 and 78 pulses/m\u00b2. The dataset is a small subset of the point cloud covering an area of approximately 130 x 130 m stored as .laz file. For this area, all trees with a DBH &gt; 5 cm were surveyed in the field and diameter at breast height, tree species as well as the location of the tree were recorded. The corresponding data is provided in a Point-Shapefile.</p> <p>The .laz file and the shapefile can be downloaded as a zip-archive at:</p> <p>https://drive.google.com/file/d/1BI_Sw0aLIcngmotZtKmEGkFEAiLu7G4N/view?usp=sharing</p> <p>Please download the file and copy it into a folder which you can find on your computer. E.g., D:/Studium/Projekt_1/ALS/</p> <p>Then unzip the data in this folder.</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#overview-of-the-lidr-package-and-acknowledgements","title":"Overview of the lidR package and acknowledgements","text":"<p>lidR is an R package for manipulating and visualizating airborne laser scanning (ALS) data with an emphasis on forestry applications. The package is entirely open source and is integrated within the geospatial R ecosytem (i.e. raster/terra/stars and sp/sf). This guide has been written to help both the ALS novice, as well as seasoned point cloud processing veterans.</p> <p>Development of the lidR package between 2015 and 2018 was made possible thanks to the financial support of the AWARE project NSERC CRDPJ 462973-14; grantee Prof. Nicholas C. Coops. Development of the lidR package between 2018 and 2020 was made possible thanks to the financial support of the Minist\u00e8re des For\u00eats, de la Faune et des Parcs of Qu\u00e9bec.</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#getting-started","title":"Getting started","text":""},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#1-loading-point-cloud-data-to-r","title":"1. Loading point cloud data to R","text":"<p>Discrete return ALS sensors record a number of pieces of data. First and foremost, positional data in three dimensions (X,Y,Z) - this is normally referred to as the \"point cloud\". The most simple point clouds only include information about X,Y,Z position and nothing else. However, most laserscanning sensors record more information such as the intensity for each point, the position of each point in the return sequence (remember the \"multi-return\" capabilities of a single laser-beam discussed in the theoretical lecture), or the beam incidence angle of each point. Due to the often massive amounts of data that are collected during a laserscanning survey, reading, writing, and efficient storage of laserscanning data is a critical step prior to any subsequent analysis.</p> <p>ALS data is most commonly distributed in LAS format, which is specifically designed to store ALS data in a standardized way. These data are officially documented and maintained by the American Society for Photogrammetry &amp; Remote Sensing (ASPRS). LAS files do however require a large amount of memory because they are not compressed. The LAZ format has become the standard compression scheme, because it is free and open-source.</p> <p>The widespread use, standardization and open source nature of the LAS and LAZ formats promoted the development of the lidR package, which has been designed to process LAS and LAZ files both as input and output, taking advantage of the LASlib and LASzip C++ libraries via the rlas package.</p> <p>The function readLAS() reads a LAS or LAZ file and returns an object of class LAS. The LAS formal class is documented in depth in a dedicated vignette. To briefly summarize, a LAS file is made of two parts:</p> <ul> <li>The header that stores summary information about its content including the bounding box of the file, coordinate reference system, and point format.</li> <li>The payload, that is the point cloud itself.</li> </ul> <p>The function readLAS() reads and creates an object that contains both the header and the payload. We will now start the practical part by running the following code in R. Make sure that you also carefully read the comments provided in the code. We will now first load all the required packages. R will give you a warning message in case a package is not installed yet. If this is the case, please install the packages either through the main menu of Rstudio by selecting \"Tools\" =&gt; \"Install packages\" and then following the appearing dialogue, or by entering the corresponding R code to install the packages into the console. E.g., to install the package \"raster\" use the code:</p> <pre><code>install.packages(\"raster\")\n</code></pre> <p>But now let's load the packages and the dataset</p> <pre><code>############################\n## Loading LiDAR data to R\n############################\n\n\n# installing the lidR package (only required one time)\n# if the package is not installed yet\n\n\n# loading the lidR package\nrequire(lidR)\nrequire(stars)\nrequire(terra)\nrequire(sp)\nrequire(sf)\nrequire(ggplot2)\nrequire(gstat)\n\n# load the example dataset - a subset from an airborne\n# laserscanning survey conducted in 2020 in study site\n# near Karlsruhe in the South of Germany\n\n# load complete dataset (the path has to be adapted)\nlas &lt;- readLAS(\"D:/Studium/Projekt_1/ALS/BR01.laz\")\n</code></pre> <p>With these lines of code, you should have now loaded the ALS data. To make sure that the data is loaded correctly we can run:</p> <pre><code># check summary of loaded dataset\nsummary(las)\n</code></pre> <p>This should give us the following outputs:</p> <p></p> <p>We can see quite a lot of information is being displayed, but we will not go into every detail. A few points that are quite interesting is that we can see for example the total number of points is 1.74 million and based on the coordinates provided in the extent attribute we can see that the area covers roughly 130 x 130 m. We can also see that the file currently has no coordinate reference system assigned. </p> <p>By simply using the readLAS() command, we loaded the complete dataset into R - this is a quite good choice in many situations, but as we can see at the memory attribute, we also loaded a quite large dataset of 205.5 MB (hence the original file size of the compressed laz-file was increased by a factor of almost 10 since the original laz-file has a size of approximately 23 MB). </p> <p>In some cases, we might be interested in not loading the complete dataset but for example only the positional data while we might not be interested in loading information about intensity of scan-angle. Or we might only be interested in a specific type of returns, for example we might be interested in only using \"first return\" data (that is all 3D points that were recorded when the laser beam interacted with an object for the first time while we want to disregard any returns that followed) In such cases, the lidR package provides some options to read only parts of the dataset as exemplified in the code below:</p> <pre><code># It is also possible to only load specific subsets of the data\n# by either using the \"select\" argument to only load certain columns\n# of the dataset (columns are attributes - such as x, y, z position,\n# scan angle, return number, etc.)\n# or by using the filter argument to only load certain rows (data points) of the\n# dataset - for the latter the options are listed here\nreadLAS(filter = \"-help\")\n# load only 3D points and discard other information\nlas_xyz &lt;- readLAS(\"D:/00_FUB/3_lehre/2_Projekt_1/1_tree_attributes/Practicals/2_LiDAR/BR01.laz\", select=\"xyz\")\n# load complete dataset but only first returns\nlas_fr &lt;- readLAS(\"D:/00_FUB/3_lehre/2_Projekt_1/1_tree_attributes/Practicals/2_LiDAR/BR01.laz\", \"-keep_first\")\n</code></pre> <p>MINI-EXERCISE: Try to tun the lines above and check how the size of the loaded datasets has changed (memory attribute) using the summary command learned already above.</p> <p>As stated above, a typical lidar dataset does not only contain information about the point locations but also additional information. In the datasets we loaded so far, we can check what kind of additional data is stored by running:</p> <pre><code>names(las@data)\n</code></pre> <p>This will result in the following output:</p> <p></p> <p>So we can see that each of the LiDAR point does not only have a X, Y and Z coordinate but many additional attributes that can be used during the analysis. Even though many of these attributes are not typically being used to extract information of the targeted variable (e.g., forest parameters). The only exceptions are Intensity and ReturnNumber which both normally carry some relevant information about the object with which the laser beam interacted. </p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#2-visualizing-lidar-data-with-lidr","title":"2. Visualizing LiDAR data with lidR","text":"<p>The lidR package takes advantage of the rgl package to provide a versatile and interactive 3D viewer with points coloured by Z coordinates on a black background as default. The very basic way to render a point cloud is the function plot().</p> <pre><code>plot(las)\n</code></pre> <p>This will lead to the following plot:</p> <p></p> <p>Be aware that the plot is actually interactive and in 3D. That is, by clicking and keeping the mouse-button clicked and then moving the mouse, you can rotate and shift the plot. Using the mouse-wheel you can zoom in and out. Try to play around a bit with this until you get familiar with the navigation in the plot.</p> <p>As is most R-plots, it is possible to refine and adapt the plot with numerous settings. Here is code for two examples. In the first example, the color of the points (which was determined by the height of the points in the first plot) will be set based on ScanAngle and in the second based on Intensity of the LiDAR returns. In both cases, the background will be set to white.</p> <pre><code># Plot las object by scan angle, \n# make the background white, \n# display XYZ axis and  scale colors\nplot(las, color = \"ScanAngle\", bg = \"white\", axis = TRUE, legend = TRUE)\n# use LiDAR intensity as color, use the break argument to improve color scale\nplot(las, color = \"Intensity\", breaks = \"quantile\", bg = \"white\")\n</code></pre> <p>This will result in the following two plots:</p> <p> </p> <p>As you can see, the x and y dimensions are not showing the actual coordinates of the area but start from the origin 0, 0. However, the heights (z axis) actually show their true values. In the current plots these are values above sea level. While these plots are quite nice, there are many cases where a transect view of the point cloud may be more efficient to visually examine the details of a LiDAR point cloud, particularly if the dataset shows a forest. In the lidR package it is also possible to depict transect views, but there are several steps necessary to achieve this. </p> <p>First, we have to clip the point-cloud to remain only a small strip (= the transect). There is a dedicated function to do this and we have to define the start point and the end point of the transect as well as a width (in meter). We can do this with the following code:</p> <pre><code># make transect plot\n# have a look at y and y coordinates to define start and end point\n# point coordinates have to lay between min and max of X and Y variables\nsummary(las$X)\nsummary(las$Y)\n\n# define some start and end point\np1 &lt;- c(476715, 5429035)\np2 &lt;- c(476758, 5429075)\n\n# clip transect\nlas_tr &lt;- clip_transect(las, p1, p2, width = 2, xz = TRUE)\n</code></pre> <p>Now we clipped out a small transect of our plot and we can visualize it using the ggplot function. You might already be familiar with ggplot from other courses in which you used R. It is probably the most famous R-package for preparing more advanced plots and there is ample literature on the package on the internet. I will hence not go into the details of the parameters here, but you can play around a bit for example with the parameter used for coloring the points (argument \"color = Z\") as well as the point size (argument \"size = 0.5\").</p> <pre><code># plot transect\nggplot(las_tr@data, aes(X,Z, color = Z)) + \n  geom_point(size = 0.5) + \n  coord_equal() + \n  theme_minimal() +\n  scale_color_gradientn(colours = height.colors(50))\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>Since creating a transect plot requires several steps and we might be interested in plotting transects a bit more frequently later on, we can define a custom function that allows us to plot a transect view of our dataset. I will not go into details to explain what the function does exactly here, but we will use it a few times in the parts below. Hence, simple run the complete code below in R and the function will become available in the next parts of the tutorial.</p> <pre><code># prepare function to make transect plotting more easy\nplot_crossection &lt;- function(las,\n                             p1 = c(min(las@data$X), mean(las@data$Y)),\n                             p2 = c(max(las@data$X), mean(las@data$Y)),\n                             width = 4, colour_by = NULL)\n{\n  colour_by &lt;- enquo(colour_by)\n  data_clip &lt;- clip_transect(las, p1, p2, width)\n  p &lt;- ggplot(data_clip@data, aes(X,Z)) + geom_point(size = 0.5) + coord_equal() + theme_minimal()\n\n  if (!is.null(colour_by))\n    p &lt;- p + aes(color = !!colour_by) + labs(color = \"\")\n\n  return(p)\n}\n</code></pre>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#ground-classification","title":"Ground classification","text":"<p>Classification of ground points is an important step in processing point cloud data. Distinguishing between ground and non-ground points allows creation of a continuous model of terrain elevation often referred to as \"digital terrain model\" (DTM). DTMs are useful for many applications such as calculating the run-off in hydrological models, determining suitable positions for wind turbines or deriving aspect and slope information. Many algorithms to classify ground points have been reported in the literature and lidR currently provides two of them: Progressive Morphological Filter (PMF) and Cloth Simulation Function (CSF) usable with the function classify_ground(). The lidRplugins package provides an additional algorithm called Multiscale Curvature Classification (MCC).</p> <p>The implementation of PMF algorithm in lidR is based on the method described in Zhang et al. (2003) with some technical modifications. The original method is raster-based, while lidR performs point-based morphological operations because lidR is a point cloud oriented software. The main step of the methods are summarised in the  following figure (taken from the lidR book).</p> <p></p> <p>The pmf() function requires defining the following input parameters: ws (window size or sequence of window sizes), and th (threshold size or sequence of threshold heights). More experienced users may experiment with these parameters to achieve best classification accuracy, however the lidR also contains the util_makeZhangParam() function that includes the default parameter values described in Zhang et al. (2003).</p> <p>To conduct a ground classification on our dataset, we run the following lines of code:</p> <pre><code>las &lt;- classify_ground(las, algorithm = pmf(ws = 5, th = 3))\nplot(las, color = \"Classification\", size = 3, bg = \"white\")\n</code></pre> <p>This will take a moment of processing time and then we can have a look at the classification be using the plot_crossection function that we defined above:</p> <pre><code># have a look at the classification in a transect view\n# define start and end point\np1 &lt;- c(476715, 5429035)\np2 &lt;- c(476758, 5429075)\nplot_crossection(las, p1 , p2, colour_by = factor(Classification))\n</code></pre> <p>This results in the following plot</p> <p></p> <p>We can see that the result is not yet perfect as some points that were classified as ground appear to be rather part of the understorey of the forest (some example points are marked in the black box). In the following we will address this issue be refining the PMF algorithm by using not only a single window size but three different window sizes and providing a sequence of threshold heights. In the given case, the provided settings will lead to a quite decent result, but you can try out other parameters as well. The optimal set of parameters may vary depending on your dataset. For example areas with very rough terrain may require other settings than rather flat areas.</p> <pre><code># adjust ground classification algorithm\nws &lt;- seq(3, 12, 3)\nth &lt;- seq(0.1, 1.5, length.out = length(ws))\nlas &lt;- classify_ground(las, algorithm = pmf(ws = ws, th = th))\nplot_crossection(las, p1 , p2, colour_by = factor(Classification))\n</code></pre> <p>Running this code will take a bit more time since multiple window sizes and thresholds are applied. Finally, this should result in the following plot:</p> <p></p> <p>This results looks quite nice and almost all of the points that were classified as ground (green color) look plausible. The classification is stored as an additional attribute in the las-file and we can use the attribute to filter the file and obtain only points that were classified as ground point. The following code does exactly this and then plots the ground points:</p> <pre><code># filter ground points and plot them\ngnd &lt;- filter_ground(las)\nplot(gnd, size = 3, bg = \"white\")\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>In this tutorial we only get to know one of the methods that is available in lidR to classify ground control points. If you at some point work with an own dataset and face problems in obtaining a high-quality ground classification, it might be worthwhile to examine the alternative methods of the package which are described with more details in the lidR book (see link at the beginning of this tutorial). </p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#calculate-a-digital-terrain-model","title":"Calculate a digital terrain model","text":"<p>Generating a Digital Terrain Model (DTM) is usually the next step in processing that follows classification of ground points. Put simply, a DTM can be described as an \u201cimage\u201d of the ground. Methods to generate DTMs have been intensively studied and several algorithms have been proposed for various terrain situations. DTMs are used for a variety of purposes in practice, such as determination of the catchment basins of water retention and stream flow, or the identification of drivable roads to access resources. It also enables users to normalize point clouds i.e. subtract the local terrain from the elevation of points to allow a manipulation of point clouds as if they were acquired on a flat surface.</p> <p>The construction of a DTM starts with known or sampled ground points and uses various spatial interpolation techniques to infer ground points at unsampled locations. The accuracy of the DTM is very important because errors will propagate to future processing stages like tree height estimation. A wide range of methods exist for spatial interpolation of points.</p> <p>Below you will find the codes to run three interpolation methods and some information about each of the method.</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#triangular-irregular-network","title":"Triangular irregular network","text":"<p>This method is based on triangular irregular network (TIN) of ground point data to derive a bivariate function for each triangle, which is then used to estimate the values at unsampled locations (between known ground points).</p> <p>Planar facets of each generated triangle are used to interpolate. Used with a Delaunay triangulation, this is the most simple solution because it involves no parameters. The Delaunay triangulation is unique and the linear interpolation is parameter-free. The drawbacks of the method are that it creates a non-smooth DTM and that it cannot extrapolate the terrain outside the convex hull delimited by the ground points since there are no triangle facets outside the convex hull. Moreover, the interpolation is weak at the edges because large irrelevant triangles are often created. It\u2019s therefore important to compute the triangulation with a buffer to be able to crop the DTM and clear the edge artifacts.</p> <p>To run the interpolation with TIN execute the following code:</p> <pre><code># calculate a digital terrain model from the classified\n# ground points. Three methods are available:\n\n# tin\ndtm_tin &lt;- rasterize_terrain(gnd, res = 0.5, algorithm = tin())\nplot_dtm3d(dtm_tin, bg = \"white\")\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>As you can see there are not many details visible. This is actually a good sign as we would normally assume that a digital terrain model in a forest is rather \"smooth\" surface since all LiDAR points related to object on the ground are \"eliminated\" during the ground-classification procedure. The only thing we can see in the figure is that a road is separating the study area into more or less two equally sized parts. The road becomes clearly visible since it is a flat area which interrupts the slightly inclined terrain. Let's have a look at the two other methods to interpolate the ground points.</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#invert-distance-weighting","title":"Invert distance weighting","text":"<p>Invert distance weighting (IDW) is one of the simplest and most readily available methods that can be applied to create DTMs. It is based on an assumption that the value at an unsampled point can be approximated as a weighted average of values at points within a certain cut-off distance d, or from a given number k of closest neighbours. Weights are usually inversely proportional to a power p of the distance between the location and the neighbour, which leads to the computing of an estimator.</p> <p>Compared to tin() this method is more robust to edge artifacts because it uses a more relevant neighbourhood but generates terrains that are \u201cbumpy\u201d and probably not as realistic as those generated using TINs. There are always trade-offs to different methods!</p> <p>To create a digital terrain model using the invert distance weighting method run:</p> <pre><code># invert distance weighting\ndtm_idw &lt;- rasterize_terrain(gnd, algorithm = knnidw(k = 10L, p = 2))\nplot_dtm3d(dtm_idw, bg = \"white\")\n</code></pre> <p>This will result in the following plot:</p> <p></p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#kriging","title":"Kriging","text":"<p>Kriging is the most advanced approach and utilizes advanced geostatistical interpolation methods that take into account the relationships between the returns and their respective distances from each other. lidR uses the package gstat to perform the kriging. This method is very advanced, difficult to manipulate, and extremely slow to compute, but probably provides the best results with minimal edge artifacts.</p> <p>To create a digital terrain model using the kriging method run:</p> <pre><code># kriging\ndtm_kriging &lt;- rasterize_terrain(gnd, algorithm = kriging(k = 40))\nplot_dtm3d(dtm_kriging, bg = \"white\")\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>If we are interested in obtaining a 2D-hillshade image of our terrain model, we can run the following code.</p> <pre><code># create hillshade image from digital terrain model\ndtm_prod &lt;- terrain(dtm_kriging, v = c(\"slope\", \"aspect\"), unit = \"radians\")\ndtm_hillshade &lt;- shade(slope = dtm_prod$slope, aspect = dtm_prod$aspect)\nplot(dtm_hillshade, col =gray(0:30/30), legend = FALSE)\n</code></pre> <p>This will lead to the following plot:</p> <p></p> <p>In our example dataset this is not very spectacular since we do not have a pronounced terrain situation and the area is comparably small. If data from a larger area for example covering a mountain chain is used, this option may become more interesting (at least for producing nice visualizations).</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#normalize-the-lidar-point-cloud","title":"Normalize the LiDAR point cloud","text":"<p>In many application fields, we might be interested in extracting the height of objects from a LiDAR point cloud. And with height I am referring to the height of objects above the ground and not above sea level. For example, we might want to know how high certain buildings or trees are. With LiDAR data this information can be easily obtained for large areas and with a very good precision of a few centimeters. To convert a standard LiDAR point cloud to a normalized point cloud in which the Z value of each LiDAR point indicates the height of the point above ground, we can simply subtract the digital terrain model from the LiDAR point cloud.</p> <p>To accomplish this in lidR - there are two different approaches. One approach requires a DTM. For example we can use the DTM calculated with the kriging approach:</p> <pre><code># create a normalized height point cloud\n# by subtracting the digital terrain model from the\n# lidar point cloud\nnlas &lt;- las - dtm_kriging\n</code></pre> <p>We can then plot the resulting point cloud and compare it with the original point cloud by plotting</p> <pre><code># plot the result\nplot(nlas, size = 4, bg = \"white\")\n# and compare it to the original point cloud\nplot(las, size = 4, bg = \"white\")\n</code></pre> <p>This will result in two individual plots, which were merged into one in the following plot:</p> <p></p> <p>We can clearly see the difference. While in the original point cloud, the height differences between the trees are less clear due to slope which also exists in the plot, the height differences become clearly visible in the normalized point cloud which all stand on a \"flat\" ground.</p> <p>One consequence of the normalization of the point cloud should be that all LiDAR points classified as ground points should have a Z-value 0 m. With the following plot we can have a look whether this is true:</p> <pre><code># this should lead to a situation where all ground points\n# have a value of 0.0 m. We can check this with the following \n# command. Be aware that this a nested function. That is, the\n# hist() command is used to create a histogram and the filter_ground()\n# command is used to only show values for point classified as\n# ground in the codeparts before and the $Z is used to only\n# show height values. The breaks command decides how fine the\n# individual bars of the histogram are - this could also be left\n# out. The dev.off() command is used to close any plot that is still\n# open.\ndev.off()\nhist(filter_ground(nlas)$Z, breaks = seq(-0.6, 0.6, 0.01), main = \"\", xlab = \"Elevation\")\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>We can see that the assumption is more or less true but we can also see that the ground points are not all exactly at 0 m but they fluctuate between roughly -0.5 and 0.5 m. This is related to the fact that we used an interpolated DTM with a given grid size. Within a single grid cell of the DTM, the height value is exactly the same in each location of the grid cell. Hence, some ground points may lay below or above this value.</p> <p>If we want all ground points to have a value of zero, lidR offers a function to normalize the point cloud using the ground points without a grid-based interpolation. There are still some interpolation going on for the non-ground points but all ground-points will have a value of zero. This method can be executed with the following command:</p> <pre><code># create a normalized height point cloud\n# by subtracting the height of the lowest point nearby\n# this is similar to the just described step, but it assumes \n# a continuous DTM without a pixel size\nnlas &lt;- normalize_height(las, knnidw())\n# the histogram plot now shows that all ground points are at zero.\nhist(filter_ground(nlas)$Z, breaks = seq(-0.6, 0.6, 0.01), main = \"\", xlab = \"Elevation\")\n</code></pre> <p>And the corresponding plot confirms that now all ground plots have indeed a Z-value of 0.</p> <p> </p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#calculate-digital-surface-models-and-canopy-height-models","title":"Calculate digital surface models and canopy height models","text":"<p>Digital Surface Models (DSM) and Canopy Height Models (CHM) are raster layers that represent - more or less - the highest elevation of ALS returns. In the case of a normalized point cloud, the derived surface represents the canopy height (for vegetated areas) and is referred to as CHM. When the original (non-normalized) point cloud with absolute elevations is used, the derived layer represents the elevation of the top of the canopy above sea level, and is referred to as DSM. Both surface models are derived using the same algorithms, with the only difference being the elevation values of the point cloud.</p> <p>Different methods exist to create DSMs and CHMs. In the most simple case, a grid can be created with a user-defined pixel size and the elevations of the highest point can be assigned to each grid cell. This is called point-to-raster. </p> <p>Point-to-raster algorithms are conceptually simple, consisting of establishing a grid at a user defined resolution and attributing the elevation of the highest point to each pixel. Algorithmic implementations are computationally simple and extremely fast. In the first example we will set the pixel size to 1 and the corresponding algorithm = p2r():</p> <pre><code># point-to-raster method\nchm &lt;- rasterize_canopy(las, res = 0.5, algorithm = p2r())\ncol &lt;- height.colors(25)\nplot(chm, col = col)\n</code></pre> <p>This will result in the following plot:</p> <p> </p> <p>As we can see the depicted height values are still showing altitudes above sea level. Hence, while we do see height differences of more than 60 m in the study area, not all of these height differences are related to the height of trees. So this would be an example of a \"digital elevation model\" (DSM) which is a raster which shows the height above sea level of the ground + the objects on the ground at each spatial location. If we are interested in only seeing the height of objects we need a \"normalized digital elevation model\" (nDSM) or in the case of forests a so called \"canopy height model\" (CHM). This created by either subtracting the a DTM from a DSM of the same area. Or by directly applying the same algorithm as used for calculating the DSM but this time to the already normalized point cloud:</p> <pre><code># point-to-raster method\nchm &lt;- rasterize_canopy(nlas, res = 0.5, algorithm = p2r())\ncol &lt;- height.colors(25)\nplot(chm, col = col)\n</code></pre> <p>This will result in the following plot:</p> <p> </p> <p>In some cases, the point-to-raster method has some drawbacks. For example if you have a LiDAR dataset with comparably few number of returns, you might end up with data caps in your elevation model. One alternative approach to calculate the DSMs and nDSMs is the TIN approach we already used to calculate DTMs.</p> <p>The triangulation algorithm works by first creating a triangular irregular network (TIN) using first returns only, followed by interpolation within each triangle to compute an elevation value for each pixel of a raster. In its simplest form, this method consists of a strict 2-D triangulation of first returns. Despite being more complex compared to the point-to-raster algorithm, an advantage of the triangulation approach is that it is parameter free and it does not output empty pixels, regardless of the resolution of the output raster (i.e. the entire area is interpolated).</p> <p>Like point-to-raster however, the TIN method can lead to gaps and other noise in the surface - referred to as \u201cpits\u201d - that are attributable to first returns that penetrated deep into the canopy. Pits can make individual tree segmentation more difficult and change the texture of the canopy in a unrealistic way. To avoid this issue the CHM is often smoothed in post processing in an attempt to produce a more realistic surface with fewer pits and less noise. To create a surface model using triangulation we use algorithm = dsmtin().</p> <pre><code># tin method\nchm &lt;- rasterize_canopy(las, res = 0.5, algorithm = dsmtin())\nplot(chm, col = col)\n</code></pre> <p>This results in the following plot:</p> <p> </p> <p>In our dataset, the differences are quite little. </p> <p>We are now coming towards the end of this tutorial and so far you have learned the most important basic processing steps for LiDAR / laserscanning data. To finish the tutorial we will have a brief look at two additional steps that are the starting points of most LiDAR-analyses conducted in vegetation and forest analyses. </p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#individual-tree-detection","title":"Individual tree detection","text":"<p>Typically LiDAR analyses in forests either work on an individual tree level or in the so called area-based approach. In the latter, the basic unit of the analysis is a cell of a user-defined fixed size (e.g., 20 x 20 m). In the individual tree-based approach, the basic unit of the analysis is a single tree. Automatically delineating trees from a LiDAR point cloud is an own field of research and we will not go into details in this tutorial. However, the lidR package offers one standard algorithm to identify tree tops from a LiDAR point cloud which will be briefly explained below.</p> <p>Tree tops can be detected by applying a Local Maximum Filter (LMF) on the loaded data set. The LMF in lidR is point cloud-based, meaning that it finds the tree tops from the point cloud without using any raster. The processing, however is actually very similar. For a given point, the algorithm analyzes neighbourhood points, checking if the processed point is the highest. This algorithm can be applied with the  Local Maximum Filter - lmf() function.</p> <p>The LMF can be applied with a constant size windows. In the code below with a windows size of ws = 5 meters meaning that for a given point the algorithm looks to the neigbourhood points within a 2.5 radius circle to figure out if the point is the local highest. While the algorithm does not need any CHM to work we chose to display the results on top of a CHM for better visualization.</p> <pre><code># detect tree tops with fixed window size of 5\nttops &lt;- locate_trees(nlas, lmf(ws = 5))\n\n# have a look at results\nchm &lt;- rasterize_canopy(nlas, res = 0.5, algorithm = p2r())\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n</code></pre> <p>This will take some time for processing and then result in the following plot:</p> <p> </p> <p>We can also have a loot at the result in 3D:</p> <pre><code># have a look at results in 3d\nx &lt;- plot(nlas, bg = \"white\", size = 4)\nadd_treetops3d(x, ttops)\n</code></pre> <p> </p> <p>If we are not happy with the results of this comparably simple approach, we can refine the algorithm by adjusting the search window depending on the height of the canopy assuming the trees which are less tall, also have smaller crowns. This can be accomplished by providing the algorithms with a function that describes the relation between the height of the trees and the window size and a sequence of heights for which different window sizes will be used:</p> <pre><code># adapt window size with height\nf &lt;- function(x) {x * 0.1 + 3}\nheights &lt;- seq(0,40,10)\nws &lt;- f(heights)\nplot(heights, ws, type = \"l\", ylim = c(0,6))\n</code></pre> <p>This will result in slightly different results:</p> <pre><code>ttops &lt;- locate_trees(nlas, lmf(f))\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n</code></pre> <p> </p> <p>Identifying the optimal parameter is not an easy task and may require some sort of reference data which can for example be obtained by visually interpreting a CHM or by identifying tree stem positions in the field. Even though the latter is often also prone to errors since identifying the exact position of a tree in the field is not a trivial task and on top of this, the stem position on the ground may not directly related to the top of the crown since many trees do not grow exactly vertically.</p> <p>The detection of tree tops is normally only the first step for the individual tree delineation/segmentation since it does not yet allow us to identify the tree crown area. lidR provides function for this task as well, but we will not demonstrate this here with our example dataset. Amongst others because our dataset is missing a coordinate reference system (which first would have to be assigned) and the functions will not immediately work. However, feel free to also try out these functions by using the example datasets delivered with lidR. The corresponding data and instruction can be found in the lidR-book (see link at the beginning of the tutorial).</p>"},{"location":"1_Laserscanning_lidR/1_Laserscanning_lidR/#calculate-point-cloud-metrics","title":"Calculate point cloud metrics","text":"<p>As very last step, we will get to know two important functions of the lidR package to calculate point cloud metrics. Point cloud metrics are an essential element of the area-based approach briefly mentioned above. The idea is that a regular grid of quadratic or hexagon-shaped polygons is overlayed with the point cloud. Then, in each grid-cell/polygon some metrics are calculated for the points located within the grid-cell/polygon. </p> <p>The standard deviation of point heights within a single tree crown is an example of a metric calculated at the tree level. The average distance between a point and its k-nearest neighbours is a metrics calculated at the point level. More complex metrics can even be imagined like the average distance between first and last returns within a pixel or within a tree. In the end, regardless of the scale at which metrics are calculated, they serve as proxies of forest inventory attributes or can be used as independent variables in predictive models.</p> <p>The standard metrics of the lidR package already include quite a lot of common and often used variables and can be obtained using the following code for either quadratic grid-cells:</p> <pre><code>a &lt;- pixel_metrics(nlas, func = .stdmetrics, res = 2.5)\n</code></pre> <p>or a hexagon-grid:</p> <pre><code>b &lt;- hexagon_metrics(nlas, func = .stdmetrics, area = 20)\n</code></pre> <p>The names of the obtained metrics can be obtained by running:</p> <pre><code>a@ptr$names\n</code></pre> <p>This will result in the following output:</p> <p> </p> <p>If we want to see how a 2D representation of one of the metrics looks like in either dataset we can pick out one of the variable names and run:</p> <pre><code>plot(a[\"zq80\"], pal = heat.colors, axes = TRUE, key.pos = NULL, reset = FALSE)\n</code></pre> <p>This will result in:</p> <p> </p> <p>or:</p> <pre><code>plot(b[\"zq80\"], pal = heat.colors, axes = TRUE, key.pos = NULL, reset = FALSE)\n</code></pre> <p>This will result in:</p> <p> </p> <p>These metrics can then be related for example to forest attributes inventoried in the field and regression models can be trained to first relate the field measured data to the metrics and then predict the trained model to the complete area how which laserscanning data has been collected.</p> <p>This was the final step of this Tutorial and you are now all set for working with the point clouds which we will collect during the field week of this course.</p>"},{"location":"BFAST/BFAST/","title":"Analysing time series with BFAST and NPPHEN","text":""},{"location":"BFAST/BFAST/#overview","title":"Overview","text":"<p>In our last practical session for the topic of remote sensing-based time-series analysis, we will have a  look at two quite complex algorithms to analyse time series with a comparably high temporal resolution (typically monthly or less). The algorithms are BFAST and NPPHEN - both have already been introduced briefly during the theoretical lectures of the time-series chapter of the course.</p> <p>You will see that the algorithms are quite time-intensive and we will hence focus on comparably small datasets to keep the processing time manageable. On ILIAS, I will provide some papers that describe the algorithms with more details. In this tutorial I will mostly focus on how to get the algorithms running.</p>"},{"location":"BFAST/BFAST/#learning-objectives","title":"Learning objectives","text":"<p>The learning objectives of this Tutorial include:</p> <ul> <li>preparing a remote-sensing based time series for use with BFAST and NPPHEN</li> <li>applying BFAST and NPPHEN</li> <li>understanding the most important outputs of both algorithms</li> </ul>"},{"location":"BFAST/BFAST/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>We will use the MODIS time series of Xining, we prepared during the first practical session of the time-series chapter of the course. In case you do not have the dataset available anymore, you can download the files here:</p> <p>https://drive.google.com/drive/folders/1eGbvYMEQXicggUmC9I7vMiPbI6DE9HdP?usp=sharing</p>"},{"location":"BFAST/BFAST/#step-1-preparing-remote-sensing-time-series-for-analysis-with-bfast","title":"Step 1: Preparing remote sensing time series for analysis with BFAST","text":"<p>One of the most challenging steps for analysing data with the BFAST algorithm is that the time series have to be pre-processed into regular time series. In the case of remote sensing data, most of the time, the observations are not regular. Even though the satellite typically passes over a certain area at a fixed time interval, cloud cover prevents that the satellite collects a valid observation during every overflight. Hence, remote sensing time series often have data gaps and hence an irregular structure. In the case of Landsat data, we furthermore have data from several sensors, so that the time structure is at least for some periods even less regular.</p> <p>In this first step of the tutorial, we will learn how to transform an irregular time series to a regular time series. We will first load the irregular time series from our MODIS dataset, then we will transform this time series to a daily time-series and finally aggregate it again to a weekly time series. To do this, we require several packages and an additional function which was suggested by my colleague Philipp G\u00c3\u00a4rtner. You can find some related information here:</p> <p>https://philippgaertner.github.io/2018/04/bfast-preparation/#</p> <p>So let's have a look at the packages we will use during this tutorial:</p> <pre><code>require(raster)\nrequire(lubridate)\nrequire(zoo)\nrequire(bfast)\nrequire(xts)\n</code></pre> <p>The bfastSpatial package is not on the official CRAN list of R, so we will have to install the package manually using:</p> <pre><code>library(devtools)\ninstall_github('loicdtx/bfastSpatial')\n# load the package\nlibrary(bfastSpatial)\n</code></pre> <p>you can find more information about this package here:</p> <p>http://www.loicdutrieux.net/bfastSpatial/</p> <p>I hope the installation of bfastSPatial will work smoothly - I experienced some troubles with this earlier but this time I had no issues. Besides the packages, we will need a custom function which I copied from the link of Philipp's webpage above. We should run this code to make the function available:</p> <pre><code>aggregate.daily.to.weekly &lt;- function(daily.ts) {\n\n  dates      &lt;- as.Date(date_decimal(as.numeric(time(daily.ts))))\n  xts.daily  &lt;- xts(daily.ts, order.by = dates)\n  xts.weekly &lt;- round(xts::apply.weekly(xts.daily, median),0)  # xts\n\n  start(xts.weekly)\n  ts.weekly &lt;- ts(data = xts.weekly, \n                  # define the start and end (Year, Week)    \n                  start = c(as.numeric(format(start(xts.weekly), \"%Y\")),\n                            as.numeric(format(start(xts.weekly), \"%W\"))), \n                  end   = c(as.numeric(format(end(xts.weekly), \"%Y\")), \n                            as.numeric(format(end(xts.weekly), \"%W\"))), \n                  frequency = 52)\n\n  return(ts.weekly)\n}\n</code></pre> <p>After running the function, it will be available in our workspace and also be listed in the environment shown in RStudio:</p> <p></p> <p>Now we will load the MODIS raster dataset and the corresponding dates as we already did in the first time-series analysis Tutorial:</p> <pre><code>###\n# load raster-stacks exported from the Google Earth Engine\n###\n\n# set working directory\nsetwd(\"D:/Multiskalige_FE/5_Practicals/Tag_8_bfast\")\n\n# load MODIS NDVI time series with images from 2000-2020\nmod_ndvi &lt;- brick(\"MODIS_all_00_20_sm.tif\")\n\n###\n# load corresponding dates of the time series\n###\n\n# MODIS\nm_dat &lt;- read.table(\"dates_mod.txt\")\nm_dat_fin &lt;- m_dat[seq(2, nrow(m_dat),2),]\nm_dat_fin2 &lt;- as.character(m_dat_fin)\nm_dat_for &lt;- as.Date(m_dat_fin2, format = c(\"%Y%m%d\"))\n</code></pre> <p>Now we are all set for conducting our time-series analysis. First, we extract again the NDVI time series of an individual pixel:</p> <pre><code># MODIS (here, row 3, column 32)\nm_ts &lt;- as.vector(mod_ndvi[3,32])\n# set values of 0 to NA (masked pixels in this MODIS dataset have a value of 0)\nm_ts[m_ts==0] &lt;- NA\n</code></pre> <p>Then we create a daily time-series using the NDVI values and the corresponding dates. Be aware that we are using a special function of the bfastSpatial package to create the daily time series. This is necessary as the other packages do now allow us to transform an irregular time series with a periodicity longer than a day to a daily time series. Basically, the function \"bfastts\" just adds empty observation for each day to get a complete daily time-series (see figure below). While this process seems quite straightforward in this tutorial, I would like to mention that the bfastts() function is still a bit of a prototype and while it works fine with the MODIS data of this tutorial, I had troubles running it for the Landsat-based dataset we used in the other Tutorials. I think it has something to do with the doubling of some acquisition dates due to the simultaneous acquisitions of multiple Landsat satellites, but I did not figure out a solution, yet. So far, the work-flow in this tutorial is hence only working for the MODIS dataset.</p> <pre><code>###\n# create time series objects \n###\n\n# create daily time series object\nmod_ts &lt;- bfastts(as.vector(m_ts), m_dat_for, type = c(\"irregular\"))\nmod_ts\n</code></pre> <p>This will lead to the following object:</p> <p></p> <p>Now, we interpolate the time series and have a look at it:</p> <pre><code># interpolate time series\nmod_ts_ip &lt;- round(na.approx(mod_ts),0)\n\n# plot the resulting time series\nplot(mod_ts_ip)\n</code></pre> <p>This results in the following plot:</p> <p></p> <p>Now we are already almost ready to run bfast. The last step, before we run it is to aggregate the time series from daily to weekly time series using:</p> <pre><code>mod_ts_ip2 &lt;- aggregate.daily.to.weekly(mod_ts_ip)\n</code></pre> <p>If you are interested, you can also plot this new time series, but you will not see any real differences to the daily time series.</p>"},{"location":"BFAST/BFAST/#step-2-running-bfast-for-an-individual-pixel","title":"Step 2: Running BFAST for an individual pixel","text":"<p>We are now ready, to run BFAST. In the BFAST algorithm several parameters have to be defined. We can have a look at the help of the bfast function to find a bit more about the settings:</p> <pre><code>?bfast\n</code></pre> <p>Unfortunately, the information given in the help is comparably sparse - it might hence be valuable to also read the two papers in which BFAST is described with more details. One key-setting is the \"h\" parameter which defines how large the time-difference between two breakpoint has to be at least before a second breakpoint can be detected. From the limited experience I have with BFAST in practice, I know that the h parameter has a quite notable impact on the results. However, unfortunately, I do not have a good general recommendation how to set it. It might be worthwhile to have a closer look at the literature about this. The other important settings are \"season\". This defines which model will be used to fit the seasonal (phenological) cycle which is inherent in most vegetation datasets. In case there is now clear seasonal cycle observable in the study area of interest (e.g., in the tropics), this parameter can be set to \"none\". Otherwise, the standard setting \"harmonic\" should work well in most cases. Finally, another important parameter is \"breaks\" which defines the maximum number of break points that should be detected by BFAST. In our example, we set this to 2. The decision about the number of breakpoints has to be taken based on the knowledge of the ecosystem under study. Typically, ecosystems experience heavy disturbances in a certain time-interval which might be quite large. So given the maximal length of current remote sensing time series (approximately 40 years), in most ecosystems, we cannot expect more then 2 or maybe 3-4 disturbances. Here, we have a MODIS time series of 20 years and hence I decided to set the number of disturbances to two.</p> <p>So let's run the algorithm:</p> <pre><code>bfm2 &lt;- bfast(mod_ts_ip2[,1], h = 10/length(mod_ts_ip2[,1]), \n         season = \"harmonic\", breaks = 2, max.iter = 2)\n</code></pre> <p>You will see that even running BFAST for a single pixel, takes quite a bit of time (depending on your computer  and depending also on the properties of the selected pixels several seconds, up to 1-2 minutes is realistic). </p> <p>After the code has run, we can have a look at the results by running:</p> <pre><code>plot(bfm2)\n</code></pre> <p>This will results in the following plot:</p> <p></p> <p>We can see, that for the current pixel, BFAST detected two break points which are rather close together in time. Whether these are real breakpoints can be discussed. They might also be related to an artefact in the time series. At least at first glance, the overall impression is not that of a clear drop.</p> <p>Nevertheless, it is worthwhile to have a closer look at the graph as it describes quite well how BFAST works. On the top panel, we can see the original time series. In the second panel from the top, we can see the seasonal model that was fitted by BFAST. In the third panel, we can see the linear trend components which are fitted separately for each continuous segment between breakpoints. The last, bottom panel shows the residuals which are not explained by the seasonal and the trend component together.</p> <p>You can now re-run the bfast function and have a look how for example changing the number of breaks or the h parameter influences the results and maybe also rerun the algorithm for some other pixels. This is good for getting a feeling how variable the results can be which is important if BFAST is used for an analysis over a larger area and the final, often summarized, results have to be interpreted.</p> <p>One more important point is to access some key-results contained in the bfast object created by the bfast() function. Two pieces of information that can be accessed quite easily is the magnitude and the time-point of the largest breakpoint. This can be achieved by running:</p> <pre><code>bfm2$Magnitude\nbfm2$Time\n</code></pre> <p>Which will result in:</p> <p></p> <p>This can be interpreted that we had a drop in NDVI of 1709 (0.1709) as compared to the expected value at the 605th value of our time series. We can get the exact date by running:</p> <pre><code>as.yearmon(time(mod_ts_ip2)[bfm2$Time])\n</code></pre> <p>Which will result in:</p> <p></p>"},{"location":"BFAST/BFAST/#step-3-running-bfast-over-a-complete-raster","title":"Step 3: Running BFAST over a complete raster","text":"<p>So far, we applied BFAST to a single pixel of a raster-time-series. In this step, we will use the \"calc()\" function to apply it to a smaller raster dataset. As we have seen before, BFAST is quite time-intensive, so we will apply it to a really small raster which we first have to create by spatially aggregating our already comparably small MODIS dataset by the factor of 10:</p> <pre><code># plot the 5th time point of the MODIS time series (earlier time points were mostly data gaps)\nplot(mod_ndvi[[5]])\n# spatially aggregate the the MODIS raster stack to a spatial resolution 2500 m\nmod_ndvi2 &lt;- aggregate(mod_ndvi,10)\n# plot the same time point after the aggregation\nplot(mod_ndvi2[[5]])\n</code></pre> <p>This will show the following two plots:</p> <p> </p> <p>As you can see, by using the aggregate function we reduced the spatial resolution of the raster stack to reduce the number of pixels. An alternate way of reducing the size of the raster would have been to crop the raster to a smaller extents. Anyway, now we only have 4 by 10 pixels left, which will result in a comparably low computational time for the BFAST calculations.</p> <p>To later see the progress of our calculations we activate the progressbar setting of the raster package using:</p> <pre><code>rasterOptions(progress = 'text')\n</code></pre> <p>To enable using the \"calc()\" function in combination with BFAST, we have to put the complete bfast-workflow we used above for a single pixel into a function. This function looks like this:</p> <pre><code># the function takes two inputs: pixels = the NDVI time series values; dat_hard = the corresponding dates\nbfmRaster2 = function(pixels, dat_hard){\n\n  # the following lines mirror exactly what we did above:\n\n  # first we set MODIS pixels with value of 0 to NA\n  pixels[pixels==0] &lt;- NA\n\n  # then we create a daily time series\n  day_ts &lt;- bfastts(as.vector(pixels), dat_hard, type = c(\"irregular\"))\n\n  # we fill the data gaps\n  day_ts_ip &lt;- round(na.approx(day_ts),0)\n\n  # we transform the daily to a weekly time series\n  week_ts_ip &lt;- aggregate.daily.to.weekly(day_ts_ip)\n\n  # we run bfast\n  bfm_f &lt;- bfast(week_ts_ip[,1], h = 10/length(week_ts_ip[,1]), \n                 season = \"harmonic\", breaks = 2, max.iter = 2)\n\n  # and extract and return the Magnitude and time point of the largest breakpoint\n  return(c(bfm_f$Magnitude, bfm_f$Time))\n\n}\n</code></pre> <p>Then wen can apply the function to the raster stack by using the \"calc()\"-function. </p> <pre><code>bfras &lt;- calc(mod_ndvi2, function(x){bfmRaster2(x, dat_hard = m_dat_for)})\n</code></pre> <p>The call of the function is written in this a bit more complicated way because we additionally have to define the second variable \"dat_hard\" during the function call. So we basically define a function that calls the bfmRaster2 function with the second variable already defined. </p> <p>This will run for a few minutes (there should appear a progress bar, after the first few pixels were processed) . Then we can have a look at the results which will also be stored as raster datasets:</p> <pre><code># change the name of the output rasters\nnames(bfras) &lt;- c(\"Magnitude\", \"Timepoints\")\n# plot the output maps\nplot(bfras)\n</code></pre> <p>This should result in the following plot:</p> <p></p> <p>In these graphs, we can see that only for a few pixels (all pixels with Magnitudes &gt; 0), breakpoints were detected and we can also see whether they were more towards the beginning or the end of the time series. In theory, it is of course possible to also extract more detailed information from the bfast-object but in this tutorial, we will not further explore these options. I am again also referring to the two publications of Verbesselt et al (2010+2010a) in which BFAST is explained with more details and which are provided on ILIAS.</p> <p>If you are interested, you can also try to apply BFAST to another study area and with higher resolution data, you just have to consider the notably increased processing time. Even though, the bfast()-function also supports multi-core processing (check the help-function ?bfast) which may be beneficial for such use-cases if a computer with more the than one cores is available.</p>"},{"location":"BFAST/BFAST/#step-4-exploring-the-npphen-algorithm","title":"Step 4: Exploring the NPPHEN algorithm","text":"<p>After BFAST we will now explore one more algorithm that accounts for the seasonal signal but in a slightly different approach. Instead of fitting a seasonal signal to the full time series, NPPHEN takes observations of the whole or a part of the time series (that is, from several years) and summarizes them into one general annual phenological cycle. This summary is accomplished by calculating a kernel-density-map in which for each date within a year, the probability of a given time-series value is defined.</p> <p>This sounds quite abstract, but if you go back to the theoretical lectures and check the corresponding graphs, the idea becomes quite clear. You can also find more information about NPPHEN in the manuscript of Estay &amp; Chavez provided on ILIAS and here:</p> <p>http://www.pucv.cl/uuaa/site/edic/base/port/uuaa/labgrs/proyectos/introduction-to-npphen-in-r/2018-06-27/114109.html</p> <p>I would like to point out at the beginning, that the NPPHEN package is still under development. I came across some issues which I will also mention below, that make me doubt a bit the conducted analysis of some of the functions. As I still like the basic idea behind the package, I am still presenting the functionalities below, but this should all be considered carefully. In case someone would like to use this approach for a real analysis, I would highly recommend to re-check the source code of the package. I had a quick look and it does not seem to be that complex.</p> <p>The first part of the code is almost identical to the BFAST code - we load the required packages, define the additional function to convert daily time series to weekly time series, we load the MODIS data and extract the time series for a single pixel:</p> <pre><code>aggregate.daily.to.weekly &lt;- function(daily.ts) {\n\n  dates      &lt;- as.Date(date_decimal(as.numeric(time(daily.ts))))\n\n  xts.daily  &lt;- xts(daily.ts, order.by = dates)\n\n  xts.weekly &lt;- round(xts::apply.weekly(xts.daily, median),0)  # xts\n\n  start(xts.weekly)\n  ts.weekly &lt;- ts(data = xts.weekly, \n                  # define the start and end (Year, Week)    \n                  start = c(as.numeric(format(start(xts.weekly), \"%Y\")),\n                            as.numeric(format(start(xts.weekly), \"%W\"))), \n                  end   = c(as.numeric(format(end(xts.weekly), \"%Y\")), \n                            as.numeric(format(end(xts.weekly), \"%W\"))), \n                  frequency = 52)\n\n  return(ts.weekly)\n}\n\n# load required packages\nrequire(raster)\nrequire(xts)\nrequire(zoo)\nrequire(bfastSpatial)\nlibrary(rgdal)\nlibrary(npphen)\nlibrary(rts)\nlibrary(lubridate)\n\n\n###\n# load raster-stacks exported from the Google Earth Engine\n###\n\n# set working directory\nsetwd(\"D:/Multiskalige_FE/5_Practicals/1_GEE_basics_v2\")\n\n# load MODIS time series with images from 2000-2020\nmod_ndvi &lt;- brick(\"MODIS_all_00_20_sm.tif\")\n\n###\n# load corresponding dates of the time series\n###\n\n# MODIS\nm_dat &lt;- read.table(\"dates_mod.txt\")\nm_dat_fin &lt;- m_dat[seq(2, nrow(m_dat),2),]\nm_dat_fin2 &lt;- as.character(m_dat_fin)\nm_dat_for &lt;- as.Date(m_dat_fin2, format = c(\"%Y%m%d\"))\n\n# extract single MODIS pixel (here, row 3, column 32)\nm_ts &lt;- as.vector(mod_ndvi[3,32])\nm_ts[m_ts==0] &lt;- NA\n\n###\n# create time series objects by merging the NDVI time series values with the corresponding dates\n###\n\n# create daily time series\nmod_ts &lt;- bfastts(as.vector(m_ts), m_dat_for, type = c(\"irregular\"))\n\n# interpolate missing values\nmod_ts_ip &lt;- round(na.approx(mod_ts),0) \n# have a look at the time series\nplot(mod_ts_ip)\n\n# aggreate time series to weekly time series\nmod_ts_ip2 &lt;- aggregate.daily.to.weekly(mod_ts_ip)\n</code></pre> <p>So far, the code is more or less identical to the one we used for BFAST. Now we have to extract two input variables from the weekly time series in a format that is compatible to algorithms of the NPPHEN package.</p> <p>First, we extract the weekly NDVI values which is comparably straightforward:</p> <pre><code># extract index values\nndvi.num &lt;- as.vector(mod_ts_ip2[,1])\nndvi.num\n</code></pre> <p>As we can see, this is now really only a vector and not a time series object anymore:</p> <p></p> <p>Next, we have to extract the corresponding dates. The dates have to be a date-vector. I played around a bit with some transformations, and the one that worked for me was this option:</p> <pre><code># extract the dates from the time-series object and covert it to numeric values\nmts &lt;- as.numeric(time(mod_ts_ip2))\n## then retransform them to dates in decimal form\ntms &lt;- date_decimal(mts)\ntms\n</code></pre> <p>This will look like this:</p> <p></p> <p>There might be smarter ways for extracting the dates, but this solution worked for me.</p> <p>After this step, we are ready to run the key-functions of the NPPHEN package. The first function will calculate the phenological signal of the complete time series. The main inputs are the ndvi-values we extracted from the MODIS pixels and the dates. Furthermore, we have to define on which hemisphere the study site is located - in our case Northern hemisphere and we hence set h=1. If we would be on the Southerm hemisphere, we would have to set h=2 as the seasons would be turned around. rge defines the value range of the provided time-series values which in our case are NDVI values scaled between 0 and 10000. Finally, we have to define the number of observations for the growing season. This basically tells the algorithm how many observation exist per year. The strange thing about this setting is, however, that only certain values will work. I did not yet find out what is the reason for this, but it seems to be an error in the function to me. The correct value for the standard MODIS 16-days product is 23, if we select this value here, the code runs even though our time series is weekly and we have 52 observations per year. We can also change the number to 46 and it will also run, and in this case the results will slightly vary. So far I have no explanations for this. The resulting plots are not fully plausible, but we will ignore this for the moment (see the tutorial linked on ILIAS where you can see how a typical result should look like). I will try to contact the developers of NPPHEN and ask them how they explain this. To produce the first plot, run the following code:</p> <pre><code># conduct the phenological reconstruction\nphen_1pix &lt;- Phen(ndvi.num, tms, h=1, rge=c(0,10000), nGS = 46)\n# plot the result\nplot(phen_1pix)\n</code></pre> <p>This will result in this graph:</p> <p></p> <p>We can see that the beginning of the phenological curve seems plausible, but the end of the curve seems incomplete. Given the fact that there should be 52 instead of 46 observation, this somehow makes sense.</p> <p>The current plot is only showing the mean NDVI values for the different time periods of the year. Next we will calculate and examine the kernel density plot where we can see the probabilities of certain NDVI values over the phenological year:</p> <pre><code># kernel density of the reconstructed phenology (for a numerical vector)\nPhenKplot(ndvi.num, tms,h=1,nGS=23, xlab=\"Day of the growing season\",ylab=\"EVI\", rge=c(0,10000))\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>We can also see in this plot that the shape of the curve is not fully plausible, but again, I will have to further examine this and I cannot deliver a good explanation at this point.</p> <p>Finally, we can use NPPHEN to calculate anomalies for a given time-period in comparison to a reference time period. For this we use the \"PehnAnoma()\" function. We again have to define the input time-series values, the dates and the hemisphere. Then, we can define a certain time period as reference time-period and a second period as the one in which anomalies will be identified. Here, I selected the time period from the start of the time-series until the end of the year 2015 as reference period and the last part of the time series will be checked for anomalies. This is all not very comfortable at the moment, as the user has to define the time-points himself by checking which id of the vector corresponds to which date. In my case, you can see for example that tms[824] is the last observation of 2015 and tms[826] is the first observation of 2016.</p> <pre><code>tms[824]\ntmx[825]\n</code></pre> <p>This will result in:</p> <p></p> <p>Ok, so lets run the code:</p> <pre><code>ano_GS16_1pix &lt;- PhenAnoma(ndvi.num, tms,h=1,refp=c(1:824), anop=c(825:1048), rge=c(0,10000)) \nplot(ano_GS16_1pix)\n</code></pre> <p>This will result in:</p> <p></p> <p>In this plot, the anomalies for the examined time-periods can be checked - however, the fact that there is a rather regular up- and down pattern makes me worry, that these results might not be fully correct. </p>"},{"location":"BFAST/BFAST/#additional-time-series-functionalities","title":"Additional time series functionalities","text":"<p>While putting together the material for this Tutorial, I came across another r-package named \"greenbrown\" that could be interesting for those who became more interested in time-series analysis during the last weeks. It offers several functions that are similar to the ones, we got to know over the last weeks but may be even more suitable for some remote sensing applications. One option for the final assignment could be to provide a Tutorial (similar as the ones you have been working now throughout the course) about the functionalities offered in this packages and using an own illustrative dataset.</p> <p>http://greenbrown.r-forge.r-project.org/trends.php</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/","title":"Preparing time series data stacks#","text":""},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#overview","title":"Overview","text":"<p>In this lecture you will learn how to use the Google Earth Engine (GEE) to extract time series of all available Landsat and MODIS data for a study area defined in a Polygon shapefile. Before we work with the actual code, I will provide some links to the official documentation of the Google Earth Engine, which you should read carefully. I decided to not reproduce all of this information in this tutorial as many of the contents on the official page are very well described and easy to understand.</p> <p>One important aspect of today's tutorial is that we will not use R to work within the GEE but java-script. However, there is no need for you to learn a new programming language from scratch. One efficient way to use the GEE is to simply copy &amp; paste code snippets that can be found on the official GEE page and in online forums and then only adapt some smaller parts of the code to make them run with your data. Most of the basic processing chains in the GEE which are required to prepare datasets for further processing in R have been already implemented and are well documented in the internet. </p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#learning-objectives","title":"Learning objectives","text":"<p>Besides getting familiar with the Google Earth Engine itself, we will also learn some concrete processing steps within the GEE: </p> <ul> <li>how to upload a Shapefile to the Google Earth Engine and use it as region of interest / study area</li> <li>load Landsat and MODIS image collections in the GEE</li> <li>select certain time-windows in the image collection</li> <li>perform cloud-masking on the image collection in the GEE</li> <li>calculate NDVI within Landsat image collections</li> <li>store the prepared NDVI time-series to a Google Drive</li> </ul> <p>In the later parts of the tutorial we will load the time series raster stacks exported from the GEE to R and convert the raster-data to time-series objects and we apply some basic tools on them.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>The only dataset used in this Tutorial is a shapefile defining the boundary of the examined study area which is the city Xining, in the Qinghai province in China. Xining is the province capital of Qinghai and has been rapidly expaning its area over the last few years. The Shapefile can be downloaded here:</p> <p>https://drive.google.com/drive/folders/16OjLRl2HPM3_eiBklzRoHwDU3NQihpcS?usp=sharing</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#short-overview-of-the-google-earth-engine","title":"Short Overview of the Google Earth Engine","text":"<p>First of all: What is the Google Earth Engine (GEE)? The GEE is an online platform developed and hosted by Google which provides several very interesting opportunities for conducting geospatial analyses using remote sensing and other geodata. The idea of the platform is that most of the data (particularly data with large file sizes) is already available directly on the platform and that the user does not have to download the files before processing. Furthermore, the GEE also provides processing power directly in the online platform. That means, it is not only possible to access large amounts of geodata online but it is also possible to directly work with the data in the google cloud. The big advantage of this is, is quite obvious. This constellation allows users such as scientists to process huge amounts of data with a super-computer which may not be available at their university and for sure not at their institute. The only thing that is required to access the GEE is a computer with internet access.</p> <p>While this sounds great at the beginning, there are also some shortcomings to this system. At the moment the GEE is by far not offering as many algorithms as for example R. However, Google offers an interface to Python which provides a similar amount of algorithms as R with direct access to the GEE and a lot of opportunities to work with the data. A second problem is that even though the service is free at the moment, this philosophy could change any moment- in case Google simply decides to not longer provide the GEE services for free. Another small issue is, that for downloading the processed data, it is required to have a Google Drive which in the cost-free version has limited storage space. Hence for processing large dataset, it might be necessary to sign-up for plans with extended data volume to download the results and hence some costs will be created by processing within the GEE. However, for the exercises we will conduct in this course, a normal google account should be sufficient to download the results.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#dataset-in-the-gee","title":"Dataset in the GEE","text":"<p>An overview over the geo-datasets that are directly available in the GEE can be found here:</p> <p>https://developers.google.com/earth-engine/datasets</p> <p>This should lead you to a webpage hat looks like this:</p> <p></p> <p>Take some time to browse the data catalogue! It is quite impressive how many of the typical remote sensing datasets are directly available in the GEE. Amongst others, the GEE hosts the complete Landsat archive of Landsat 4, 5, 7 and 8 as well as the Sentinel-2 archive and most parts of the Sentinel-1 data. You can also find MODIS data. Most of the data are not only available as raw data but also as higher-level data. That is, the images have already been pre-processed with the standard processing chains of the original data providers. This can save a lot of time, as most of the tiring, repetitive tasks have already been completed and the user can directly focus on analyzing the data.</p> <p>For accessing the individual datasets (called \"collections\") in the GEE code editor (will be explained below), it is necessary to know the exact name and access-link of each image collection. You can find the corresponding values when you select one of the datasets under the link provided above. For example if we want to access the Landsat 8 surface reflectance data (that is, an atmospheric correction has already been applied to the raw satellite data), we would find the correponding name/link here:</p> <p>https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR</p> <p>The entry \"Earth Engine Snippet\" is the access-link/name under which we can access the LS 8 data within the GEE:</p> <p>ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")</p> <p>As a first small exercise, try to find out what the corresponding Snippets are for Landsat 5 Surface Reflectance Data and one of the MODIS products in which NDVI is included and at a spatial resolution of 250 m. Please provide the answers in ILIAS (Aufgabe 9 - Code Snippets).</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-1-registering-for-the-google-earth-engine","title":"Step 1: Registering for the Google Earth Engine","text":"<p>If you don't have a Google Earth Engine account yet, you can sign-up here:</p> <p>https://developers.google.com/earth-engine</p> <p>Simply press on the marked link and follow the instructions:</p> <p></p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-2-the-google-earth-documentation","title":"Step 2: The Google Earth Documentation","text":"<p>The official GEE documentation provides a rich amount of tutorials explaining the functionalities of the GEE from scratch. It is highly recommended to read some of the materials provided here to gather a first understanding how the GEE works and to develop a basic understanding of the java-script language being used in the GEE code editor. However, please be aware that many things can also be accomplished without understanding the java-script syntax completely but rather by modifying code-snippets as mentioned already above. The GEE documentation can be accessed here:</p> <p>https://developers.google.com/earth-engine/tutorials</p> <p>Some recommendable tutorials to play around with and get acquainted with the way the GEE works are linked below. Take some time and explore some of the tutorials - you will see it is quite interesting how fast data can be accessed and visualized. If you participated in the remote sensing course in the winter semester you will quickly understand how much more comfortable the data access in the GEE is, in comparison to downloading individual satellite images, pre-processing them and then loading them in R or another programming environment. Before starting with the Tutorials below, it might be worthwhile to have a quick look at Step 3 first were the GEE code editor is briefly introduced.</p> <p>Some recommended Tutorials:</p> <p>https://developers.google.com/earth-engine/image_visualization</p> <p>https://developers.google.com/earth-engine/image_info</p> <p>https://developers.google.com/earth-engine/image_math</p> <p>https://developers.google.com/earth-engine/image_relational</p> <p>https://developers.google.com/earth-engine/ic_filtering</p> <p>These are just some recommended tutorials to get started with remote sensing data, but you will see that in the same documentation page, there will be loads of additional examples to also conduct more complex analyses directly within the GEE environment.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-3-the-gee-code-editor","title":"Step 3:  The GEE code Editor","text":"<p>After registering for the GEE you can access code editor (the main interface we will be using for working in the GEE) here:</p> <p>https://code.earthengine.google.com/</p> <p>This will lead to an interactive web-page which looks like this:</p> <p></p> <p>The code editor window is separated into four major sections. In section 1 you can find all the Scripts, documentations and Assets (basically, data that the user uploads) connected to your user account. In section 2 the code you are currently working on will be displayed and in section 3 you wil be informed about the processing progress of your code (Console) and you can for example start the export of files (Tasks). Finally, in section 4, a world map is displayed and you will later on also learn how to display the data you have processed in the GEE on this map.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-4-exporting-a-complete-time-series-of-modis-ndvi-data","title":"Step 4: Exporting a complete time series of MODIS NDVI data","text":"<p>In this first hands-on part of the tutorial, we will export a complete time series of MODIS NDVI products for a small area located at the border of the Qinghai Tibetan Plateau. The area covers parts of the city Xining in China. At this point, I am assuming that you have already played around with the Google Earth Engine by exploring some of the tutorials mentioned in Step 2.</p> <p>As first step to perpare our work-flow we will upload the Shapefile provided in the \"Datasets used in this Tutorial section\". For this, we will select the tab Assets in section 1 of the code editor:</p> <p></p> <p>Then we will click the red NEW button and select \"Shape files\":</p> <p></p> <p>In the appearing window, we have to first select all the supported Shapefile sub-files (marked with 1) and then assign a name to the uploaded files, for example \"Xining\" (marked with 2). Then we can upload the files by pressing \"UPLOAD\" in the bottom right part of the window.</p> <p></p> <p>The files will then be uploaded to the Google Earth engine and saved in your list of asstes. You might have to press the \"refresh\" button next to the red \"NEW\" button to make the new asset named \"Xining\" appear in your list. We can now use the uploaded Shapefile for working with the GEE.</p> <p>In order to this, we have to import the asset into the script we are currently working on. We can do this by selecting the \"arrow\" button marked with 1 in the screenshot below.</p> <p></p> <p>After clicking the \"arrow\" button, the asset/Shapefile will be imported to t he current script and a new line will appear on the top of the script. We can define a name for the imported Shapefile by changing the default name \"table\" to some other term. In the given example, I changed the name to \"AOI\" - area of interest.</p> <p>In the following I will now provide the complete code for exporting MODIS NDVI data from the GEE - you can simply copy &amp; paste this code to the code editor window and you should be ready to run it. More detailed explanations can be found directly in the code and further below:</p> <pre><code>// Filter a MODIS image collection by date and region \n// Calculate an NDVI\n// Export the NDVI time series to Google Drive\n\n\n// Step 1: Define the time period to be considered \nvar sdate = '2000-01-01'\nvar edate = '2020-05-25'\n\n// Step 2: define functions requires for processing\n\n// ###################################\n// functions to perform cloud masking\n// ###################################\n\nvar maskQA = function(image) {\n      return image.updateMask(image.select(\"SummaryQA\").eq(0));\n    };\n\n// Step 3: Process the data\n\n// Load the MODIS collection and filter the collection for the\n// considered time period and the area of interest\n\n// ##############################################################\n// Load MODIS product MOD13Q1 (please check the specifications\n// in the GEE data catalogue)\n// ##############################################################\nvar MODIS_VI = ee.ImageCollection(\"MODIS/006/MOD13Q1\")\n    .filterDate(sdate, edate)\n    .filterBounds(AOI);\n\n// ##############################################################\n// Apply cloud masks to image collections\n// ##############################################################\n\nvar MODIS_best = MODIS_VI.map(maskQA)\nprint(MODIS_best)\n\n// ##############################################################\n// Select the NDVI band from the MODIS product \n// ##############################################################\n\nvar MODIS_ndvi = MODIS_best.select('NDVI');\nprint(MODIS_ndvi)\n\n// ##############################################################\n// transform the NDVI image collection to a stack of bands so that they can\n// be exported to the Google Drive\n// ##############################################################\nvar MODIS_ndvi_fin = MODIS_ndvi.toBands();\n\n// ##############################################################\n// Apply a work-around to access the image dates (see further instructions below)\n// ##############################################################\n\nfunction ymdList(imgcol){\n    var iter_func = function(image, newlist){\n        var date = ee.Number.parse(image.date().format(\"YYYYMMdd\"));\n        newlist = ee.List(newlist);\n        return ee.List(newlist.add(date))\n    };\n    return imgcol.iterate(iter_func, ee.List([]));\n}\nvar dates = ymdList(MODIS_ndvi);\n\nprint(dates);\n\n\n// ##############################################################\n// Export Landsat time series to GeoTiff (see further instructions below)\n// ##############################################################\n\n\n// Export a cloud-optimized GeoTIFF.\nExport.image.toDrive({\n  image: MODIS_ndvi_fin,\n  description: 'MODIS_all_00_20_sm',\n  scale: 250,\n  maxPixels: 5937315072,\n  region: AOI,\n  fileFormat: 'GeoTIFF',\n  formatOptions: {\n    cloudOptimized: true\n  }\n});\n</code></pre> <p>To successfully run this code, copy &amp; paste the complete code to the code editor window. Then click save or save as and the current script will be saved and appear in your list of scripts in section 1 of the code editor. Alternatively you can also access the code here:</p> <p>https://code.earthengine.google.com/9468bf79e67904e6cb0a639aa3b7019b</p> <p>Be aware that you have to still define the Shapefile using your assets-list if you access the code via the link. After accessing and saving the script, you should be able to run the code by clicking Run.</p> <p>Once you pressed Run, new information will appear in the Console in section 3. </p> <p></p> <p>In the console, we can mostly find some information that was printed to the Console by the code-lines that start with the \"print()\" command. In this example, the two upper entries of the console simply allow us to see how many images have been processed/selected based on our definition: 465 images were available for the selected product and time-window. The last entry, is in our case the most important one, as this entry contains all the dates at which the satellite images were acquired. In this tutorial we will simply copy and paste the dates to a text-file by opening the list (click on the text marked with 1) and then mark all the entries and copy them</p> <p></p> <p>Then open the Windows Editor program:</p> <p></p> <p>And paste the entries to the text file:</p> <p></p> <p>And finally save this text-file to a folder in which we can find it again. Let's name it for example \"dates_mod.txt\". This is not a very elegant wy of exporting the acquisition dates but while preparing this Tutorial, I had troubles finding a straightforward solution directly in the GEE and as this workflow works, we will stick with it for now and I hope that by next year, I will have found a smoother option to accomplish this.</p> <p>With this step, we have saved the acquisition dates, but we did not yet export the corresponding images. We will now do this by selecting the \"Tasks\" tab in section 3 of the code editor (marked with 2):</p> <p></p> <p>We will then see a list of tasks that wait for being executed. In my case, there are several tasks from earlier scripts in the list, in your case there might only be on task which is named as the one in the top of my list - MODIS_all_00_20_sm:</p> <p></p> <p>We can now start the export of the raster stack to our Google Drive by clicking the \"RUN\" button (marked with 1). This will open a new window in which we can define the spatial resolutiojn with which we want to export the images and a folder in our google drive in which the data shall be stored. We can also not define a folder, then the image will simply be exported to the parent folder of the Google Drive. Once you are happy with your settings click \"RUN\" and then you will have to wait a few minutes or up to a few hours (if the data is large) until the data appears in your Google Drive. In this example a file named \"MODIS_all_00_20_sm.tif\" will occur in your google drive. If you are not sure how to access your Google drive, please google it. Should be very easy to find. Then download the data from your google drive in a folder on your hard-disc which you will be able to find again (we will need the data in Step 6).</p> <p></p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-5-exporting-a-complete-time-series-of-landsat-5-7-and-8-data","title":"Step 5: Exporting a complete time series of Landsat 5, 7 and 8 data","text":"<p>After we managed to export all available NDVI MODIS images of the MODIS product MOD13Q1 for our area of interest, we will now try to accomplish the same but for the complete Landsat archive of the satellites Landsat 5, 7 and 8. The basic processing steps are the same, but the code itself is a bit more complex as we have to merge data from several image collections and also have to first calculate the NDVI from the original images.</p> <p>We will again have to load the Shapefile available in our \"Assets\" list as we have just learned for the MODIS example and will also again have to apply the work-around described in Step 4 to export the image acquisition dates manually by copy and pasting the dates to a text-file. I will not go into details about these steps again but simply provide the code for exporting the Landsat raster stack below. There are more detailed comments provided in the code itself. In case there are more questions related to the code, please formulate them in the Forum and I will try to reply as soon as possible. Be aware, that the data exported in this step are a bit larger as in the MODIS example (550 MB vs. 2 MB) - hence the export from the GEE might take notably longer in the Landsat case.</p> <p>Here is the code that should be ready to run - please go through it carefully and try to understand what is happening. It is not of utmost important to understand each individual step, but rather to understand the coarse work-flow:</p> <pre><code>// Filter a Landsat image collection by date and region \n// Calculate an NDVI\n// Export the NDVI time series to Google Drive\n\n\n// Define the time period to be considered \nvar sdate = '1986-01-01'\nvar edate = '2020-05-25'\n\n// ####################################\n// functions to perform cloud masking\n// ####################################\n\n// Landsat 4+5+7\n\nvar cloudMaskL457 = function(image) {\n  var qa = image.select('pixel_qa');\n  // If the cloud bit (5) is set and the cloud confidence (7) is high\n  // or the cloud shadow bit is set (3), then it's a bad pixel.\n  var cloud = qa.bitwiseAnd(1 &lt;&lt; 5)\n          .and(qa.bitwiseAnd(1 &lt;&lt; 7))\n          .or(qa.bitwiseAnd(1 &lt;&lt; 3))\n  // Remove edge pixels that don't occur in all bands\n  var mask2 = image.mask().reduce(ee.Reducer.min());\n  return image.updateMask(cloud.not()).updateMask(mask2);\n};\n\n// Landsat 8\nfunction maskL8sr(image) {\n  // Bits 3 and 5 are cloud shadow and cloud, respectively.\n  var cloudShadowBitMask = 1 &lt;&lt; 3;\n  var cloudsBitMask = 1 &lt;&lt; 5;\n\n  // Get the pixel QA band.\n  var qa = image.select('pixel_qa');\n\n  // Both flags should be set to zero, indicating clear conditions.\n  var mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0)\n      .and(qa.bitwiseAnd(cloudsBitMask).eq(0));\n\n  // Return the masked image, scaled to reflectance, without the QA bands.\n  return image.updateMask(mask).divide(10000)\n      .select(\"B[0-9]*\")\n      .copyProperties(image, [\"system:time_start\"]);\n}\n\n// #############################################\n// define function to calculate Landsat NDVI\n// separate function for Landsat 5+7 and Landsat 8\n// #############################################\nvar addNDVI_LS8 = function(image) {\n  var ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI');\n  return image.addBands(ndvi);\n};\n\nvar addNDVI_LS5_7 = function(image) {\n  var ndvi = image.normalizedDifference(['B4', 'B3']).rename('NDVI');\n  return image.addBands(ndvi);\n};\n\n\n\n// ##############################################################\n// Load the Landsat image collection of Landsat 5, 7 and 8\n// ##############################################################\nvar surfaceReflectanceL5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR')\n    .filterDate(sdate, edate)\n    .filterBounds(AOI);\nvar surfaceReflectanceL7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')\n    .filterDate(sdate, edate)\n    .filterBounds(AOI);\nvar surfaceReflectanceL8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\n    .filterDate(sdate, edate)\n    .filterBounds(AOI);\n\n// ##############################################################\n// Apply cloud masks to image collections\n// ##############################################################\n\n\nvar LS5 = surfaceReflectanceL5\n    .map(cloudMaskL457);\n    //.median();\nprint(LS5)\n\nvar LS7= surfaceReflectanceL7\n    .map(cloudMaskL457);\n    //.median();\nprint(LS7)\n\nvar LS8 = surfaceReflectanceL8\n    .map(maskL8sr);\n    //.median();\nprint(LS8)\n\n// ##############################################################\n// Calculate NDVI and merge Ls 5, 7, and 8\n// ##############################################################\n\n// merge Landsat image collection 5 to 7\nvar LS_5_7 = LS5.merge(LS7)\n// calculate NDVI for merged collection\nvar LS_5_7_NDVI = LS_5_7.map(addNDVI_LS5_7).select('NDVI');\nprint(LS_5_7_NDVI, \"LS_5_7_NDVI\");\n\n// calculate NDVI for Landsat 8 collection\nvar LS8_NDVI = LS8.map(addNDVI_LS8).select('NDVI');\nprint(LS8_NDVI, \"LS8_NDVI\");\n\n// merge all NDVI data\nvar LS_NDVI_all = LS_5_7_NDVI.merge(LS8_NDVI)\nprint(LS_NDVI_all, \"LS_NDVI_all\");\n\n// transform collection to bands\nvar LS_NDVI_all_fin = LS_NDVI_all.toBands();\n// crop bands to AOI\nvar LS_NDVI_all_clip = LS_NDVI_all_fin.clip(AOI);\n\n// extract acquisition dates\nfunction ymdList(imgcol){\n    var iter_func = function(image, newlist){\n        var date = ee.Number.parse(image.date().format(\"YYYYMMdd\"));\n        newlist = ee.List(newlist);\n        return ee.List(newlist.add(date))\n    };\n    return imgcol.iterate(iter_func, ee.List([]));\n}\nvar dates = ymdList(LS_NDVI_all);\n\n// print acquisition dates\nprint(dates);\n\n\n\n// ##############################################################\n// Export Landsat time series to GeoTiff\n// ##############################################################\n\n\n// Export a cloud-optimized GeoTIFF.\nExport.image.toDrive({\n  image: LS_NDVI_all_clip,\n  description: 'LS_NDVI_all_86_20',\n  scale: 30,\n  maxPixels: 5937315072,\n  region: AOI,\n  fileFormat: 'GeoTIFF',\n  formatOptions: {\n    cloudOptimized: true\n  }\n});\n</code></pre> <p>Alternatively, you can also access the code via this link:</p> <p>https://code.earthengine.google.com/82beb77c79bea6813967a6ad07056c7e</p> <p>After you have successfully executed the code and exported the file using the same work-flow as described for MODIS, you should also download the corresponding file (named LS_NDVI_all_86_20.tif) from your google drive to the same folder where you stored the MODIS raster. The two text-files containing the image acquisition dates for MODIS and Landsat should also be in the same folder.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-6-exploring-the-exported-data-in-r","title":"Step 6: Exploring the exported data in R","text":"<p>As final step in this tutorial, we will load the NDVI raster-stacks exported from the GEE in R and create time-series by merging the NDVI values with the image acquisition dates stored in the text-files. We will need the exported raster-files and the text-files. So please make sure that you have all data stored in a folder and know where this folder is.</p> <p>Next, we open RStudio and load the required packages:</p> <pre><code># load required packages\nrequire(raster)\nrequire(xts)\nrequire(zoo)\n</code></pre> <p>In case some packages are missing, please install them (you should know how to do this by now, if not, please check the older Tutorials). Next, we will load the raster-files containing the MODIS and Landsat time series:</p> <pre><code>###\n# load raster-stacks exported from the Google Earth Engine\n###\n\n# set working directory\nsetwd(\"D:/Multiskalige_FE/5_Practicals/1_GEE_basics_v2\")\n# load Landsat time series with images from 1986-2020\nls_ndvi &lt;- brick(\"LS_NDVI_all_86_20.tif\")\nnlayers(ls_ndvi)\n# load MODIS time series with images from 2000-2020\nmod_ndvi &lt;- brick(\"MODIS_all_00_20_sm.tif\")\nnlayers(mod_ndvi)\n</code></pre> <p>Be aware, that this time, we use the brick() command instead of the stack() command to load the raster files. This command will allow to access the raster-files in a slightly different way which increases the speed to access all raster-layers of an individual pixel (which in our case refers to a time-series). If you want to see the difference, you can re-run the code using the stack() command instead of the brick() command and you will see that one of code lines will run very slow (find out which one if you are interested!).</p> <p>After loading the raster stacks, we will also load the text-files containing the image acquisition dates, we copy &amp; pasted from the GEE console. We will use the following code to do this:</p> <pre><code>###\n# load corresponding dates of the time series\n###\n\n# Landsat\n\n# read table\nls_dat &lt;- read.table(\"dates_ls.txt\")\n# drop every second line (containing only the id)\nls_dat_fin &lt;- ls_dat[seq(2, nrow(ls_dat),2),]\n# transform remaining rows from factor to character\nls_dat_fin2 &lt;- as.character(ls_dat_fin)\n# transform character-expression to dates\nls_dat_for &lt;- as.Date(ls_dat_fin2, format = c(\"%Y%m%d\"))\n\n# MODIS\n\n# read table\nm_dat &lt;- read.table(\"dates_mod.txt\")\n# drop every second line (containing only the id)\nm_dat_fin &lt;- m_dat[seq(2, nrow(m_dat),2),]\n# transform remaining rows from factor to character\nm_dat_fin2 &lt;- as.character(m_dat_fin)\n# transform character-expression to dates\nm_dat_for &lt;- as.Date(m_dat_fin2, format = c(\"%Y%m%d\"))\n</code></pre> <p>Be aware that R has an own data-type for dates. To transform the entries of the text-files into a vector containing only dates, we have to follow several processing steps as indicated in the code above. First we load the text-file into a variable. In this stage, the imported file looks like this:</p> <p></p> <p>That is, we  have the ID in one row and the actual acquisition dates in the format: YYYYMMDD in every second row. Hence, we are only interested in every second row of our variable. That is we we run the code:</p> <pre><code>ls_dat_fin &lt;- ls_dat[seq(2, nrow(ls_dat),2),]\n</code></pre> <p>which will then lead to the following output:</p> <p></p> <p>We now only have the acquisition dates in the variable, but as we can see the current vector is still in the wrong format. The information on \"Levels\" indicates that the data type of the vector is currently \"factor\". We hence first transform the vector to \"character\" and then to a \"date\" vector using the lines:  </p> <pre><code># transform remaining rows from factor to character\nls_dat_fin2 &lt;- as.character(ls_dat_fin)\n# transform character-expression to dates\nls_dat_for &lt;- as.Date(ls_dat_fin2, format = c(\"%Y%m%d\"))\n</code></pre> <p>Now, we have prepared the acquisition dates in a way, so that they can be used to create time-series objects. But before we will do this, we will have a quick look at the raster data we exported from the Google Earth Engine. We will use a for-loop to plot some of the NDVI images of the time series. We will not plot all images, as this would take a really long time (particularly for the Landsat data which generally requires a lot more time to plot the individual NDVI images). Be aware that you can stop the ploting-loop at any time by pressing the little \"stop\" button in RStudio. We will plot 10 of the Landsat scenes and 40 of the MODIS scenes. Depending on the speed of your computer this may take a while. Have a look at the images that appear and reflect what you are seeing.</p> <pre><code>###\n# have a brief look on the data by plotting the individual time series\n# raster of MODIS and some selected scenes of Landsat\n###\n\n# plot selected Landsat NDVI rasters\n\nfor(i in 420:430){\n\n  plot(ls_ndvi[[i]], main=ls_dat_for[i], zlim=c(-0.5,1))\n\n}\n\n# plot MODIS NDVI rasters\n\nfor(i in 1:40){\n\n  plot(mod_ndvi[[i]], main=m_dat_for[i], zlim=c(-5000,10000))\n\n}\n</code></pre> <p>Probably most of you observed at least two things: 1. The plotted raster data in many cases showed data gaps with NA or 0 values; 2. The NDVI images show quite clear seasonal signals with a lot more positive NDVI values during the summer months. Both of these observations are quite typical for dense time series of remote sensing data. Due to cloud cover and snow, there are many missing values included. Particularly, if no temporal mosaicing is conducted. The latter we will learn next week. We will now have a closer look at the seasonal signal by plotting NDVI time series of individual pixels. To do this, we first extract the complete NDVI time series of one MODIS and one Landsat pixel:</p> <pre><code>###\n# extract NDVI time series for individual pixels\n###\n\n# extract Landsat pixel (here row 45, column 56)\nls_ts &lt;- as.vector(ls_ndvi[45,56])\n\n# MODIS (here, row 1, column 1)\nm_ts &lt;- as.vector(mod_ndvi[1,1])\nm_ts[m_ts==0] &lt;- NA\n</code></pre> <p>You could easily modify the codes above to select different pixels and explore how the corresponding time-series look like. In case of the MODIS pixels, a value of 0 indicates a masked pixel which had a low data quality due to cloud-cover or snow. We hence set al values of 0 to NA.</p> <p>Next, we will create time series objects. Time series objects are a special kind of data type in R which typically contain some sort of observational values (in our case NDVI values) and corresponding time stamps (which in our case were prepared from the text files as described above). There are different packages in R that allow creating time series objects. Here, we use the xtc package. A summary of the most important xtc commands can be found here:</p> <p>https://drive.google.com/open?id=1sAe2GalxPk2T3Ce8R53Zz5fqooY9Katt</p> <p>To create the time series object, we first create a dataframe containing the NDVI values of the pixel and the time-stamps and subsequently create the xtc object:</p> <pre><code># prepare dataframe with NDVI values and dates\nls.df &lt;- data.frame(ls_ts, ls_dat_for)\nm.df &lt;- data.frame(m_ts, m_dat_for)\n\n# create time series object\nls.NDVI.ts &lt;- xts(ls.df$ls_ts, order.by=ls.df$ls_dat_for)\nmod.NDVI.ts &lt;- xts(m.df$m_ts, order.by=m.df$m_dat_for)\n</code></pre> <p>Next, we will plot the prepared time-series datasets:</p> <pre><code># plot the time series\nplot(ls.NDVI.ts)\nplot(mod.NDVI.ts)\n</code></pre> <p>This will lead to the following graphs:</p> <p> </p> <p>As we can see, both time series show a quite clear seasonal signal. The MODIS time series is notably shorter than the Landsat time series. Be aware that the two time series do not represent the exact same location and should hence not be directly compared. They are just meant to be a random example. Even though, you could adapt the code and extract a time series for pixels that are actually overlapping. The signal is most likely not directly comparable anyway as the MODIS pixels are a lot bigger than the Landsat pixels (250 m x 250 m vs. 30 m x 30 m). To get a better understanding of how the time series actually looks like, we can interpolate the gaps in the time series using some standard processing options offered by the xtc package:</p> <pre><code>###\n# work with time-series object\n###\n\n# interpolate missing values\n\nls.NDVI.ts.ip &lt;- na.approx(ls.NDVI.ts)\nplot(ls.NDVI.ts.ip)\n\nmod.NDVI.ts.ip &lt;- na.approx(mod.NDVI.ts)\nplot(mod.NDVI.ts.ip)\n</code></pre> <p>Running this code will lead to the two following graphs:</p> <p> </p> <p>The interpolated time series look a lot smoother and it seems even possible to observe some trends in these new graphs. In the NDVI time series there seems to be one outlier in 2016 which does not seem to be very realistic and is most likely some sort of artefact in the raw data which was not detected by the automated pre-processing routines. In both time series, there seems to be an overall trend to increasing NDVI values. We can try to depict this trend a bit clearer by converting the high-frequency time series of approximately one observation every 16 days to an annual time-series. We can do this with the following code:</p> <pre><code># convert time series to yearly values\nls.NDVI.ts.y &lt;- to.yearly(ls.NDVI.ts)\nmod.NDVI.ts.y &lt;- to.yearly(mod.NDVI.ts)\n\n# plot yearly time series\n\nplot(ls.NDVI.ts.y)\nplot(ls.NDVI.ts.y$ls.NDVI.ts.High)\n\nplot(mod.NDVI.ts.y)\nplot(mod.NDVI.ts.y$mod.NDVI.ts.High)\n</code></pre> <p>This will in total lead to four plots:</p> <p> </p> <p>In the first and the third plot here, four trend lines are shown representing the first and the last NDVI value of the corresponding year (black and blue - could not find out yet which one is which) as well as the highest (red line) and lowest NDVI value (green line). In the second and forth plot, only the highest NDVI value of each year are depicted in a trend line. Here, the general increase in NDVI maxima is well depicted for the Landsat pixel, while a similar but weaker trend can be observed for the MODIS pixel.</p>"},{"location":"MSRS_1_GEE_basics/MSRS_1_GEE_basics/#step-7-ilias-exercise-find-a-pixel-with-decreasing-vegetation-trend-or-a-pixel-where-vegetation-disappeared-completely","title":"Step 7: ILIAS Exercise  - find a pixel with decreasing vegetation trend or a pixel where vegetation disappeared completely","text":"<p>You know now, how to extract a NDVI time-series for an individual pixel and we have learned above how to also interpolate and plot the corresponding time series. As we have so far only seen the time series signal for two pixels (one Landsat and one MODIS), we will play around with this a bit more in this exercise. The objective of the exercise is to identify a Landsat or a MODIS pixel in which a either a declining NDVI trend can be observed or the trend suggests that a vegetation area (showing the typical seasonal NDVI signal) has been transformed to another land-cover type (for example a comparable stable urban or bare soil signal which should show constantly low NDVI values). Please try to find such a pixel by changing the code above. Once you identified a pixel, make a screenshot of the time series and upload it to ILLIAS </p> <p>With this, we reach the end of this first Tutorial on remote sensing time-series analysis. Next week, we will learn how to directly prepare annual time-series datasets in the GEE engine and get to know some algorithms for analyzing (remote sensing based) time series objects in R.  </p>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/","title":"Preparing annual time series data stacks and conducting time series analysis","text":""},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#overview","title":"Overview","text":"<p>After getting to know the Google Earth Engine (GEE) in the last practical session of the course, you will today learn to use the GEE to manipulate the satellite image collections directly in the GEE cloud to derive an annual time series of Landsat NDVI values acquired only for certain months of a year. In comparison to what we learned last week, this requires some additional coding in the GEE environment. Exporting annual satellite image mosaics instead of simply exporting all available data (as we did last week), brings some advantages such as (a) the possibility to exclude seasonality from the signal, (b) to account for local data gaps by temporal interpolation and \u00a9 to notably reduce the size of the exported data.</p> <p>When preparing the material for this Tutorial, I came across a technical report of Pironkova et al. 2018 (you can find the document on ILIAS) which matches very well the contents I wanted to communicate in this tutorial. Hence, most of the code you will find below is based on the code provided by this technical report. I only added some lines of code, which I will describe further below. Please have a look at this technical report along with this Tutorial as you might find valuable additional information there.</p> <p>In the second part of the tutorial we will further process the the annual vegetation index time series in R to detect monotonic trends and change points. These steps were again mostly based on the analyses suggested in Pironkova et al. 2018 but I added one more analysis to conduct a Pettitt test to identify turning points. More information below.</p>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#learning-objectives","title":"Learning objectives","text":"<p>The learning objectives of this Tutorial include:</p> <ul> <li>deepening our capabilities to manipulate large amounts of satellite data in the GEE</li> <li>learn how to prepare and export annual vegetation index time series in the GEE (considering data only from certain phenological stages/time periods of the year)</li> <li>applying simple time-series analysis tests and trends in R to full images (instead of to single pixels)</li> </ul>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>The only dataset required in this Tutorial is a shapefile defining the boundary of the examined study area which is a grassland area on the Qinghai Tibetan Plateau in which notable grassland degradations took place over the last few decades. The Shapefile outlines the area of the winter pastures of a Tibetan village for which some in-depth studies have been conducted (see for example Li et al. 2017 - provided in ILIAS to some more detailed background information):</p> <p>-- add link to Shapefile here --</p>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#step-1-annual-ndvi-mosaics-in-the-gee","title":"Step 1: Annual NDVI mosaics in the GEE","text":"<p>Last week, we for the first time had a look at the GEE and I assume that you are all already familiar with the basic functionalities of the code editor. In the following, I will present step-by-step the code and functions that are necessary to derive annual mosaics of Landsat-based NDVI values. The code can of course easily be adapted to derive the same mosaics for other vegetation indices that can be derived from Landsat data.</p> <p>You might remember from last week, that typically the raw Landsat data are pre-processed to eliminate unwanted observation, such as pixels affected by clouds or snow. In this code example, we are working with today, these pre-processing steps are a bit more sophisticated and aside the cloud-mask functions, two more functions are used to eliminated saturated pixels (more than 100% reflectance) and areas affected by large aerosol concentrations. The corresponding functions either directly use the input bands for calculating NDVI (for the saturation function) or the pixel_quality band that is delivered with each atmospherically corrected Landsat scene (and which is avaiable if the surface reflectance products of Landsat are used in GEE). The corresponding codes in the GEE looks like this:</p> <pre><code>//--------------------------------------------//\n// 1. QA FUNCTIONS //\n//--------------------------------------------//\n//SATURATES MASK (L5/7)\nvar maskSaturate57 = function(image){\nimage = image.select('B3', 'B4');\nvar mask = image.lt(10000).and(image.gte(0));\nreturn image.updateMask(mask);\n}\n\n//SATURATES MASK (L8)\nvar maskSaturate8 = function(image){\nimage = image.select('B4', 'B5');\nvar mask = image.lt(10000).and(image.gte(0));\nreturn image.updateMask(mask);\n}\n\n//PIXEL MASK (L8)\nvar maskPixels8 = function(image){\nvar pixel_qa = image.select('pixel_qa');\nvar mask = pixel_qa.eq(322);\nreturn image.updateMask(mask);\n}\n\n//PIXEL MASK (L5/L7)\nvar maskPixels57 = function(image){\nvar pixel_qa = image.select('pixel_qa');\nvar mask = pixel_qa.eq(66);\nreturn image.updateMask(mask);\n}\n\n//AEROSOL MASK (L8)\nvar maskAerosol = function(image){\nvar aero_qa = image.select('sr_aerosol'); var mask = aero_qa.neq(194).and(aero_qa.neq(224)).and(aero_qa.neq(160)).and(aero_qa.neq( 130));\nreturn image.updateMask(mask); } \n//ATMOS OPACITY MASK (L5/L7) -to get rid of haze \nvar maskHaze = function(image){\n//Select band and multiply by scaling factor\nvar atmos_qa = image.select('sr_atmos_opacity').multiply(0.0010);\n//Mask for non-hazy pixels and remove fill vals\nvar mask = atmos_qa.lte(0.1).and(atmos_qa.gt(-9.9));\nreturn image.updateMask(mask)\n}\n</code></pre> <p>The next function are required for calculating the NDVI for Landsat 5,7 and 8 images:</p> <pre><code>//----------------------------------------------//\n// 2. NDVI FUNCTIONS //\n//----------------------------------------------//\n//NDVI FUNCTIONS\nvar getNDVI57 = function(image) {\n//Apply saturate function\nimage = maskSaturate57(image);\nvar nir = image.select('B4');\nvar red = image.select('B3');\nvar ndvi = nir.subtract(red).divide(nir.add(red)).rename('nd');\nreturn(ndvi);\n}\nvar getNDVI8 = function(image){ \n  //Apply saturate function \n  image = maskSaturate8(image); \n  var nir = image.select('B5'); \n  var red = image.select('B4'); \n  var ndvi = nir.subtract(red).divide(nir.add(red)).rename('nd'); \n  return(ndvi);\n}\n</code></pre> <p>These kind of functions should already look more or less familiar from last week's tutorial. One difference in comparison to last week is, that the bands are pre-processed wth the saturation function defined above, to avoid calculating the NDVI for pixels with impossible reflectance values.</p> <p>The next function addresses a known issue of the Landsat family: The bands of Landsat 5, 7 and 8 are all slightly shifted in terms of the spectral range. Hence, the NDVI values calculated for Landsat 5, 7 and 8 would not be completely identical even if they would observe exactly the same situation on the ground at the same time and under the exactly same conditions. The difference are not huge, but nevertheless they are there and some correction coefficents have been suggested to correct these differences between the NDVIs. The function below does exactly this to calibrate LS 8 and LS 5 values to LS 7:</p> <pre><code>//-----------------------------------------------//\n// 3. SENSOR CALLIBRATION FUNCTIONS //\n//-----------------------------------------------//\n//Coefficient Function (L5)\nvar applyCoefficientL5 = function(image){\nvar image_adjusted = image.select('nd').multiply(1.036);\nreturn(image_adjusted); } \n//Coefficient Function (L8) \nvar applyCoefficientL8 = function(image){\nvar image_adjusted = image.select('nd').multiply(1.0863);\nreturn(image_adjusted); }\n</code></pre> <p>After briefly explaining these helper-functions, we will not concentrate on the main function to create the annual NDVI mosaics. Please have a look through the code given below and check the additional explanations given directly in the code - I marked all parts which are meant to be modified by the user with comments and explanation marks.</p> <pre><code>//---------------------------------------------// \n// 4. MAIN FUNCTION // \n//---------------------------------------------//\nvar createNDVIComposite = function(){ \n  //Set year range \n  // !!!! Adjust the years you want to cover here !!!! //\n  var yearrangeStart = 1986; \n  var yearrangeStop = 2019;\n\n  // create an Image list to store the NDVI mosaic of each year (this part of the code\n  // with the Image list was added by myself)\n  var listfin = ee.Image([]);\n\n  //Loop through years\n\n  for(var loopYear = yearrangeStart; loopYear &lt;= yearrangeStop; loopYear +=1){\n\n    //Set year's date range //\n    // !!!! Adjust the time period you want to cover within each year here !!!! //\n\n    var start = ee.Date.fromYMD(loopYear, 6, 20); \n    var end = ee.Date.fromYMD(loopYear, 9, 25);\n\n\n    //Landsat 8 \n    // load Landsat 8 surface reflection collection and apply all\n    // pre-processing functions\n    // and calculate NDVI + apply sensor calibration coefficients\n\n    var l8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\n      //Filter AOI (imported at the top)\n      .filterBounds(MainProject)\n      //July and August only\n      .filterDate(start, end)\n      //Filter CLOUD_COVER\n      .filterMetadata('CLOUD_COVER', 'less_than', 80)\n      //Apply Pixel Mask\n      .map(maskPixels8)\n      //Apply Aerosol Mask\n      .map(maskAerosol)\n      //Calculate NDVI\n      .map(getNDVI8)\n      //Apply Sensor Callibration Coefficient\n      .map(applyCoefficientL8);\n\n\n    //Landsat7\n    // load Landsat 7 surface reflection collection and apply all\n    // pre-processing functions\n    // and calculate NDVI\n\n    var l7 = ee.ImageCollection(\"LANDSAT/LE07/C01/T1_SR\")\n      //Filter AOI (imported at the top)\n      .filterBounds(MainProject)\n      //July and August only\n      .filterDate(start, end)\n      //Filter CLOUD_COVER\n      .filterMetadata('CLOUD_COVER', 'less_than', 100)\n      //Apply Pixel Mask\n      .map(maskPixels57)\n      //Apply Haze Mask\n      .map(maskHaze)\n      //Calculate NDVI\n      .map(getNDVI57);\n\n\n    //Landsat5\n    // load Landsat 5 surface reflection collection and apply all\n    // pre-processing functions\n    // and calculate NDVI + apply sensor calibration coefficients\n\n    var l5 = ee.ImageCollection(\"LANDSAT/LT05/C01/T1_SR\") \n      //Filter AOI (imported at the top) \n      .filterBounds(MainProject) \n      //July and August only \n      .filterDate(start, end) \n      //Filter CLOUD_COVER \n      .filterMetadata('CLOUD_COVER', 'less_than', 100) \n      //Apply Pixel Mask \n      .map(maskPixels57) //Apply Haze Mask \n      .map(maskHaze) //Calculate NDVI \n      .map(getNDVI57) //Apply Sensor Callibration Coefficient \n      .map(applyCoefficientL5);\n\n\n    //Merge collections\n    var mergedCollection = ee.ImageCollection(l8.merge(l7).merge(l5));\n\n    //Create composite with median, clip to AOI and rename band based on year \n    var finalOutput = mergedCollection.reduce(ee.Reducer.median()).clip(MainProject).rename(loopYear.toString());\n\n    //Generate filename for export \n    var filename = (\"NDVI_Composite_\").concat(loopYear.toString());\n\n    // add mosaic of current year to image list    \n    listfin = ee.Image(listfin).addBands(finalOutput.rename(filename));\n\n  //end of loop\n\n    }\n\n    // print out the stacked image list to check how many mosaics are contained\n    print(listfin)\n\n    // convert all datasets to the same data type (LS8 has another datatype thatn LS5 and 7)\n    var listfin2 = listfin.toDouble()\n\n\n    // Export the stack of NDVI mosaics to Google Drive\n\n    Export.image.toDrive({\n    image: listfin2,\n    description: 'yearly_LS_ts',\n    //Landsat resolution is 30m\n    scale: 30,\n    region: MainProject,\n    //LCC_MNRF projection\n     crs: 'epsg:4326',\n    maxPixels: 800000000\n    })\n\n }\n</code></pre> <p>As we prepared the whole code with functions, we now have to run one more line of code to actually call the function that will create the annual mosaic:</p> <pre><code>var comp = createNDVIComposite();\nprint(comp)\n</code></pre> <p>Please also be aware that you additionally have to load and define the Shapefile with the boundary of the study area - otherwise, the code will return an error message. Try to find out yourself which variable name is referring to the Shapefile (Asset) in the code given above and then load the Shapefile (Asset) into the code and assign to the corresponding variable name yourself. In case you do not fully remember how to do this, please check last week's tutorial.</p> <p>You can access a fully functional version of the code here:</p> <p>https://code.earthengine.google.com/d9ec1f094d1a3f3cfd7f7531d0738eae?noload=true</p> <p>Please run the code and export the resulting annual mosaic to your google drive. We will use the data in Step 2 of the Tutorial. In case you have some sort of troubles running the code, you can access the resulting file also here:</p> <p>https://drive.google.com/file/d/1pMELTPLLL9pwsQZ1uY72vgs11hutWBdm/view?usp=sharing</p>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#step-2-mann-kenndal-trend-test-and-theil-sens-slope","title":"Step 2: Mann-Kenndal trend test and Theil Sen's slope","text":"<p>As indicated above, large parts of the following code were again taken from the technical report of Pironkova et al. 2018. The code has been mostly prepared by Krystal Lan (lan.krystalt@gmail.com) and Ryan Whaley (rdgwhaley@gmail.com). I changed and added a few lines here and there.</p> <p>First, we will load all the packages required for analysing our annual NDVI datasets. Please install the packages in case you do not already have them installed:</p> <pre><code># load all required packages\nrequire(raster)\nrequire(rkt)\nrequire(trend)\nrequire(zoo)\n</code></pre> <p>Next, we can set some global raster options which are quite useful. I do not typically use these settings but as it was included in the original code and I found the settings useful, I thought it makes sense to also keep them in the Tutorial:</p> <pre><code>rasterOptions(maxmemory=1e+06, chunksize=1e+07, progress = 'text')\n</code></pre> <p>With this commant, it is possible to change the general settings of the raster package, in this case two settings are referring to how the raster package handles memory (maximum amount of memory used as well as in which chunk size data is loaded when large files are being processed). This settings are quite interesting to adapt the raster package functionalities a bit to the processing power of the computer you are working with. Finally the command \"progress = 'text'\" will make the raster package always inform you about the status of the currently conducted calculation with a progress bar. I think this quite handy, particularly if waiting times sometimes are quite long and you are not sure whether the progress is still working of the computer has crashed.</p> <p>Next, we will load our annual Landsat based NDVI mosaics we just created sing the GEE and apply a Mann-Kendall-trend test to each pixel of our time series. First we load the data and prepare an output folder. We load the data with the command \"brick()\" as this will have some computational advances for some of the functions applied below.</p> <pre><code>##################################\n##MK-test + Seasonal and Regional Kendall tests (SKT / RKT) + Theil-Sen's Slope estimator\n##################################\n# Set working directory (location of rasters)\nsetwd(\"D:/Multiskalige_FE/5_Practicals/Tag_7_time_series\")\n# Set output directory (where the results will go)\nresults &lt;-\"D:/Multiskalige_FE/5_Practicals/Tag_7_time_series/Results\"\n# Stack rasters and then add them to brick\nbricked_files &lt;-brick(\"yearly_LS_ts.tif\")\n</code></pre> <p>Let's first have a look at our image time series by plotting it:</p> <pre><code>x11()\nplot(bricked_files)\n</code></pre> <p>This will results in a plot that looks more or less like this:</p> <p></p> <p>As you can see, not all of the bands (annual NDVI mosaics) contain data and for some of the years only parts of the study area have observations. For the moment, we will not do anything about this. This is also a somewhat expected outcome of how we calculated our mosaics.</p> <p>Next, we have to define a vector which contains the dates matching the satellite data's acquisition times. In this case a simple numeric vector with the years is sufficient. Even though the bands of the raster stack were renamed in the GEE  (I made some progress since the last Tutorial...), I did not yet find a way to access this information in R. If you load the \"yearly_LS_ts.tif\" in QGIS, you can see that the information is theoretically there:</p> <p></p> <p>However, I still have to figure out how to access these names in R - the typical \"names()\" command shows other filenames. If you have a close look at the Figure above, you will see that for three years of our time series, no mosaic was created. These are the years for which no cloud-free satellite acquisitions were available. So instead of 34 years (1986-2019) we only have 31 years in our time series. We don't have data for the years 1986, 1990 and 1993. We will manually account for this while creating the corresponding vector: </p> <pre><code># Set year range for analysis (number of years have to be the same as number of bands)\nyears2 &lt;-seq(1986, 2019)\nyears &lt;- years2[-c(1,5,8)]\n</code></pre> <p>Next, we will create a function to call the \"rkt()\" function of the rkt package for each pixel in the time series. This is a quite clever way of applying a function that was developed for vector data to a raster file. You will see how this works below. Check also the comments directly in the code. Be aware that our \"years\" variable is hard-coded in the function. So you should not change the variable name above and you should make sure, that the length of the year vector matches the number of bands of your raster file. This is particularly important if you want to apply the code also to other time periods and input data.</p> <pre><code># Analysis function\nrktFun &lt;-function(x) {\n  if(all(is.na(x))){        # if no data is available for the given pixel NA is returned as results\n    c(NA,NA,NA)\n  } else {\n    analysis &lt;-rkt(years, x)    # this executes the rkt function for a NDVI time series of an individual pixel\n    a &lt;-analysis$B # this will extract the results: theil sen slope\n    b &lt;-analysis$sl # this will extract the results: pvalue\n    c &lt;-analysis$tau # this will extract the results: Mann-Kendall tau\n    return(cbind(a, b, c)) # return all results\n  } }\n</code></pre> <p>After defining this function, it can be applied directly to our raster time series by using the following call:</p> <pre><code>rRaster &lt;-calc(bricked_files, rktFun)\n</code></pre> <p>Running the function in this way, will return the results of the rkt function also as raster files. The \"calc()\" function is hence an quite interesting generic tool to apply any type of function to a raster stack.</p> <p>You will see that applying the function to the raster stack will take some time. In case you activated the rasterOptions above, you should see a progress bar.</p> <p>The rkt function applies the Mann-Kendall-trend test to each of pixel and corresponding NDVI time series. As we learned in the theoretical lecture of the time-series chapter, the Mann-Kendall test is a non-parametric test that checks whether there is a monotonic trends in the provided dataset. It basically checks the relationship of the value of each  element of a time series in comparison to its neighbors. If there is a positive monotonic trend, neightbors following a given element in the time series should all have higher values, while elements at an earlier time point in the time series should have lower values. The function delivers three outputs: 1. The Theil-Sen slope (a non parametric approach to calculate the steepness of a trend line in a time series. It is calculated as the median slope of all slopes calculated between all possible point pairs), 2. the p-value which indicates the significance of the trend of the pixel according to the Mann-Kendall-test and finally the 3. the tau-values which indicates how strongly monoton the trend is. Be aware that you can have a very strong monotony in a trend but only a very low slope. This would mean that a value is increasing very stabiliy, but that the increase is very low. On the other hand, you can have a quite high slope but a rather low monotony becausethe curve is going up and down a lot. So the three pieces of information should always be interpreted together.</p> <p>With this three lines of code we save the results to a raster</p> <pre><code># Write to Results folder\nwriteRaster(rRaster[[1]], paste0(results,\"/ts_slope.tif\"), overwrite=T)\nwriteRaster(rRaster[[2]], paste0(results,\"/mk_pvalue.tif\"), overwrite=T)\nwriteRaster(rRaster[[3]], paste0(results,\"/mk_tau.tif\"), overwrite=T)\n</code></pre> <p>We can of course also plot the results:</p> <pre><code>plot(rRaster)\n</code></pre> <p>This will results in the following graph:</p> <p></p> <p>On the top left, we can see the Theil-Sen slope which is slightly positive for many parts of the study area but also shows some areas with strong negative trends. On the top right, we can see the p-values of the Mann-Kendall trend test, which indicate quite low values for most of the study area. Finally, we can see how monoton the trends are as represented in the Mann-Kendall tau value shown in the bottom left panel. In this case, the Theil-Sen slope and the tau values show quite comparable patterns, which indicates that all occurring changes happened rather continuously.</p> <p>In the next step, we will use the calculated p-values to mask out areas for which the identified trends were not significant. For this, we will first create three p-value masks with different significance levels:</p> <pre><code>##################################\n## 5. P-Value Masking ##\n##################################\n# Load tau raster\ntau &lt;-raster(paste0(results, \"/mk_tau.tif\"))\n# Set p-values to create masks for\np_values &lt;-c(0.01, 0.05, 0.1)\n# Loop through p-values, producing a mask for each\nfor(i in 1:length(p_values)){\n  # Load the P-value raster \n  p_value_raster &lt;-raster(paste0(results, \"/mk_pvalue.tif\")) \n  # Select current p-value \n  p_val &lt;-p_values[[i]] \n  # Create string vers for filenaming \n  p_val_str &lt;-gsub(\"\\\\.\", \"\", as.character(p_val)) \n  # Mask \n  p_value_raster[p_value_raster &gt; p_val] &lt;-NA \n  p_masked &lt;-mask(tau, p_value_raster) \n  # Write result \n  writeRaster(p_masked, paste0(results, \"/pvalue_mask\", p_val_str, \".tif\"),\n  overwrite = TRUE)\n# Cleanup\n}\n</code></pre> <p>Then, we can apply the three masks to our Mann Kendall-tau value raster files and save them. In this case, the tau values are further reduced to only areas showing comparably high tau values of greater than 0.4 or smaller than -0.4:</p> <pre><code>#############################################\n## 6. P-Value Masking with Significant Tau ##\n## Note: Must be run after section 5 ##\n#############################################\n\n# Isolate tau values &gt; 0.4 and &lt; -0.4\nsigTau &lt;-raster(paste0(results, \"/mk_tau.tif\"))\nsigTau[sigTau&gt;(-0.4) &amp; sigTau&lt;0.4] &lt;-NA\n# Loop through p-values, producing a mask for each\nfor(i in 1:length(p_values)){\n  # Select current p-value\n  p_val &lt;-p_values[[i]]\n  # Create string vers for filenaming\n  p_val_str &lt;-gsub(\"\\\\.\", \"\", as.character(p_val))\n  # Read current p-value raster\n  p_value_raster &lt;-raster(paste0(results, \"/pvalue_mask\", p_val_str,\".tif\")) \n  # Mask significant tau with p-value raster \n  tau_masked &lt;-mask(sigTau, p_value_raster) \n  # Write result \n  writeRaster(tau_masked, paste0(results, \"/tau_mask\", p_val_str, \".tif\"),\n  overwrite = TRUE) \n}\n</code></pre> <p>To have a look at the last created result (tau values with trends greather than 0.4 and a p-value of smaller than 0.1) we can run:</p> <pre><code>plot(tau_masked)\n</code></pre> <p>This will show the following plot:</p> <p></p> <p>The other results were stored to the harddisc and can either be loaded in R again or visualized in QGIS.</p>"},{"location":"MSRS_1_GEE_basics2/MSRS_1_GEE_basics2/#step-3-identify-turning-points","title":"Step 3: Identify turning points","text":"<p>As last step, we will analyse the annual NDVI mosaics to identify turning points using the pettitt-test. The pettitt test is a comparably simple test which is only able to identify the single, strongest turning point in a time series. We will continue using the already loaded datasets in R. To apply the test to the full raster-stack we will follow a different approach this time, as the due to the way the pettitt test is implemented in R, the calc()-function we applied above is not working smoothly with our dataset.</p> <p>However, there is a simple workaround to make test work with our dataset. As first step, we will transform our raster data into a matrix by running</p> <pre><code>vals &lt;- values(bricked_files)\nhead(vals)\n</code></pre> <p>running this code will result in the following output:</p> <p></p> <p>It is not important, that in this case all the values show NaN values, this is simply due to the fact that the borders of the image do not contain (as you can also see in the plots of the study area above). However, what is important to understand is that in the derived variable vals, each row contains the time series of a single pixel. Hence, we can now simply apply the pettitt-test to each of the rows using a for-loop and store the results:</p> <pre><code># create empty matrix to store results\nres &lt;- matrix(nrow=nrow(vals), ncol=2)\n\n# start looping through the pixels \nfor (i in 1:nrow(vals)){\n\n  # get time series of first pixel\n  x &lt;- vals[i,]\n\n  # check if there is data in the pixel\n  if(all(is.na(x))){\n\n    # if not, save NA, NA as result\n    res[i,] &lt;- c(NA,NA)\n\n  } else {\n\n    # if there is data, fill data gaps in the time series using simple interpolation\n    x1 &lt;- na.approx(na.approx(x))\n    # apply the pettitt test\n    analysis &lt;- pettitt.test(x1)\n    # extract the results\n    a &lt;-as.numeric(analysis$estimate)[1] # pettitt test (id at which time step the change occurred)\n    b &lt;-analysis$p.value \n    # save the results\n    res[i,] &lt;- cbind(a, b)\n\n  } \n  # print current iteration\n  print(i)\n}\n</code></pre> <p>The next step now is to re-copy the results (which are currently stored in a matrix) into the raster-format to re-construct the spatial information. To do this, we simply copy one of the bands of our time series dataset and the overwrite its values with the results of the pettitt test.</p> <p>For the p-values obtained for the pettitt-test we can do this by running the following code:</p> <pre><code># get a single raster band of the time series (does not matter which one)\npettitt.p.val &lt;- bricked_files[[1]]\n# overwrite the values of the raster band with the p-values obtained for the pettitt-test\n# this step only works because our results file has exactly the same number rows as the\n# raster has pixels\nvalues(pettitt.p.val) &lt;- res[,2]\n# plot the resulting raster\nplot(pettitt.p.val)\n</code></pre> <p>This will lead to the following plot:</p> <p></p> <p>We could run the exactly same code to obtain the main result of the pettitt test which is the id of the point in time series at which the turning point was identified. However, the id is currently a value between 1 and 31 (the number of observations in the annual time series of each pixel). More interesting for us would it be to directly have the year in which the change occurred. This requires that we overwrite the ids currently stored in the variable res[,1] with the corresponding years, stored in the \"years\" variable.</p> <p>To accomplish this we run the following code.</p> <pre><code># copy the results concerning turning points in a new variable\nturnp &lt;- res[,1]\n\n# change each of the id values to the corresponding year\nfor (i in 1:length(years)){\n\n  turnp[turnp==i] &lt;- years[i]\n  print(i)\n\n}\n</code></pre> <p>Subsequently, we follow the same strategy as above for the p-values to copy the final results back into a raster:</p> <pre><code># get a single raster band of the time series (does not matter which one)\npettitt.timep &lt;- bricked_files[[1]]\n# overwrite the pixel values with the results\nvalues(pettitt.timep) &lt;- turnp\n# plot the turning point raster\nplot(pettitt.timep)\n</code></pre> <p>This will results in the following plot:</p> <p></p> <p>Finally, we can mask out all pixels for which the pettitt test was not significant by first creating a p-value mask:</p> <pre><code>mask &lt;- pettitt.p.val &lt; 00.5\nplot(mask)\n</code></pre> <p>Which at the selected p-value looks like this:</p> <p></p> <p>And then apply the mask to the turning point raster:</p> <pre><code>timep_fin &lt;- mask(pettitt.timep, mask, maskvalue=0, updatevalue=NA)\nplot(timep_fin)\n</code></pre> <p>This will result in the final image of today's Tutorial:</p> <p></p>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/","title":"Geoprocesing and reference and coordinate systems","text":"<p>Dieses Tutorial zeigt Schritt f\u00fcr Schritt, wie man bestimmte Aufgaben wie das Lesen von Shapefiles, das Erstellen von Puffern, das Zusammenf\u00fchren von geometrischen Objekten, das Schneiden von Objekten und das Exportieren von Ergebnissen durchf\u00fchrt.</p>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#vorbereitung","title":"Vorbereitung","text":"<p>Im ersten Teil des Tutorials wird gezeigt, wie man die ben\u00f6tigten R-Pakete installiert und l\u00e4dt. Es wird auch gezeigt, wie man das Arbeitsverzeichnis einstellt und Shapefiles und ein Raster in R einliest.</p>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#installieren-der-benotigten-pakete","title":"Installieren der ben\u00f6tigten Pakete","text":"<p>Wenn sie noch nicht schon installiert sind, werden hier drei <code>R-Pakete</code> installiert: <code>sf</code>, <code>raster</code>, und <code>dplyr</code>.</p> <pre><code>if (!requireNamespace(\"sf\", quietly = TRUE)) {\ninstall.packages(\"sf\")\n}\nif (!requireNamespace(\"raster\", quietly = TRUE)) {\ninstall.packages(\"raster\")\n}\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) {\ninstall.packages(\"dplyr\")\n}\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#laden-der-benotigten-pakete","title":"Laden der ben\u00f6tigten Pakete","text":"<p>Nachdem die Pakete installiert wurden, m\u00fcssen sie noch geladen werden.</p> <pre><code>library(sf)\nlibrary(raster)\nlibrary(dplyr)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#das-arbeitsverzeichnis-setzen","title":"Das Arbeitsverzeichnis setzen","text":"<p>Das Arbeitsverzeichnis wird auf den Pfad der Daten gesetzt. <code>PFAD-ZU-DATEN</code> muss angepasst werden.</p> <pre><code>setwd(\"PFAD-ZU-DATEN\")\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#einlesen-der-shapefiles-im-arbeitsverzeichnis","title":"Einlesen der Shapefiles im Arbeitsverzeichnis","text":"<p>Hier werden mehrere Shapefiles im Arbeitsverzeichnis eingelesen und als <code>R-Objekte</code> gespeichert.</p> <pre><code>bezirke_ortsteile &lt;- st_read(\"bezirke_ortsteile.shp\")\nprotected_areas_berlin &lt;- st_read(\"protected_areas_Berlin.shp\")\nstra\u00dfen_berlin_haupt_utm &lt;- st_read(\"stra\u00dfen_berlin_haupt_utm.shp\")\nwasserschutzgebiete_berlin &lt;- st_read(\"Wasserschutzgebiete_Berlin.shp\")\nzufallspunkte_berlin_1 &lt;- st_read(\"Zufallspunkte_Berlin_1.shp\")\nzufallspunkte_berlin_2 &lt;- st_read(\"Zufallspunkte_Berlin_2.shp\")\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#einlesen-des-rasters-im-arbeitsverzeichnis","title":"Einlesen des Rasters im Arbeitsverzeichnis","text":"<p>Ein Raster im Arbeitsverzeichnis wird eingelesen und als <code>R-Objekt</code> gespeichert.</p> <pre><code>temperatur &lt;- raster(\"temperatur.tif\")\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#verarbeitung","title":"Verarbeitung","text":"<p>Im zweiten Teil des Tutorials werden verschiedene Verarbeitungsschritte durchgef\u00fchrt. Es werden beispielsweise Puffer erstellt, geometrische Objekte zusammengef\u00fchrt, Objekte geschnitten und ein Raster maskiert.</p>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#buffer-von-straen_berlin_haupt_utm","title":"Buffer von stra\u00dfen_berlin_haupt_utm","text":"<p>Hier wird ein Buffer von der <code>stra\u00dfen_berlin_haupt_utm</code> erstellt und als neues <code>R-Objekt</code> buffer gespeichert. Die Bufferbreite betr\u00e4gt <code>100</code> Meter und wird in <code>dist</code> angegeben.</p> <pre><code>buffer &lt;- st_buffer(stra\u00dfen_berlin_haupt_utm, dist = 100)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#merge-von-zufallspunkte_berlin_1-zufallspunkte_berlin_2","title":"Merge von Zufallspunkte_Berlin_1, Zufallspunkte_Berlin_2","text":"<p>Die beiden Objekte <code>zufallspunkte_berlin_1</code> und <code>zufallspunkte_berlin_2</code> werden zu einem Objekt zusammengef\u00fchrt und als neues <code>R-Objekt</code> merge gespeichert.</p> <pre><code>merge &lt;- st_union(zufallspunkte_berlin_1, zufallspunkte_berlin_2)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#dissolve-von-bezirke_ortsteile-mit-bezname","title":"Dissolve von bezirke_ortsteile mit BEZNAME","text":"<p>Die Polygone im Shapefile <code>bezirke_ortsteile</code> werden nach <code>BEZNAME</code> gruppiert, dann zu einem Polygon vereinigt, als neues <code>R-Objekt</code> dissolve gespeichert und in das Polygonformat konvertiert.</p> <pre><code>dissolve &lt;- bezirke_ortsteile %&gt;%\ngroup_by(BEZNAME) %&gt;%\nsummarize(geometry = st_union(geometry)) %&gt;%\nst_cast(\"POLYGON\")\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#union-von-wasserschutzgebiete_berlin-und-protected_areas_berlin","title":"Union von Wasserschutzgebiete_Berlin und protected_areas_Berlin","text":"<p>Die beiden Shapefiles <code>wasserschutzgebiete_berlin</code> und <code>protected_areas_berlin</code> werden zu einem Objekt zusammengef\u00fchrt und als neues <code>R-Objekt</code> gespeichert.</p> <pre><code>union &lt;- st_union(wasserschutzgebiete_berlin, protected_areas_berlin)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#clip-von-protected_areas_berlin-des-objektes-steglitz-zehlendorf-aus-dissolve","title":"Clip von protected_areas_berlin des Objektes \"Steglitz-Zehlendorf\" aus dissolve","text":"<p>Das Polygonobjekt <code>dissolve</code> wird nach dem Bezirk <code>Steglitz-Zehlendorf</code> gefiltert, und das Shapefile <code>protected_areas_berlin</code> wird dann auf das Polygonobjekt zugeschnitten und als neues <code>R-Objekt</code> clip gespeichert.</p> <pre><code>clip &lt;- st_intersection(protected_areas_berlin, dissolve[dissolve$BEZNAME == \"Steglitz-Zehlendorf\", ])\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#clip-des-temperatur-rasters-mit-dissolve","title":"Clip des temperatur Rasters mit dissolve","text":"<p>Das Raster <code>temperatur</code> wird auf das Polygonobjekt <code>dissolve</code> zugeschnitten und als neues <code>R-Objekt</code> <code>clip_raster</code> gespeichert.</p> <pre><code>clip_raster &lt;- mask(temperatur, dissolve)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#export","title":"Export","text":"<p>Im letzten Teil des Tutorials wird gezeigt, wie man die Ergebnisse in verschiedenen Formaten, wie Shapefiles oder Raster, exportieren kann.</p>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#export-der-shapefiles","title":"Export der Shapefiles","text":"<p>Die erstellten Shapefiles werden im Arbeitsverzeichnis als neue Dateien gespeichert.</p> <pre><code>st_write(buffer, \"buffer.shp\", overwrite = TRUE, append = TRUE)\nst_write(merge, \"merge.shp\", overwrite = TRUE, append = TRUE)\nst_write(dissolve, \"dissolve.shp\", overwrite = TRUE, append = TRUE)\nst_write(union, \"union.shp\", overwrite = TRUE, append = TRUE)\nst_write(clip, \"clip.shp\", overwrite = TRUE, append = TRUE)\n</code></pre>"},{"location":"gis/geoprocesing-and-reference-and-coordinate-systems/#export-des-rasters-clip","title":"Export des Rasters clip","text":"<p>Das erstellte Raster <code>clip_raster</code> wird im Arbeitsverzeichnis als neue Datei gespeichert.</p> <pre><code>writeRaster(clip_raster, \"clip_raster.tif\", format=\"GTiff\", overwrite = TRUE)\n</code></pre> <p>Hier werden die Ergebnisse der Verarbeitungsschritte als Shapefiles und Raster exportiert, die dann in anderen Anwendungen weiterverwendet werden k\u00f6nnen.</p>"},{"location":"landscape_metrics/landscape_metrics/","title":"Calculation of Landscape Metrics from a Land-cover raster map","text":""},{"location":"landscape_metrics/landscape_metrics/#overview","title":"Overview","text":"<p>In this lecture you will learn how to calculate landscape metrics from a land-cover map saved as a raster file in R. The idea is that you can later use the supervised classification results from the practical of the first day as input to this tutorial. However, for the tutorial itself, a dataset of four land-cover classification maps is provided. More details below.</p> <p>The learned processing steps include:</p> <ul> <li>load the land cover map to R</li> <li>calculate the landscape metrics for the entire raster image</li> <li>calculate the landscape metrics for subsets of the image to create a landscape metric map</li> </ul> <p>Besides R, we will also use QGIS in this tutorial.  In case you do not have QGIS installed, please download it at https://qgis.org/en/site/forusers/download.html and install it - this should be straightforward and all the necessary instructions are given on the webpage.</p>"},{"location":"landscape_metrics/landscape_metrics/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>In this tutorial we will use four land-cover maps that were created by a supervised classification. The four maps all show the same area around Karlsruhe with the same five land-use classes and at approximately the same point in time. However, the data from which the maps were derived differ and originate from three different satellite sensors:</p> <ol> <li>Sentinel 2: 10 m pixel size</li> <li>Landsat 8: 30 pixel size</li> <li>MODIS: 250 m pixel size</li> <li>MODIS: 500 m pixel size</li> </ol> <p>The data are available here:</p> <p>https://drive.google.com/drive/folders/1LULH7ur_wnZIcxlayWlE0EMbPElrAe0t?usp=sharing</p>"},{"location":"landscape_metrics/landscape_metrics/#step-1-getting-familiar-with-the-dataset","title":"Step 1: Getting familiar with the dataset","text":"<p>We will now first have a look at the data that we are working with. So please download the dataset given at the link above unzip the files and then open the QGIS project by double-clicking the file</p> <p>overview_results_4_skalen.qgz</p> <p>Now QGIS should open and show the following:</p> <p></p> <p>The QGIS project shows the four land-cover classification maps we will be using in the Tutorial. You can browse through the other three maps by activating the layers in the \"Layer\" window on the lower left in QGIS. Currently, the data with the highest spatial resolution (\"grain\") is depicted. If you activate the mod500_classification layer, the view in QGIS will look seen below and you can easily see the difference in spatial resolution (\"grain\") between the two land-cover maps. Despite the grain differences, you can still see that the two maps show roughly the same patterns in terms of land-cover patterns with the big forest area at the center left, larger water areas in the western part of the map and a mosaic of all land-cover classes in the eastern part of the map- </p> <p></p> <p>Please have a look also at the two other provided maps which have spatial resolutions between the two depicted datasets. Next, we will load the data into R and start calculating the landscape metrics for the complete image.</p>"},{"location":"landscape_metrics/landscape_metrics/#step-2-load-the-land-cover-maps-to-r-and-plot-them","title":"Step 2: Load the land cover maps to R and plot them","text":"<p>First, we will load all required packages. R will give you a warning message in case a package is not installed yet. If this is the case, please install the packages either through the main menu of Rstudio by selecting \"Tools\" =&gt; \"Install packages\" and then following the appearing dialogue, or by entering the corresponding R code to install the packages into the console. E.g., to install the package \"raster\" use the code:</p> <pre><code>install.packages(\"raster\")\n</code></pre> <p>After loading the packages by running:</p> <pre><code># load requires packages\nrequire(raster)\nrequire(SDMTools)\nrequire(doParallel)\nrequire(foreach)\n</code></pre> <p>After all packages are successfully installed, we will load the land cover raster maps using two steps. First, change the path to the folder containing the image, then execute the \"raster\" command to load the image. To check whether you are in the correct folder, you can display all files of the folder using the list.files()-command. In this case it is important to use the \"raster\" command instead of the \"stack\" command due to the input format required by the function we will use to calculate the landscape metrics. </p> <pre><code>## load land-cover maps derived from S2\n\n# set working directory to the folder where you stored the data for the tutorial\nsetwd(\"E:/Tag2_landscape_metrics/\")\nlist.files()\n\n# load the land cover classification raster maps\ns2_luc &lt;- raster(\"s2_classification.tif\")   \nls_luc &lt;- raster(\"ls_classification.tif\")\nmod250_luc &lt;- raster(\"mod250_classification.tif\")\nmod500_luc &lt;- raster(\"mod500_classification.tif\")\n</code></pre> <p>To check whether the data has been loaded correctly, we can briefly plot the four maps using the following commands:</p> <pre><code># open a new display window\nx11()\n\n# change plot settings to plot all four plots in one window using 2 columns and 2 rows\npar(mfrow=c(2,2))\n\n# plot the images\nplot(s2_luc)\nploz(ls_luc)\nplot(mod250_luc)\nplot(mod500_luc)\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>If we prefer to invest a bit more time into the plot to allow for an easier interpretation of the landcover classes, we can make it look a bit more like in the QGIS visualization that we saw before by running the following code:</p> <pre><code>## alternative, nicer-looking plot\n\n# open a new display window\nx11()\n\n# change plot settings to plot all four plots in one window using 3 rows and 2 columns\npar(mfrow=c(2,3))\n\n# prepare coloring\ncuts=c(0,1,2,3,4,5) #set breaks\npal &lt;- colorRampPalette(c(\"darkgreen\", \"blue\", \"brown1\", \"chartreuse2\", \"darkgoldenrod1\"))\n\n# plot the images\nplot(s2_luc, breaks=cuts, col = pal(5), legend=F)\nplot(ls_luc, breaks=cuts, col = pal(5), legend=F)\nplot(mod250_luc, breaks=cuts, col = pal(5), legend=F)\nplot(mod500_luc, breaks=cuts, col = pal(5), legend=F)\n# plot dummy to include legend\nplot(mod500_luc, col = \"white\", axes=F, ann=F, xaxt=\"n\", yaxt=\"n\", box=F, legend=F)\n#plot legend\nlegend(\"bottomleft\", legend=c(\"Forest\",\"Water\",\"Urban\",\"Grassland\", \"Bare soil\"),fill=c(\"darkgreen\", \"blue\", \"brown1\", \"chartreuse2\", \"darkgoldenrod1\"))\n</code></pre> <p>This will look like this:</p> <p></p>"},{"location":"landscape_metrics/landscape_metrics/#step-3-calculate-landscape-metrics-for-the-entire-image","title":"Step 3: Calculate landscape metrics for the entire image","text":"<p>After successfully loading and plotting the images, we will now calculate the landscape metrics for each image. We will accomplish this using the SDMTools packages and the \"ClassStat\" and the \"PatchStat\" functions. The two functions only require the input raster (expected is a categorical raster file) and a user-defined cellsize, which in our case will be the spatial resolution of the corresponding satellite sensors. We can calculate the landscape metrics by running the following lines:</p> <pre><code># calculate class-stats for each image\nmetr_s2 &lt;- ClassStat(s2_luc, cellsize=10)\nmetr_ls &lt;- ClassStat(ls_luc, cellsize=30)\nmetr_mod250 &lt;- ClassStat(mod250_luc, cellsize=250)\nmetr_mod500 &lt;- ClassStat(mod500_luc, cellsize=500)\n\n# calculate patch-stats for each image\npatch_s2 &lt;- PatchStat(s2_luc, cellsize=10)\npatch_ls &lt;- PatchStat(ls_luc, cellsize=30)\npatch_mod250 &lt;- PatchStat(mod250_luc, cellsize=250)\npatch_mod500 &lt;- PatchStat(mod500_luc, cellsize=500)\n</code></pre> <p>This calculation may take a few seconds. Once they are ready, we will be able to have a look at the calculated metrics and also make some comparisons between the four land-cover maps.</p> <p>First of all we are interested in what kind of metrics were calculated. To see the names and the definitions of the calculated metrics, we can have a look at the details of the applied functions by running the code:</p> <pre><code>?ClassStat\n?PatchStat\n</code></pre> <p>For simply seeing the names of the metrics, we can also run:</p> <pre><code>colnames(metr_s2)\ncolnames(patch_s2)\n</code></pre> <p>Now, let us have a closer look on what has actually been calculated. If we simply run the objects that were created by calling the functions, we can see that all landscape metrics have been calculated for all of the five land-cover classes in the image. Running:</p> <pre><code>metr_s2\n</code></pre> <p>will result in:</p> <p></p> <p>Here, it becomes clear that for each class and landscape metric, a single value is given. Some of the metrics are quite easy to interprete such as \"prop.landscape\" which simply  indicates the fractional cover of the land-cover class in the complete image. Hence, in this case, the values of all five classes should add-up to 1. For understanding also the other metrics, it is recommended to have a closer look at the details provided in the descriptions of the r-package and the citations given there.</p> <p>We will now try to make some comparisons of values between the four input land-cover datasets with varying spatial resolution. To do this, we will create some bar plots. To get the plots, we first have to select which landscape metric we want to have a look at and then the land-cover class for which we want to compare the values:</p> <pre><code>metric=10\nluc_class=2\n</code></pre> <p>Remember, for getting the names of the calculated landscape metrics we can run:</p> <pre><code>colnames(metr_s2)\n</code></pre> <p>If we want to know how the 10th calculated metric is called, we can also run:</p> <pre><code>colnames(metr_sw)[10]\n</code></pre> <p>Now, lets plot some comparative barplots to always compare the values of landscape metric 10 (mean patch area) calculcated for land cover class 2 (water) of Landsat with the three other input datasets:</p> <pre><code># selected metric and class\nmetric=10\nluc_class = 2\n\n# make plots\nx11()\npar(mfrow=c(1,3))\nbarplot(c(metr_ls[luc_class,metric], metr_s2[luc_class,metric]), xlab=\"Landsat vs. S2\", main=paste0(colnames(metr_ls)[metric]), cex.axis=1.5, cex.lab = 1.5)\nbarplot(c(metr_ls[luc_class,metric], metr_mod250[luc_class,metric]), xlab=\"Landsat vs. MODIS 250 m\", main=paste0(colnames(metr_ls)[metric]), cex.axis=1.5, cex.lab = 1.5)\nbarplot(c(metr_ls[luc_class,metric], metr_mod500[luc_class,metric]), xlab=\"Landsat vs. MODIS 500 m\", main=paste0(colnames(metr_ls)[metric]), cex.axis=1.5, cex.lab = 1.5)\n</code></pre> <p>This will result in:</p> <p></p> <p>We can see that even though we calculated the same metric, for the same class and the same landscape with the same extent, the differences in spatial resolution of the input datasets, leads to quite strong differences in mean patch area. The differences are stronger, the stronger the resolution differences are. However, this of course also depends on the applied metric and land-cover class. You can now try to make some more comparisons, by changing the variables metric and luc_class in the code and then re-run the plot command.</p>"},{"location":"landscape_metrics/landscape_metrics/#step-4-calculate-landscape-metrics-for-a-grid","title":"Step 4: Calculate landscape metrics for a grid","text":"<p>So far, we calculated a single landscape metric for the whole land-cover map. In our case, the landscape is still comparably small in size so calculating a single metric for the whole landscape, may make sense for some applications. However, in many other cases, we might either have a larger landscape at hand or we might be interested to also see how our landscape varies in terms of its metrics at a finer spatial grain as compared to the complete landscape. In the following, we will adjust the code used above to calculate landscape metrics for smaller sub-parts of the land-cover maps.</p> <p>This will require that we put the calculation into a loop and before running this loop we will have to create a  grid with a user-defined grid cell size. In the following, the code will be presented step by step. First we define the grid-cell size:</p> <pre><code># define a tile size for which you want to compute the landscape metrics\ntile_size &lt;- 500\n</code></pre> <p>In our case this would mean 500 m - but this will depend on the applied coordinate reference system. As we are using data in the metric UTM coordinate reference system, the 500 is fine. It would be more complicated when using the geographic coordinate system with Latitude and Longitude as in this case the grid cell size would have to be defined in geographic degrees. Next, we define the input dataset for which we want to create the grid and extract its extent. In this case, we will use the land-cover map derived from Sentinel-2</p> <pre><code># define the land-use map you want to use as input\ninp &lt;- s2_luc\n\n# use extent of raster layer to prepare grid cells\n# with the tile size defined above \ne &lt;- extent(inp)\n\n# check what e looks like by running\ne\n</code></pre> <p>This will result in the following:</p> <p></p> <p>We can see that the variable e contains the outer margins of our input image with minimum and maximum x and y coordinates, respectively. From this, we will now derive the total width and height of the area the image is covering by running (the results will be in meter as we are in the metric coordinate system):</p> <pre><code># get x and y ranges\nx_ra &lt;- (e[2]-e[1]) \ny_ra &lt;- (e[4]-e[3])\n</code></pre> <p>Then we will set the grid-cell size by assigning the user-defined value from above to two variables, representing the x and y direction. The two variables will be required in the code below. Be aware that we in theory could also use non-quadratic grid cells, but for now, let's just stay with the quadratic cells.</p> <pre><code># set x,y lengths of grid to user defined tile size\nx_r &lt;- tile_size\ny_r &lt;- tile_size\n</code></pre> <p>Now we are ready to run a nested for-loop to create the grid cell coordinates:</p> <pre><code># create list to store the results of the tile coordinates\ncases &lt;- list()\n\n# create coordinates of all tiles\niter=1\nfor (i2 in 1:(floor(x_ra/x_r))) {\n  for (i in 1:(floor(y_ra/y_r))) {\n\n    e &lt;- extent(inp)\n    e[1] &lt;- e[1] + (i2-1)*x_r\n    e[2] &lt;- e[1] + x_r\n    e[3] &lt;- e[3] + (i-1)*y_r\n    e[4] &lt;- e[3] + y_r\n    cases[[iter]] &lt;- c(e[1], e[2], e[3], e[4])\n    iter = iter+1\n  }\n}\n\n# unbind tile coordinate list\ncases2 &lt;- do.call(rbind, cases)\n# asign meaningful colnames\ncolnames(cases2) &lt;- c(\"xmin\", \"xmax\", \"ymin\", \"ymax\")\n# check final coordinate list\nhead(cases2)\n</code></pre> <p>I will not get into details here about what this code is doing exactly, but feel free to explore the code a bit more. In short, this code will return a list of coordinate-sets defining the 500 m grid-cells for which we will calculate our landscape metrics. The last r command in the code head(cases2) will result in:</p> <p></p> <p>So you can see that each row in the \"cases2\"-variable has the same structure as the \"e\" variable from above and basically describes the outer margin of a single grid-cell.</p> <p>OK! Now let's calculate the metrics for the grid. In the following, we will run the code in a parallelized script. This will enable a notably faster processing time, if the computer has more than one cpu/core available. To do this, we only have to change some parts of the code in comparison to a normal for-loop. Again, I will not go into details here, but in case you are interested in how this works exactly, you can get some first information here:</p> <p>https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf</p> <p>Now, let us have a look at the code. First, we start the process by initalizing the parallel processing:</p> <pre><code>#setup parallel backend to use more than one processors\n\n# define number of cores (you can switch the value to a higher numer of your computer has more cores)\n# for checking how many cores your computer has you can run: detectCores()\nncors=2\ncl&lt;-makeCluster(ncors)\nregisterDoParallel(cl)\n\n# get timestamp to see how long the process takes\nprint(timestamp())\n</code></pre> <p>At this point the pure processing part begins. The processing is devided into four steps. First, the extent of the i-th grid cell is defined by taking the i-th row from the variable cases2 created above. Second, the raster image is clipped with the extent. Third, landscape metrics are caclulated for the clipped raster-subset. Fourth, all metrics are merged into a single variable cstat2 and center coordinates of the current grid cell are added to this variable (to allow for copying the information back to a raster later on). This variable is then returned and the next iteration is started:</p> <pre><code>rs &lt;- foreach(i=1:length(cases2[,1]), .packages=c(\"raster\", \"SDMTools\")) %dopar% {\n\n  # create an extent file using the coordinates from the coordinate list\n  e2 &lt;- extent(cases2[i,1], cases2[i,2], cases2[i,3], cases2[i,4])\n  # crop the large image to the tile\n  img &lt;- crop(inp, e2)\n\n  # calculate landscape metrics for the file\n  cstat &lt;- ClassStat(img, cellsize = 10)\n  cstat1 &lt;- PatchStat(img, cellsize = 10)\n\n  cstat2 &lt;- cbind(cstat, cstat1)\n\n  # transform results to dataframe\n  cstat2 &lt;- as.data.frame(cstat2)\n\n  # attach mean x and y coordinates to the results for comfortable plotting afterwards\n  x_mean &lt;- (cases2[i,1] + cases2[i,2])/2\n  y_mean &lt;- (cases2[i,3] + cases2[i,4])/2\n\n  cstat2$xm &lt;- rep(x_mean, length(cstat2[,1]))\n  cstat2$ym &lt;- rep(y_mean, length(cstat2[,1]))\n\n  #patch\n\n  #return final dataframe to store in list\n  cstat2\n\n}\n\n# stop parallel processing\nstopCluster(cl)\n\n#get another timestamp to see how long it tood\nprint(timestamp())\n</code></pre> <p>After landscape metrics have been calculated for all grid cells, the raw output data has to be further processed to transfer them back into raster files. The result of the for-loop described above are stored in a variable called \"rs\" which is in the list-format of R. As first step, we transfer this list into a dataframe by applying the rbind-function to all entries in the list:</p> <pre><code># check first results\nhead(rs)\n# bind all results to have one large dataframe\nrs_fin &lt;- do.call(rbind, rs)\n\n#check final results\nhead(rs_fin)\n</code></pre> <p>This results in:</p> <p></p> <p>Next, we extract one of the landscape metrics for one of the five examined land-cover classes and save it as a raster file. In theory all calculated metrics could be saved using the same procedure with some small adaptations to the code. In the code below we select the landcover class 1 which is forest. Details are provided in the comments to the code.</p> <pre><code>##################################################\n## start postprocessing results\n##################################################\n\n## extract number of patches for yth land-use class\n\ndev.off()\n\n# select land-cover class (1 = forest)\nluc_class=1\n\n# subset the overall results to only keep values of the selected land-cover class\nrs_fin_cl &lt;- rs_fin[rs_fin$class==luc_class,]\n\n# check the available metrics\ncolnames(rs_fin_cl)\n\n# select one metric - in this case metric 4 which is the percentage cover of the target class\n# in a given grid cell \nmetric = 4\n\n# prepare map of percentage cover of forest\n# to do this, first build a table including the center coordinates of each grid cell\n# and the selected metric\ninp_ras &lt;- cbind(rs_fin_cl$xm, rs_fin_cl$ym, rs_fin_cl[,metric])\n\n# then use the rasterfromXZY-function to create a raster file\ndfr &lt;- rasterFromXYZ(inp_ras)\n\n# copy the coordinate reference system information to transfer the raster to a\n# raster with geoinformation\ncrs(dfr) &lt;- crs(ls_luc)\n\n# plot the map\nplot(dfr, main=colnames(rs_fin_cl)[metric])\n\n# save result to tiff-file that can be opened in QGIS\nwriteRaster(dfr, \"prop_forest_area.tif\", format=\"GTiff\", overwrite=T)\n</code></pre> <p>We have now calculated a first landscape metric-map in R. We can check our results by loading the just created prop_forest_area.tif file into our QGIS project from the start of the tutorial. If we now compare the land-cover map with the percentage cover raster we calculated (depicted below after adapting the visualization settings), we can see that the results seem plausible. Grid cells covered only by forest have a 100% cover (value of 1) while areas with only smaller fractions of forest, show the corresponding values:</p> <p> </p> <p>You can see in the QGIS project that the current processing flow is not yet perfect, as we are losing a small part of the image edges (the created raster does not have exactly the same size as the input image). This is not fully solvable as long as the x- and y-ranges of the input image are not evenly dividable by the selected grid cell size. Related problems have been discussed in the theoretical part of today's course session. </p> <p>So you have now learned all the processing steps required to calculate landscape metrics from a land-cover map in R. For training and better understanding the code, I would recommend to adjust the code above a bit to calculate some more landscape metrics and also compare metrics amongst the different input-datasets with varying spatial resolution. In next week's practical exercise you will have to use the work-flow learned here, to solve a small ecological question.</p>"},{"location":"planetary-sciences/01-download-ls-and-s2/","title":"Download of Landsat and Sentinel satellite images","text":"<p>Abstract  In this Tutorial we will learn how to download multispectral satellite images of Landsat and Sentinel-2 sensors. We will also learn how to pre-process the satellite images in order to load them in QGIS or Python. For pre-processing Sentinel-2 images we will use the European Space Agency's BEAM software which you can download here:</p> <p>Download SNAP software</p>"},{"location":"planetary-sciences/01-download-ls-and-s2/#download-landsat-data-from-the-earthexplorer-portal-of-the-usgs","title":"Download Landsat data from the EarthExplorer portal of the USGS","text":"<p>For downloading Landsat images, several web-portals exist. However, from my experience, the by far most comfortable option is the earthexplorer webpage of USGS. A very good video-tutorial on how to download Landsat satellite imagery is provided here:</p> <p>Download Landsat images from the USGS earth explorer website</p> <p>Please have a look at the video and download a Landsat 8 or Landsat 9 image from the year 2022 from any location of the world, that you are interested in. Make sure that you download an image of Collection 2 Level 2.  One small tip: It will be easier to find a suitable (cloud-free) image if you focus on a region of the Earth that is not permanently clouded (tropical areas are often tricky).</p> <p>When following the instructions in the video, please additionally consider the following remarks:</p> <ol> <li> <p>Contrarily to what is said in the video, I would recommend to always download the packaged file (and not the individual bands) if you have a decent internet connection - this will be less complicated and you will make sure that you indeed download all files that you need.</p> </li> <li> <p>Be aware that depending on the time period you indicate at the beginning of the process, images from some Landsat sensors may not be available since the Landsat sensors all operated for a certain time period as indicated in Table 1. That is, if you want to download an image from 2022, you will only be able to download images from Landsat 7,8 and 9 since the other sensors were not operating anymore in 2022.</p> </li> <li> <p>When working with the downloaded data, it is extremely important to understand the processing level of the data which depends on selected Level and Collection. You can find more information on this here. Having a closer look at those details is very valuable as it will enable you to fully understand what the downloaded files contain (e.g., the physical unit and the scaling in which the information in the bands is stored, etc.). We will get back to this later on.</p> </li> </ol> <p>Table 1: Landsat sensors operation time</p> Sensor Operation time Landsat 1 1972-1978 Landsat 2 1975-1982 Landsat 3 1978-1983 Landsat 4 1982-1993 Landsat 5 1984-2013 (!!) Landsat 7 1999-today Landsat 8 2013-today Landsat 9 2021-today"},{"location":"planetary-sciences/01-download-ls-and-s2/#download-sentinel-2-data-from-esas-open-science-hub","title":"Download Sentinel-2 data from ESA's open science hub","text":"<p>Similarly as in the case of Landsat, there is also a comparably comfortable (even though slightly less comfortable than the earthexplorer page - at least in my opinion) webpage to download Sentinel-2, as well as Sentinel-1 and 3 images. You can find the webpage here.</p> <p>Once again, there is a very good video available with instructions on how to download Sentinel-2 images from the webpage: Download Sentinel-2 images from the ESA science hub website </p> <p>Please have a look at the video and download a Sentinel-2 image from the approximately same time period and location as you chose for the Landsat image. Be aware that Sentinel-2 images are only available starting from mid-2015. </p> <p>Make sure that you save the Landsat and Sentinel-2 files at a location on your computer that you are able to find again afterwards.</p> <p>Once we have downloaded the images, we will continue with some simple pre-processing steps to save both images as multi-layer geotiff-files which we can then use in Python or QGIS (as already learned in the GIS-practicals of the course). We will apply different pre-processing work-flows for Landsat and Sentinel-2 and while there are also options available to perform the pre-processing steps directly in Python, we will here first learn the basic option using SNAP for the Sentinel-2 image and QGIS for the Landsat image.</p>"},{"location":"planetary-sciences/01-download-ls-and-s2/#pre-process-the-landsat-image-into-a-multi-layer-geotiff-file-using-qgis","title":"Pre-process the Landsat image into a multi-layer geotiff file using QGIS","text":"<p>After downloading the Landsat 8 or 9 image from the earthexplorer webpage and extracting the archive file on your hard-disc you should have a file folder similar to the one shown in Figure 1. Extracting an archive file typically works by performing a right-click on the downloaded file and then select some option related to \"extract files\" - in case you cannot open the downloaded files, you might have to install a (de-)compression software tool first - you can for example use \"7zip\" (=&gt; simply google, download and install it). </p> <p> </p> Figure 1: Files of a Landsat-image after extraction <p>The extracted files include numerous meta-data files as well as the actual remote sensing data. The most important files are the image files containing the spectral values observed by the spectral channels of the satellite sensor. These images can be identified by their ending:</p> <p><code>..._SR_B*.TIF</code></p> <p>where the * takes values between 1 and 7 for the bands 1 to 7 of Landsat 8 (in my case). That is, B stands for \"Band\" while SR stands for \"surface reflectance\". This is the case because I downloaded level 2 data which have already been atmospherically corrected, that is the radiance measured at the sensor has been converted to surface reflectance. We will learn more about this in one of the next lectures.</p> <p>Additionally, a band with ending</p> <p><code>..._ST_B10.TIF</code></p> <p>is available which represents the thermal band of Landsat with ST standing for \"surface temperature\".</p> <p>The exact physical units and scaling of the data contained in the images can be checked in the official product descriptions of the Landsat sensors. For the image I have downloaded, the corresponding information can be found in the report provided here.</p> <p>It is highly recommended to have a closer look at these reports and you will have to do this to answer some of the questions asked below.</p> <p>For now, we will focus on the spectral bands containing surface reflectance information (bands are marked in red in Figure 1. ). We will now use QGIS to stack these bands and save them into a single multi-layer/band geotiff file.</p> <p>To do this we open the Toolbox in QGIS (if not already open) by selecting:</p> <p><code>Processing (in the main file menu) \u21d2 Toolbox</code></p> <p>Then we search for the keyword \"merge\" in the toolbox window as shown in Figure 2.</p> <p> </p> Figure 2: Find the GDAL-merge tool <p>In the list of returned tools, we select the \"merge\" tool listed under GDAL \u21d2 Raster miscellaneous and double click-it to open it (tool is selected in Figure 02).</p> <p> </p> Figure 3: The GDAL-merge tool <p>In the upcoming dialogue shown in Figure 3, we will then have to add the 7 Landsat channels containing the spectral values observed by the satellite sensor. For this we press the \"...\" - button next to the \"input Layers\" section. </p> <p> </p> Figure 4: Adding bands to the merge tool <p>The menu will change to a new window as shown in Figure 4. Here, we will now press the \"Add File(s)\" button (marked with 1 in Figure 4) and select the 7 spectral bands with the endings <code>_SR_B*.TIF</code> as marked in Figure 1 and confirm with \"open\". Make sure that the order is also correct with B1 being the first/top band and B7 the last/bottom. If everything is correct, use the \"arrow button\" marked with 2 in Figure 4 to return to the main menu of the \"merge\" tool.</p> <p> </p> Figure 5: Applying  the merge tool <p>As last step we select the option \"Place each input file into a separate band\" and define an output filename and path (as marked with 1 and 2 in Figure 5). Then we click \"run\" to merge the 7 bands into a single multi-layer/band geotif-file.</p> <p> </p> Figure 6: The resulting merged multi-band image <p>This should result in a view similar as in Figure 6 - even though the actual view might of course be very different depending on which image you downloaded. With some adjustment of the visualization settings with which you should already be familiar with from the GIS-parts of the course we can obtain a RGB-view of the satellite images, mimicking the visual impression we have as humans (Figure 7).</p> <p> </p> Figure 7: The resulting merged multi-band image in RGB view <p>You should now be able to pre-process and visualize Landsat images in QGIS. This is a really interesting skill, considering that Landsat images are available since 1972 and for the complete globe. The number of bands to merge and the visualization settings will differ depending on the Landsat sensor with which the data was collected, but you will always be able to understand which bands you have to add to your image stack if you refer to the Landsat product guides which you can find under the links above.</p>"},{"location":"planetary-sciences/01-download-ls-and-s2/#pre-process-the-sentinel-2-image-into-a-multi-layer-geotiff-file-using-snap","title":"Pre-process the Sentinel-2 image into a multi-layer geotiff file using SNAP","text":"<p>After downloading the Sentinel-2 image and extracting the archive file on your hard-disc you should have a file folder similar to the one shown in Figure 8. </p> <p> </p> Figure 8: Files of a Sentinel-2 image after extraction <p>In case of Sentinel-2, the situation is even more complex than with Landsat and not only numerous files are visible but there are even several sub-folders containing meta-data as well as the original image files. As already shown in the download-video, the actual image files of the Sentinel-2 image can be found in of the subfolders which in my case is named:</p> <p><code>GRANULE\\L1C_T18QXJ_A027836_20220705T153624\\IMG_DATA</code></p> <p>The bands are saved in jpeg2000 format which is a compressed format which, however, does not lose any information.</p> <p>The jpeg2000-format is a not that common format and hence, it might be desirable to save the data in a different format such as geotif which can be opened by most software for processing geodata. Besides the data format we have to consider as well that not all bands of Sentinel-2 have the same spatial resolution. There are four bands at 10 m spatial resolution (pixel size) and 6 bands at 20 m spatial resolution. Furthermore, there are two bands with 60 m spatial resolution. The latter are mostly used to inform atmospheric correction algorithms.</p> <p>The typical procedure to pre-process Sentinel-2 images hence includes to build a subset of only the bands with 10 and 20 m spatial resolution, stack them, resample some of the bands and save all bands into a multi-layer/band file with either 10 or 20 m pixel size.</p> <p>The probably easiest way to accomplish these pre-processing steps is to use the SNAP toolbox of the European Space Agency. SNAP is a quite complete free and open-access toolbox which offers numerous tools to visualize and analyse remote sensing data. In the following, we will not explore all options that are available in SNAP, but if you are interested in getting to know the software a bit better, there are numerous resources on the web, including the tutorials on the official webpage</p> <p>As well as some inofficial youtube-videos such as.</p> <p>Here, we will only get to know the steps necessary to load the S2-image into SNAP and save the image into a multi-layer/band geotif file.</p> <p>For this we first open SNAP. In the main menu of SNAP we select </p> <p><code>File \u21d2 Import \u21d2 Optical Sensors \u21d2 Sentinel-2 \u21d2 S2-MSI L1C</code></p> <p>as shown in Figure 9.</p> <p> </p> Figure 9: Files of a Sentinel-2 image after extraction <p>In the upcoming dialogue, we now browse to the folder which contains our extracted and downloaded Sentinel-2 dataset. Here, we then select the .xml file which IS NOT CALLED \"Inspire.XML\". The name of the file is always different and depends on the downloaded image. In my case the file we have to open is called \"MTD_MSIL1C.xml\".</p> <p>We select the file and confirm with \"Import Product\" (see Figure 10).</p> <p> </p> Figure 10: Files of a Sentinel-2 image after extraction <p>After a few seconds the Sentinel-2 image will appear in the Product-Explorer window on the left in the SNAP user interface. We can expand the menus (by clicking the buttons marked in red in Figure 11) to get a better idea of what the file contains.</p> <p> </p> Figure 11: Exploring the Sentinel-2 image in SNAP <p>We can see that the file is rather complex with numerous sub-folders containing more folders. The actual image-data we are mostly interested in is contained in the \"Bands\" folder as also marked in Figure 11.</p> <p> </p> Figure 12: Open RGB view <p>If we want to have a look at what the image looks like, we can perform a right click on the product name and select </p> <p>\"Open RGB Image Window\" as shown in Figure 12.</p> <p> </p> Figure 13: Open RGB view <p>In the new dialogue, we simple confirm with \"OK\" (Figure 13). And then a RGB-view of your satellite image should appear. In my case this looks like shown in Figure 14.</p> <p> </p> Figure 14: RGB view of the Sentinel-2 image <p>We will not dive further into the various visualization options SNAP offers but directly continue with the pre-processing steps.</p> <p>For this we select </p> <p><code>Raster  \u21d2 Subset</code></p> <p>as shown in Figure 15.</p> <p> </p> Figure 15: Subset Sentinel-2 image <p>From the main file menu. In the appearing dialogue, we select the \"band subset\" section as marked in Figure 16. Here, we now select only the Sentinel-2 bands that either have a spatial resolution of 10 or 20 m. Formulated in other words, we will drop the bands 1, 9 and 10 which all have a spatial resolution of 60 m. Please be aware that you have to know which Sentinel-2 bands have which spatial resolution. You can also check this in the meta-data but it is somehow expected that you familiarized yourself with the sensor of the data you are working with.</p> <p>Technical details of the Sentinel-2 sensors can be found for example here</p> <p> </p> Figure 16: Selecting only bands with 10 or 20 m spatial resolution <p>We then confirm with \"OK\" and a new version of my image will immediately appear in the Product Explorer window. Be aware that so far SNAP is not saving this subset as a new image. It only defined the subset on the \"meta-data\" level. The actual processing and subsetting of the bands will only take place, once the image is saved to a new file. </p> <p>Before we can actually save the image to a geotif-file, we will have to conduct one additional pre-processing step. We have to resample either the 10 m bands to 20 m or the 20 m bands to 10 m to have the same spatial resolution for each raster layer.</p> <p>To do this we select</p> <p><code>Raster \u21d2 Geometric \u21d2 Resampling</code></p> <p>as shown in Figure 17.</p> <p> </p> Figure 17: Opening the resampling tool in SNAP <p>In the appearing window, we select the \"Resampling Parameters\" section and chose the option \"By reference band from source product\" - here we can now either select a band with 10 m spatial resolution or 20 m spatial resolution and all other bands will be resampled to this resolution (if necessary). In my case, I select a band with 10 m spatial resolution (Band 2).</p> <p> </p> Figure 18: The resampling tool in SNAP <p>The resampling method is set to \"Nearest\" to not induce any changes to the measured values.</p> <p>We confirm by pressing \"Run\".</p> <p>After pressing \"Run\", immediately a new image product will appear in the Product Explorer window. We will select this new product as shown in Figure 19 and then, as final step, export this image product to a geotif-file.</p> <p> </p> Figure 19: Select the subsetted and resampled image to export it in a geotif file <p>For this we select the option</p> <p><code>File \u21d2 &gt; Export \u21d2 GeoTIFF / Big TIFF</code></p> <p>as shown in Figure 20.</p> <p> </p> Figure 20: Select the subsetted and resampled image to export it in a geotif file <p>In the appearing dialogue, we enter a filename and press \"Export product\" (as shown in Figure 21). Now the actual processing of the image starts. Hence, this whole procedure may take a while since all of the steps defined above, that is, subsetting the image, reampling the image and saving the image to a Tiff-file will now all be performed one after the other.</p> <p> </p> Figure 21: Export the Sentinel-2 image to a geotif file <p>If you want to make sure that everything has worked fine, you can load the exported Geotif-file in QGIS and visualize it as a RGB image as you have learned in during earlier lectures of the course. </p>"},{"location":"planetary-sciences/01-download-ls-and-s2/#exercises","title":"Exercises","text":"<ol> <li> <p>Identify the physical unit and scaling of the Landsat and Sentinel-2 image you have downloaded.  That is, you have to report </p> <ul> <li>whether the spectral information is for example saved as \"digital numbers\" / \"radiance\" / \"top of atmosphere reflectance\" / \"surface reflectance\" etc. </li> <li>What the numbers of the raster cells mean - they could for example be reflectance values scaled between 0 and 10000 where 10000 = 100% reflectance, or they could be raw digital numbers between 0 and 255.</li> </ul> <p>To answer this question, you will most likely have to read the product guides of the Sentinel-2 and Landsat products you have downloaded</p> </li> <li> <p>To prove that you have completed the tutorial, please provide two Screenshots showing the Landsat and Sentinel-2 image in a color-composite (either RGB or CIR) in QGIS. RGB would be the impression we have with our eyes (Red =&gt; Red, Green =&gt; Green, Blue =&gt; Blue) and in the CIR mode the channels are assigned as follows: Red =&gt; Near Infrared, Green =&gt; Red, Blue =&gt; Green.</p> </li> </ol>"},{"location":"qgis/01-GUI/","title":"Getting to know the graphical user interface","text":"<p>Abstract  After completing this tutorial, the participant has an understanding of the Q-GIS graphical user interface, knows how to activate and deactivate windows, is familiar with the QGIS-toolboxes and is able to set the language of QGIS.</p> <p>Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/01-GUI/#setting-the-language-of-qgis","title":"Setting the language of QGIS","text":"<p>Before starting to work with QGIS we will set the language settings of QGIS to English. This is necessary as all descriptions of the Tutorials will refer to the english QGIS version. Working in another language might cause unnecessary confusions. To switch the language to English, we first start QGIS by double-clicking the desktop icon called QGIS Desktop 2.x.x with GRASS 7.x.x (in your case the x-es will be some numbers indicating the QGIS version you have installed on your computer). Alternatively you can start QGIS from the start menu of your computer - the exact way how to do this varies with operating system and the Linux/Windows/Apple operating system version you have installed - but it is assumed that you know how to start a program on your computer. </p> <p>Then within QGIS, we open the Settings menu in the main menu bar of QGIS and select -&gt; Options as shown in Figure 1.</p> <p> </p> Figure 1: Open the settings menu <p>This will open a new window as shown in Figure 2. In this new window we check the override system locale/System-Locale \u00fcbersteuern box at the top of the window and then select American English / English United States from the drop down menus marked with 1 in Figure 2. Then we press OK and completely close QGIS. When we now restart QGIS, the language should have switched to English and we are ready to start with the Tutorials.</p> <p> </p> Figure 2: Change the language settings"},{"location":"qgis/01-GUI/#the-graphical-user-interface-gui-of-qgis","title":"The Graphical User Interface (GUI) of QGIS","text":"Figure 3: The QGIS graphical user interface <p>After opening QGIS and selecting a new project, the graphical user interface of QGIS will look as demonstrated in Figure 3. Depending on whether you already worked in QGIS before, some windows/docks might be missing or additional ones are shown. How to open or close certain windows will be addressed in section 3 of this tutorial. In Figure 3, the most important section of the QGIS GUI are marked with red numbers. A brief description on each of these sections is given in Table 1.</p> QGIS section Description Section 1 This is the main visualization screen or window in QGIS. Once data is loaded, the files will be displayed here. Section 2 This is the Layer Window. All loaded geodata will be displayed in this window in form of a single layer. The order of the listed layers determines their order in the visualization screen. Layers that are above other layers, will also be dis played above them. Right-clicks on the layers enable multiple direct actions that can be applied to the layers and additionally provide access to further dialogues to change the visualisation of the layer or access its detailed properties. Section 3 This is the main file menu of QGIS where all options of the program that are not included in toolboxes can be accessed. Section 4 This is the standard tool bar of QGIS. Most frequently needed tools like saving, navigating in the visualization screen or selecting data are provided. Section 5 This is the Vector-editing tool bar. It is required to change vector files (for example shapefiles). These changes can include for example adding new or editing existing spatial objects (polygons/lines/points) to or in an existing shapefile. Section 6 This is the toolboxes-window. Here all analysis tools of QGIS and official add-ons (including for example GRASS GIS and SAGA GIS). The toolbox window has a search option on the top. Most analysis steps (except for visualiza-tion settings) are conducted with the tools provided in these toolboxes. Section 7 This is the browser window where you can easily search your files and drap &amp; drop it to the Layer window below to load the geodata to QGIS Table 1: Brief description of the individual window sections in QGIS as shown in Figure 3"},{"location":"qgis/01-GUI/#opening-closing-and-arranging-windows-docks","title":"Opening, closing and arranging windows / docks","text":"<p>Closing one of the windows (for example Section 2, 8 or 6) is accomplished by simply clicking the x symbol on the top right of a window.</p> <p>As a first exercise try to close section 2 and 7 by clicking the x symbols in the top right of the windows.</p> <p>As a result only the visualization window in the center (Section 1 - which cannot be closed) and the toolbox window (Section 6) remain open. As one of the key-actions in each GIS-project is the re-arrangement of Geodata-layers in the Layer window, we should now re-open the Layer window. This is a bit more complicated than closing it. To achieve this we have to </p> <p>select View in the main file menu (Section 3) -&gt; Panels -&gt; Layer panel (Figure 4 ).</p> <p>Now the Layer window should re-appear.</p> <p> </p> Figure 4: Re-opening a closed window <p>The same procedure can be repeated for any (accidentally) closed window/panel. As you can see in the file menu there are numerous panels available that are not used by default in QGIS. Some of the available panels might be helpful depending on how you work in QGIS. For example you can try to activate the Statistics window. Once data is loaded, it will give you the option to display some statistical summaries of the information on the currently selected layer.</p> <p>As a next exercise we will learn how to rearrange panels in the QGIS GUI. Panels can be arranged by simple clicking and draging any panel in the grey bar on top of the panel depicting its title. By doing this, panels locked to the sides of the GUI-space can be released and positioned at another place. To lock the panel on one of the sides of the GUI, the panels have to be dragged to the corresponding side until they lock. Try to rearrange the currently open panels by positioning the Layer panel on the right side and the toolbox window to the left side of the GUI. This should result in a GUI as depicted in Figure 5.</p> <p> </p> Figure 5: The QGIS GUI after re-arranging windows"},{"location":"qgis/02-vector-data/","title":"Loading and visualizing Shapefiles / Vector data","text":"<p>Abstract  After completing this tutorial, the participant knows how to load a Shapefile (vector file) and how to make use of the visualization options in QGIS to adapt the colours, symbols and format of the spatial features (points, lines, polygons) contained in the shapefile. You will additionally learn how to save a QGIS project.</p> <p>Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/02-vector-data/#download-data-for-the-tutorial","title":"Download data for the tutorial","text":"<p>For this and the subsequent tutorials you will need to work with some geodata. Please download the data required for this tutorial here:</p> <p>Download</p> <p>This zip-file contains two ESRI Shapefiles (vector-data) - the first one named gis.osm_landuse_a_free_1.shp contains a land-use dataset of Southern Italy and the second dataset is a global dataset named newsweek_data.shp which contains some demographic information for each country of the Earth.</p> <p> </p> Figure 1: Files contained in the zipped file for Tutorial 2 <p>Both shapefiles consist of several data files as shown in Figure 1. You will learn why a single shapefile consists of multiple datafiles later on in the course.</p>"},{"location":"qgis/02-vector-data/#loading-a-shapefile-vector-file-in-qgis","title":"Loading a Shapefile (vector file) in QGIS","text":"<p>After opening QGIS and selecting a new project, the graphical user interface of QGIS will look as demonstrated in Figure 2. In Figure 2, we can use the browser window to navigate to the folder which contains the files we have just downloaded. Then we can open the file gis.osm_landuse_a_free_1.shp by simply dragging and dropping the file in the layer window (marked with 2 in Figure 2).</p> <p> </p> Figure 2: Openning a Shapefile in QGIS <p>This will open the selected shapefile and automatically display it in the main window of QGIS (Section 1 in Figure 1). You should now see something similar to Figure 3. The colours will most likely differ from the ones displayed in Figure 3 as QGIS randomly assigns a colour to each newly loaded shapefile (vector file). How colours can be adapted and how the attributes stored in shapefiles can be used to colour-code and format individual spatial objects (polygons, lines, points) will be explained in the next section.</p> <p> </p> Figure 3: After opening the shapefile in QGIS"},{"location":"qgis/02-vector-data/#basic-visualization-of-shapefiles-in-qgis","title":"Basic visualization of Shapefiles in QGIS","text":"<p>As next step we will change the colour of the complete loaded Polygon-shapefile by using the properties dialogue that is available for each dataset loaded into QGIS. In order to do this either double click the entry of the shapefile-layer in the layer window of QGIS as shown in Figure 4 or alternatively perform a right-click on the same layer and from the appearing text menu select properties.</p> <p> </p> Figure 4: Double-click the Shapefile layer <p>This will open a new window as displayed in Figure 5 with many functionalities. In this tutorial we will focus on the options to adapt the visualization settings of the vector file. To open the corresponding tab in the window select the tab Symbology (the corresponding tab may have also been opened as standard setting). </p> <p> </p> Figure 5: The properties window with the **Symbology** tab activated. The latter allows to modify the the visual appearance of the vector file in numerous ways <p>We will now explore five options to adapt the visual appearance of the shapefile. Everytime we conducted a change and want to see the effects on the visualization in the main QGIS window we have to first confirm our choice by clicking apply and then press ok to close the properties dialogue window. We can later return to the properties dialogue by repeating the steps described above, that is by double-clicking the shapefile-layer as indicated in Figure 4 or by performing a right-click and selecting Properties. The first adaptation that we will try out is to change the colour of the whole Shapefile. In order to do this first click the area marked with 1 in Figure 6. This will change the available options in the tab. Then click Fill color-area marked with 2. A new window will open from which you can select any colour you want. Select a colour, press OK, then Apply and OK again. </p> <p>You will see that the colour of the shapefile has changed to the colour you selected.</p> <p> </p> Figure 6: Changing the colour of the complete shapefile <p>As a second option we will explore how to not only assign a new colour but also change the style and colour of the outline and the filling of the polygons. to change the fill-style of the polygons</p> <p>we first click the area named Fill and marked with 1 in Figure 7. Then we can select any fill type we want from the list of option provided below. We could for example select a quite complex pattern such as the one marked with 6. Then, we can further customize the pattern of the filling and also the outline of each polygon by clicking through the areas marked with 2, 3, 4 and 5 and modify colors or line widths etc.</p> <p> </p> Figure 7: Changing the fill pattern and the colour of the outline of the shapefile <p>Please try out a few different settings and have a look how they affect the visualization in the main windows after you pressed the apply button and closed the properties dialogue by clicking OK.</p> <p>You should now be able to adapt the visualization of a shapefile as a whole, that is all spatial objects in the Shapefile are displayed with the same visualization parameters. However, in many cases a shapefile does not only contain a single class of interest but several ones. For example our currently loaded shapefile contains information about the land cover classes of the depicted areas. So we know where in the area covered by the shapefile we can find industrial areas, cemeteries, parks or residential areas. We might be interested in visualizing this also in the map. We could for example give a green colour to parks while we could assign a grey or red colour to areas covered with residential areas or industry. In the next Section, we will learn how this can be accomplished with QGIS.</p>"},{"location":"qgis/02-vector-data/#using-information-from-the-attribute-table-of-the-shapefile-to-colour-code-classes-within-a-single-shapefile","title":"Using information from the attribute table of the shapefile to colour-code classes within a single shapefile","text":"<p>To make sound use of the information stored in the attribute table, we need to first understand what information is contained in the attribute table. So let us have a look at the table by</p> <p>right-clicking on the shapefile-layer and selecting Open Attribute Table as demonstrated in Figure 8</p> <p> </p> Figure 8: Opening the attribute table of the shapefile <p>This will open the attribute table of the Shapele in a new window. The window will approximately look like the window shown in Figure 9.</p> <p> </p> Figure 9: The attribute table of the gis.osm landuse a free 1 Shapefile <p>As you can see there are four columns available in the attribute table of our Shapele: osm id, code, fclass and name. Here, the osm id is a unique identifier number assigned by the Open Street Map system which is the data source for our Shapefile. This identifier makes each object in a given Open Street Map dataset clearly identifiable. The code field shows a land cover code for each object in the Shapefile. It basically is a numeric description of the next field fclass where a descriptive term for the land cover type is given. In Figure 9 you can for example see that all polygons assigned to the class park have the code 7202. Finally, there is another column called name which indicates an official name for the given polygon. For example the name of a park or a cemetery. In the next step, we will now make use of the information stored in the fclass column to assign meaningful colours to the individual land cover classes. In order to do this</p> <p>we first open the shapefile properties dialogue, as explained above and select the style tab. Then we press the drop-down menu marked with 3 in Figure 6. Here we select the option categorized. This will lead to the window shown in Figure 10. Here, we can now use the drop-down-menu marked with 1 to select the column from the attribute table which we want to use to colour-code our spatial objects in the Shapele. Here, we will select the class fclass and then confirm the choice by pressing the classify button marked with 2 in Figure 10.</p> <p> </p> Figure 10: Colour-code the polygons of the Shapefile using the attribute table <p>This will lead to a situation similar to the one depicted in Figure 11. The colours are again likely to be dierent as QGIS selects the colours randomly. We can now assign meaningful colours to each of the land-cover types by double-clicking any of the colour boxes marked in Figure 11. In the new pop-up dialogue we can assign a new colour and also make more detailed changes to the format of the filling and the outlines by selecting simple fill and use the then appearing properties as shown in Figure 12.</p> <p> </p> Figure 11: Visualization options for displaying categories <p> </p> Figure 12: Colour and format selection for each land cover class <p>You should now be able to load and visualize a Shapefile by either changing the style for the whole Shapefile or classify and colour-code the spatial objects of the Shapefile to some discrete classes using information given in the attribute table. In the exercise of this Tutorial, you will find out how it is possible to colour-code the spatial objects of a Shapefile using attribute table information from an attribute with continuous values.</p>"},{"location":"qgis/02-vector-data/#saving-a-qgis-project","title":"Saving a QGIS project","text":"<p>After learning how to adapt the visualization of a Shapele, you might want to know how you can save these settings for the next time you open QGIS. The easiest way to save the visualization settings but also all other things you have accomplished while working with your data in QGIS is to store the current situation as a QGIS-project. You can do this by </p> <p>selecting Project -&gt; Save as... from the main file menu of QGIS as shown in Figure 13. This will open a new dialoge where you can define an output folder and then enter a name for the QGIS-project and click save to save the file. QGIS-project files of the latest version of QGIS have the file format ending .qgz while older versions used .qgs as standard setting.</p> <p> </p> Figure 13: Saving a QGIS project <p>After storing the project file it is possible to re-load the status of your QGIS project in the future by selecting Project -&gt; open from the main file menu and then navigating to the .qgz file that you have stored earlier. Alternatively, you can also double-click this file in the Windows Explorer (or similar data explorer apps in Linux or MacOS environments). This will automatically load QGIS and the project. It is important to understand, that the QGIS project-files themselves do not contain any geodata. Project files only store links to the data which are stored on the hard disk of your computer. That means if you delete or move your files to another folder while QGIS is closed and then want to re-open the QGIS-project you had been working on, QGIS will tell you that some of the files of the project cannot be found anymore and they will not displayed in the project. So again: project files only remember the visualization options, the layer order, and which windows and toolboxes were opened when you stored the project file. It does not include the geodata itself! That is also why project files are typically rather small in size. But this also means that if you will send this project file to a colleague, she/he will not be able to see what you saw unless you are also sending all the geodata to her/him.</p>"},{"location":"qgis/02-vector-data/#exercise","title":"Exercise","text":"<p>Amongst the files you downloaded you will find a shape file called newsweek data.shp.</p> <p>Try do conduct the following exercises:</p> <ol> <li> <p>Load this dataset to QGIS and have a look at its attribute table.</p> </li> <li> <p>Identify the column that contains information about the life expectancy across the different countries of the Earth.</p> </li> <li> <p>Visualize the life-expectancy values for each countries using the Style-Tab of the Properties diaologue and the corresponding columns from the attribute table</p> </li> </ol> <p>Some tips: Instead of using the option categorize use the option graduated. As mode try out the option Natural jenks; try to also vary the number of classes and see how this affects the visualization.</p> <ol> <li>Export the current view by selecting Project -&gt; Save as Image from the main menu of QGIS (Figure 14). This will be the proof that you completed the Tutorial.</li> </ol> <p>General advice: Don't be shy to try out a few different options and settings!! This is the only way to learn how things work.</p> <p> </p> Figure 14: Save current map view as image"},{"location":"qgis/03-raster-data/","title":"Loading and visualizing raster data","text":"<p>Abstract  In this Tutorial we will learn how to load and visualize raster files in  QGIS. The concept of histograms and which role they play for adapting the visualization of raster datasets in QGIS will be explained. As example dataset we will make use of a satellite image of the satellite sensor Sentinel-2.</p> <p>Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/03-raster-data/#download-data-for-the-tutorial","title":"Download data for the tutorial","text":"<p>For this and the subsequent tutorials you will need to work with a Sentinel-2 satellite image. Please download the data required for this tutorial here:</p> <p>Download</p>"},{"location":"qgis/03-raster-data/#loading-a-raster-file-in-qgis","title":"Loading a raster file in QGIS","text":"<p>Similarly as learned in the last tutorial, we can open a raster file by simply dragging and dropping the file from the browser-window to the layer window (see Figure 1). </p> <p> </p> Figure 1: Opening a raster file via drag and drop in QGIS <p>Alternatively, we can also use the main file-menu of QGIS to add a raster file / raster layer as seen in the Figure 2. This option was not described in the previous tutorials on vector files, but this also works with vector files.</p> <p> </p> Figure 2: Opening a raster file via the file menu of QGIS <p>If you chose the option to use the file menu, a new window will pop-up and you will then have to select the path to the raster file you want to open by clicking the button marked with 1 in Figure 3.</p> <p> </p> Figure 3: Open file dialogue menu of QGIS <p>Once we have successfully opened the raster file, it should be displayed in the main visualization window of QGIS, similarly as shown in Figure 04.</p> <p> </p> Figure 4: View after loading the raster file <p>The opened raster dataset is a satellite scene from EU's Sentinel-2 satellite. QGIS will automatically select a visualization setting of the raster dataset based on the statistics of a few randomly selected pixels. However, in most cases these settings will not be optimal. So do not worry if the displayed raster seems to be very dark or with strange colors when using other datasets. In some cases it might even look completely black but still contain relevant data which will only show up after the visualization has been optimized. In our case the first impression should already be quite good, eventhough, it is not yet a realistic true-colour visualization (which describes a visual impression similar to what we see with our eyes). In the next section we will learn how the achieve this.</p>"},{"location":"qgis/03-raster-data/#rgb-visualization-of-raster-files","title":"RGB-Visualization of raster files","text":"<p>To better understand how the optimization of the visualization of raster files works, it is important to have a good understanding how raster files are structured. Raster files can be pictured as a grid of pixels where each pixel contains a value. The range of these values depends on the data source for the raster data. They could for example originate from a model simulation that predicted air temperature. Then each pixel might have a value between approximately -30 and +50 showing the air temperature above the Earth surface in Degree Celsius. The values might also contain information about the altitude above (and below) sea level and might then range from -413 m (deepest point below sea level on a land surface, an area close to the Dead sea) to 8848 m (top of the Mount Everest).  In our case, the raster dataset stems from a satellite sensor which measures the amount of electromagnetic radiation reflected in certain wavelengths of the electromagnetic spectrum. In simpler words, one could say that the satellite sensor measures the amount of different colours (careful - this is a very simple way of putting it and physically not really correct) at certain locations (pixels) on the Earth surface and then stores this information into individual raster layers (see Figure 5). In our case, the satellite raster dataset consists of 10 raster layers that store information on how much blue, green and red light (and some additional colours that humans cannot see with their eyes) have been reflected in the different areas of the Earth surface that were observed by the satellite. Each raster layer contains information on one colour. Hence, our raster dataset can be pictured as a stack of individual raster layers or images which will be called bands or channels in the following (Figure 6 )1.</p> <p> </p> Figure 5: Structure of raster data <p> </p> Figure 6: Raster stack <p>In QGIS we can always only use either just one band - Render type: Single band gray (render type can be selected in drop-down menu marked with 1 in Figure 8) or a set of three bands - Render type: Multiband color (also known as RGB-composite) - to create a visualization of the raster dataset. This is related to the way computers create colours on the screen. Basically, there are only three colours: red, green and blue which are then mixed on a very fine scale to create a visual impression of all colours that we see on the screen. During the visualization optimization we tell QGIS which three bands of the raster dataset should be used to create red, green and blue colours on the screen. </p> <p>So let us try this with our satellite image. To change the visualization settings of the loaded raster data,</p> <p>we either perform a right click on the raster layer in the layer window of QGIS and select properties or alternatively, we can perform a double-click on the same layer. This will open up the properties window, where we will select the Symbology tab. (marked with the red box in Figure 7)2</p> <p> </p> Figure 7: Raster symbology window of QGIS <p>Now we will assign the satellite bands which collected information on blue, green and red colours to the corresponding channels of QGIS. The red channel of QGIS (marked with 2 in Figure 7) is currently assigned to Channel 1. We will now change this by</p> <p>Clicking the drop down menu for the Red Band (marked with 2 in Figure 7) and select Band 03, which corresponds to the band of the satellite that collected information on electromagnetic radiation that corresponds to red light. Analogously, we will select Band 02 for the Green Band of QGIS (marked with 3 in Figure 7 normally, this channel should already be correct) and then Band 01 for the Blue band of QGIS (marked with 4 in Figure 7). Then we select Apply and then OK to see how this changes the visualization of the image (Figure 8).</p> <p> </p> Figure 8: View after adjusting the settings <p>In the new visualization (as seen in Figure 8) we can see that the colours on the land surface of the satellite image look more natural to us now. However, we can also see that the sea surface seems to be very dark and not blue as we might have expected. This relates to the fact that water has very low reflectance values across all wavelengths (colours) and typically appears very dark in satellite images as it absorbs most of the incoming radiation/energy/light. This raises the question whether we can increase the information content for these areas by adjusting the settings some more. Let's try!</p> <p>To do this,</p> <p>We return to the Properties window and select the Symbology tab. Now we will click the area marked with 6 in Figure 7 to open some additional options to load minimum and maximum values for each raster layer as depicted in Figure 9.</p> <p> </p> Figure 9: Raster symbology window in QGIS - advanced settings <p>There are three options available to automatically derive minimum and maximum pixel values between which the available range of colours intensities will be spanned. These minimum and maximum values are marked with 1 in Figure 9. To estimate the minimum and maximum values, QGIS uses a set of random pixel values that it collects in the image. Then it applies some statistics on the pixel values to understand how the pixel values are distributed in the value range. The three options to calculate the statistics are cumulative count cut, min / max and mean \u00b1 standard deviation (box marked with 2 in Figure 9).</p> <p>So why do we have to use such statistics to improve the visualization? This can be explained best using a histogram. A histogram shows the distribution of values of a dataset by plotting the frequency of values occurring in a defined value range on the y-axis and the value ranges themselves on the x axis. In Figure 10 an example for a histogram of the pixel values of a raster image is shown. In the upper part of Figure 10 one can see the histogram of the full value range of the raster image with values between 0 and 255 (which would indicate an eight bit image). In this histogram one can clearly see that there are hardly any very low values (close to 0) and also hardly any very high values (close to 255), while most values accumulate in the middle of the value range (between around 60 and 180).</p> <p> </p> Figure 10: A histogram of raster values <p>So how would QGIS now translate these values into colours? Assuming QGIS is attempting to visualize a single raster layer with pixel values as indicated in Figure 10 it would conduct the following steps: Pixels having a value of 0 will be set to the colour black and pixels having the maximum value of 255 will be set to the colour white. All pixels with values inbetween will receive a grey value that is darker if the value is low (closer to black) and brighter if the value is high (closer to white).</p> <p>If such a translation between the minimum and maximum value is conducted based on the full value range, most pixels of the image will be displayed in intermediate grey levels, while there will be hardly any white or black pixels (as there are hardly any pixels having values close to 0 or to 255). That means the visualization will loose a lot of so called contrast in the image. To avoid this, it is possible to adapt the value range displayed on the screen in QGIS. With this step, the extreme values to which black and white colours are assigned will be newly assigned. In the bottom of Figure 10 this is done by setting the minimum value (corresponds to black) to 60 and the maximum value (corresponds to white) to 180. Now the histogram is stretched and we would see the full range of colours between black and white in the image with a maximized contrast.</p> <p>The same procedure is applied in QGIS when changing the Min and Max values of the three bands (section marked with 1 in Figure 9). As said before, this can be done automatically by using the three options to calculate statistics based on some pixel values or it can also be accomplished by editing the min and max values manually. You could for example change the Min values of all bands to a higher values and see how this affects the visualization of the image. In the next step, we will learn a standard-procedure to adapt these settings.</p> <p>We will now adapt the value ranges of the three channels of our satellite image using the standard statistical approach. We do this by</p> <p>selecting the option mean +- standard deviation and keeping the default settings. We confirm by pressing Apply and OK.</p> <p>This will result in the image shown in (Figure 11)3</p> <p> </p> Figure 11: View after adjusting the image stretch <p>The colour of the sea has turned from very dark or black to blue which may match better what we would expect to see. However, one can also see that the land surface areas seems to be quite bright now compared to the sea. So adjusting visualization options is often a compromise and it might not be possible to show all areas/surface types in their optimal settings at the same time.</p> <p>In the new visualization settings, the sea appears blue but also shows some more details in compared to the earlier two visualization settings. However, might there be ways to further  adapt the visualization to see even more details of the sea? </p> <p> </p> Figure 12: The zoom tool of QGIS <p>Indeed there are! One solution is to adapt the value range again but this time only considering pixels from the sea. In QGIS, there is one option to do this which we will explore as next step. First, we use the zoom-tool of QGIS (marked in Figure 12) to zoom into an area where only sea is visible by</p> <p>clicking the zoom tool-button and then dragging a square within an area of the image which is only covered by the sea. This will lead to a view where only blue areas are visible in the QGIS visualization window (as shown in Figure 14). Next, we will repeat the steps to optimize the value ranges as we have learned before. That is, we will open the properties window, select the symbology tab and open the option to automatically estimate minimum and maximum values by clicking the area marked with 6 in Figure 7. The only thing we will do difffferent this time, is that we will change the dropdown menu marked with 3 in Figure 9 from Whole Raster to Current canvas. Then we will press Apply and then OK and close the Properties window.</p> <p> </p> Figure 13: View after applying the zoom tool to zoom into an area only covered by the sea <p> </p> Figure 14: View after optimizing the visualization settings for the sea <p>The will lead to a new visualization as shown in Figure 14. As you can see, the formerly uniformely blue image turned into a quite colorful image where lots of fine details about the sea surface became visible. By activating the Current canvas option, QGIS calculated the statistics only for pixels located in the currently visible part of the image. That is, only sea pixels were considered to derive the min and max values. If you now use the zoom-out button, located next to the zoom-in button, you can see that all the other areas in the image are very bright and no details can be seen anymore in these areas (Figure 15). This is because all of the land-surface areas have notably higher pixel values than the pixels located in the sea and are hence mostly assigned the maximum value of the defined range. You can also re-open the properties window and the style tab and have a look at the current value.</p> <p> </p> Figure 15: View of the full image after the adaptation of the visualization options to improve the level of details displayed in sea areas"},{"location":"qgis/03-raster-data/#exercise","title":"Exercise","text":"<p>To practice a bit more raster visualization options, try do conduct the following exercises:</p> <ol> <li> <p>Change the multi-band visualization by assigning other bands of the satellite image to the red, green and blue channel of QGIS. For example you can try the combination Red Channel: 6 Green Channel: 3 and Blue Channel 2. This is the so called color-infrared-view where the red channel is replaced by near-infrared information which makes the vegetation appears in red colours in the image. </p> </li> <li> <p>Zoom to the extent of the satellite image and export the current view by selecting Project -&gt; Save as Image from the main menu of QGIS (Figure 16). This will be the first proof that you completed the Tutorial.</p> </li> </ol> <p> </p> Figure 16: Save current view to image <ol> <li>Try to switch the render type from multi-band color to single-band gray and compare the gray values of band 3 and band 6 of the raster dataset. What do you see? Are there any differences in the patterns you observe? Give some short descriptions of you observe - you can export images with the same procedure as explained in step 2. This should with your explanations. This will be the second proof that you completed the Tutorial.</li> </ol>"},{"location":"qgis/03-raster-data/#reference","title":"Reference","text":"<ol> <li> <p>Figure 6 \u21a9</p> </li> <li> <p>Figure 7 \u21a9</p> </li> <li> <p>Figure 11 \u21a9</p> </li> </ol>"},{"location":"qgis/04-general-tools/","title":"Useful general tools","text":"<p>Abstract After completing this tutorial you will know how to navigate efficiently in the main visualization window of QGIS. You will be able to arrange and directly zoom to layers, add transparency to a layer, measure distances in the visualization window, and obtain information on a pixel or a spatial object. Developed with QGIS version - Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/04-general-tools/#efficient-navigation-in-the-visualization-window-of-qgis","title":"Efficient navigation in the visualization window of QGIS","text":"<p>In the last tutorials we have learned how to open and visualize raster datasets as well as vector datasets. Now we will learn how we can navigate within the main visualization window of QGIS. We already got to know the \u201czoom-tools\u201d in the last Tutorial. We will now add some more tools and procedures that make life easier when navigating in QGIS. </p> <p>To learn about these functionalities, we first have to load some data. In this case we will use the same data we already know from the two preceding Tutorials. So to start</p> <p>we load the raster dataset \u201cS2 Neapel sm2.tif\u201d and the Shapefile \u201cgis.osm landuse a free 1.shp\u201d in the same way as you have already learned in Tutorial 2 and 3. First load the raster dataset and then the shapefile.</p> <p> </p> Figure 1: Overview of the tools we will get to know today <p>This will lead to a situation that looks like illustrated in Figure 1. We will now learn what we can do with the buttons marked in Figure 1. A brief overview of the functionalities of each button is summarized in Table 1.</p> <p>Table 1: Overview of most important buttons to navigate and measure in QGIS | Button Nr | Brief description | |--|--| | Button 1 | This is the \u201cpan\u201d button which allows you to easily navigate through the QGIS visualization window without changing the zoom-level. | | Button 2+3 | These are the \u201czoom-buttons\u201d. They can be used to change the zoom level of the visualization window. | | Button 4 | This is the \u201cinfo-button\u201d. With this button you can obtain information on a pixel of a raster layer or a spatial object stored in a vector file. | | Button 5 | This is the \u201cmeasure-tool\u201d. It can be used to measure distances, angles and areas within the main visualization window. | | Button 6 | This is the \u201c\u2018select-tool\u201d. It allows to select an individual or several spatial objects from a vector file. | | Button 7 | This button allows to zoom to the currently selected spatial object. | | Button 8 | This is the \u201czoom-to-full-extent\u201d button. </p> <p>So let us try out the different buttons with the loaded data. First,</p> <p>select the \u201cpan-button\u201d (marked with \u201c1\u201d in Figure 1), navigate the cursor over the main visualization window and then click and hold the mouse button and simultaneously drag the mouse cursor to navigate within the visualization window. Repeat this step until you have reached an area where there is not data to be visualized anymore.</p> <p>Now you are more or less \u201clost\u201d and you would like to return to the area where your data is located. So in order to do this, we will learn an additional function hid in the \u201cright-click menu\u201d of each layer. So what we do next is</p> <p>perform a right-click on the \u201cS2 Neapel sm2\u201d layer as listed in the layer window of QGIS, then select the first option in the menu which is called \u201cZoom to Layer\u201d.</p> <p>You will see that QGIS will now automatically returns to the extent of the \u201cS2 Neapel sm2\u201d layer. This is a very useful tool that you will probably use frequently.</p> <p>OK, now we have learned how we can directly zoom to the extent of a loaded layer. However, we might also want to zoom-in to a specific subset of our study area. We can do this by</p> <p>selecting the \u201czoom-in\u201d button marked with \u201c2\u201d in Figure 1 and then either click on the area where we want to zoom-in or alternatively click and drag the mouse curson to form a rectangle to which QGIS will then zoom in. A further alternative to using the \u201czoom-in\u201d button is to simply use the mouse\u2013wheel. If you navigate the mouse cursor over the main visualization window and rotate the mouse-wheel you will directly see the zoom\u2013effect.</p> <p>In case you want to zoom-out again, you have several options to do this. We have already learned to use the right-click on one of the layers to select the option \u201cZoom to Layer\u201d, alternatively we can either</p> <p>use the \u201czoom-out\u201d button marked with \u201c3\u201d in Figure 1 or we can also use the \u201czoom to full extent\u201d button marked with \u201c8\u201d in Figure 1. If we click this button QGIS will zoom out to a view where all currently loaded layers are completely displayed. Try it out!</p> <p>As a last alternative for zooming, we will now learn how to first select a specific spatial object in a vector file and then zoom-in to this object. To achieve this,</p> <p>select the \u201cselect Features\u201d button marked with \u201c6\u201c in Figure 1. Then click on one of the polygons of the \u201cgis.osm landuse a free 1\u201d layer. You have to make sure that the \u201cgis.osm landuse a free 1\u201d layer is currently activated/selected in the layer window of QGIS. Otherwise, the button might be greyed out.</p> <p> </p> Figure 2: Selecting a spatial object in QGIS <p>This will lead to a situation similar to the one presented in Figure 2. Here, a polygon located close to the volcano was selected and is now highlighted with yellow color. As next step, we</p> <p>press the \u201czoom to selected object\u201d button marked with \u201c7\u201d in Figure 1</p> <p>QGIS will now zoom-in to the selected object as seen in Figure 3.</p> <p> </p> Figure 3: Zooming in to a selected spatial object <p>You are now able to efficiently navigate within the QGIS visualization window. In the next sections we will learn three more useful general tools of QGIS that you will most likely often use.</p>"},{"location":"qgis/04-general-tools/#arranging-layers-and-adding-transparency","title":"Arranging Layers and adding transparency","text":"<p>If you have followed the recommendation above to first load the raster file and then the shapefile, the raster layer is currently displayed below the shapefile. If we want to change this, we can re-arrange the layers in the layer window of QGIS. To do this, we simply</p> <p>click and hold the \u201cgis.osm landuse a free 1\u201d layer and drag it below the \u201cS2 Neapel sm2\u201d layer.</p> <p>You will see that this will shift the vector file below the satellite raster data in the main visualization window (Figure 4).</p> <p> </p> Figure 4: Shifting the satellite layer to the top <p>So, as quite inuitively understandable, the layer position in the layer window also always determines the order in which the layers are visualized. However, the visualization of a layer can also be completely deactived by unchecking the checkboxes on the left besides the name of the layers that are depicted in the layer window of QGIS</p> <p>In Figure 5 the layer containing the satellite raster layer was deactivated by unchecking the box. We will now re-activate the layer so that both datasets are visible.</p> <p> </p> Figure 5: Deactivating a layer <p>Shifting the satellite data on top of the vector layer did not really improve the visualization situation as now all spatial objects overlaping with the satellite raster data became invisible. So we will now try to find a solution in which both datasets are displayed at the same time with a minimum loss of information due to the overlapping. To do this, we first</p> <p>rearrange the layer once more to have the satellite raster layer below the shapefile layer. Next we will right-click the \u201cgis.osm landuse a free 1\u201d layer and select \u201cproperties\u201d. In the appearing properties window we select the \u201cSymbology\u201d tab. As shown in Figure 6, we will now change the \u201cLayer transparency\u201d option in the \u201cLayer rendering\u201d section from 0 to 50 and accept the new settings with pressing \u201cApply\u201d and then \u201cOK\u201d.</p> <p> </p> Figure 6: Adapting the transparency settings of a layer <p> </p> Figure 7: New visualization with the transparent Shapefile <p>As visible in Figure 7 the \u201cgis.osm landuse a free 1\u201d layer is now displayed transparently and both datasets can be seen at the same time. Transparency can be added to any dataset loaded in QGIS except using the same dialogue as just described.</p>"},{"location":"qgis/04-general-tools/#the-measuring-tool-in-qgis","title":"The measuring tool in QGIS","text":"<p>We will now have a look at the \u201cmeasure-tool\u201d which is marked with \u201c5\u201d in Figure 1. If you have a closer look at the button of the tool you can see that there is a small arrow pointing downwards next to the button symbol. If you press this arrow you can see that there are four options for the measuring tool:</p> <p>Measure Line To measure linear and non-linear distances Measure Area To measure areas of Polygons Measure Angle To measure angles between two lines and Measure Bearing to measure the horizontal angle of an object.</p> <p>To see how the tool works,</p> <p>we will first zoom-in to the vulcano displayed in the satellite raster file. Then we select the \u201cMeasure Line\u201d option of the tool and measure the East-West expansion of the vulcano as shown in Figure 8</p> <p> </p> Figure 8: Measuring the East-West expansion of the vulcano <p>Next, we will switch to the \u201cMeasure Area\u201d option and measure the whole extent of the volcano by drawing a polygon around it as depicted in Figure 9. As marked in Figure 9 that unit can be changed by using the marked drop-down menu.</p> <p> </p> Figure 9: Measuring an area in QGIS"},{"location":"qgis/04-general-tools/#the-infobutton-in-qgis","title":"The info\u2013button in QGIS","text":"Figure 10: Zoom in to the area marked with the red rectangle <p>As last useful tool in this Tutorial, we will get to know the \u201cinfo-tool\u201d. This tool allows us to find out either the value of a pixel of a raster file or attributes of a vector file as stored in the attribut table. To see how the tool works, we</p> <p>will first zoom-in to the area marked with the red rectangle in Figure 10, then we select the \u201cinfo-button\u201d marked with \u201c4\u201d in Figure 1. Next, we select the \u201cgis.osm landuse a free 1\u201d layer in the layer window of QGIS and then click on a spatial feature of the Shapefile. QGIS will then display the attribute table information stored for this spatial feature in the new \u201cIdentify results\u201d window that has opened after activating the \u201cinfo-button\u201d tool. In Figure 11 you can see an example for this.</p> <p> </p> Figure 11: Retrieving attribute information using the info-button tool. <p>The same procedure can be repeated for the raster file by</p> <p>first selecting the \u201cS2 Neapel sm2\u201d layer in the layer window of QGIS and then again using the \u201cinfo-button\u201d tool to click on any pixel of the raster dataset. All values of the 10 raster bands will then be shown in the \u201cIdentify results\u201d window. By switching the view-option from \"tree\" to \"graph\" as shown in Figure 12 you can visualize the spectrum of a given pixel</p> <p>You should now be familiar with the most important general tools of QGIS that will ease your daily life with handling and navigating through geodata in QGIS.</p> <p> </p> Figure 12: Deriving a spectrum using the \u201cinfo-button\u201d."},{"location":"qgis/04-general-tools/#exercises","title":"Exercises","text":"<p>To further familiarize yourself with the tools you have just learned to handle, please solve the following tasks:</p> <ol> <li> <p>Measure the area of the crater of the volcano</p> </li> <li> <p>Identify the residential area (visually) closest to the crater and register its osm_id (one attribute you can derive using the info button)</p> </li> <li> <p>Measure the distance of the residential area to the center of the crater (use the approximately shortest distance between the polygon and the center of the crater)</p> </li> <li> <p>Try to identify four different land-cover classes in the satellite image and use the info-button to display the spectra of the land-cover classes. Please make screenshots (using the \"print screen/Druck\" button on your keyboard and then \"paste/einf\u00fcgen\" in some graphic program - or maybe you also have an alternative screenshot tool on your computer) of the spectra and describe the differences you observe for the four classes in your own words. Feel free to make more than one screenshot per class to better understand how the classes you identified differ in their spectral behaviour.</p> </li> </ol> <p>Please upload a single pdf-file including the results of Exercises 1-4 in the corresponding assignment in Blackboard.</p>"},{"location":"qgis/05-digitizing/","title":"Basic vector processing","text":"<p>Abstract</p> <p>After completing this tutorial you will know how to create a new shapefile and digitize new spatial objects into the shapefile. Furthermore, you will be able to conduct a buffer analysis, and add geometric information to the newly created spatial objects. Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/05-digitizing/#creating-a-new-shapefile-vector-file","title":"Creating a new Shapefile vector file","text":"<p>In this tutorial we will get to know the most important basics for creating and processing vector Shapefiles. We will first load the already familiar satellite image as base information from which we can digitize information into a Shapefile. After creating the shapefile, we will conduct some more analysis steps with it.</p> <p>To start,</p> <p>we load the raster dataset \u201cS2_Neapel_sm2.tif\u201d as already learned in previous tutorials. Next, adapt the visualization settings to have a balanced view of all classes by using the channels R=3, G=2, B=1 and loading new max / min values using the \u201cSymbology\u201d-tab in the properties window.</p> <p>As next step, we will create an empty shapefile by</p> <p>selecting the menu \u201cLayer\u201d then \u201cCreate Layer\u201d and \u201cNew Shapefile Layer\u201d as indicated in Figure 1</p> <p> </p> Figure 1: Creating a new shapefile layer. <p>This will open a new window in which you can define the type of Shapefile you want to create. There are three options: 1. Point 2. Line and 3. Polygon \u2013 see also area marked with \u201c1\u201d in Figure 2. Furthermore, it is necessary to define a coordinate reference system (CRS) - marked with \u201c2\u201d in Figure 2. We will now do this by</p> <p>selecting \u201cPolygon\u201d and then defining the CRS by clicking the little \u201cglobe\u201d button marked with the red frame in Figure 2</p> <p> </p> Figure 2: Selecting the correct settings for a Shapefile. <p>However, we first have to decide what is the correct coordinate reference system. As you can see form Figure 3 there are very many coordinate reference systems (CRS) to choose from. In our case, we will simply select the coordinate reference system of the already loaded satellite image. This is often an easy solution if no further information about coordinate reference systems is available.  In our case, we can find out the coordinate reference system of the satellite image by having a look at the lower right corner of the QGIS graphical user interface as marked in Figure 4. At this position you will always see the current CRS of the QGIS project. It is normally defined by the first datasets that gets loaded into a project. In our case, the satellite image was loaded first, so the whole project was adapted to the CRS of the satellite image. In case several datasets are loaded, they might have differing CRS. We will investigate such a case in one of the Tutorials which are still to come.</p> <p> </p> Figure 3: Defining the coordinate reference system. <p> </p> Figure 4: Identify the coordinate reference system of the current QGIS project. <p>So how do we ensure that the CRS of our new Shapefile matches the CRS of the satellite image? In Figure 4 we can see that the CRS of the current QGIS project and hence the satellite image has the EPSG code: 32633. We will now select the same CRS in the \u201cselect CRS dialogue\u201d in QGIS by</p> <p>clicking in the \u201cFilter\u201d area marked with \u201c1\u201d in Figure 3, then we enter the digits of the EPSG code, that is \u201c32633\u201d. By doing this, all CRS systems except for a single one will disappear (see Figure 5). As you will learn in the theoretical lectures, each EPSG code is unique! So we will now select the coordinate system \u201cWGS 84 / UTM zone 33N\u201d and confirm with clicking \u201cOK\u201d. As final step, we will have to define a name for the shapefile and the folder where you want to store it. To do this, we click the ... button in the top right of the form next to the \"File name\" field and enter a filename and navigate to the folder where we want to store the new Shapefile. Name the Shapefile \u201cPolygon_tut5.shp\u201d, press \u201cOK\" and \"OK\" again in the main form to create the new Polygon Shapefile.</p> <p> </p> Figure 5: Filtering using the EPSG code. <p>This should lead to a new situation as depicted in Figure 6. As you can see, not too much has changed as the Polygon-Shapefile currently is still empty and contains no spatial features. We will learn how we can add new features in the next section.</p> <p> </p> Figure 6: Situation after creating a shapefile."},{"location":"qgis/05-digitizing/#digitalization-of-new-spatial-objects-into-a-shapefile-layer","title":"Digitalization of new spatial objects into a Shapefile layer","text":"<p>In this section we will mostly work with the \u201cDigitizing toolbar\u201d which can be seen in Figure 7. In your case the buttons of the editing toolbar will most likely be still greyed out and only the button marked with \u201c2\u201d might be a active depending on which layer is currently selected in the layer window section of QGIS. So to activate the other buttons, we have to initialize the digitalization process. To do this, we</p> <p>we first select the newly created \u201cPolygon_tut5\u201d layer in the layer window. Then we initialize the digitalization process of this Shapefile by clicking the button marked with \u201c2\u201d in Figure 7. The Shapefile is now in the \u201cEditing mode\u201d and new spatial features can be added and old spatial features can be changed or deleted.</p> <p> </p> Figure 7: Filtering using the EPSG code. <p>As next step we will digitize the crater area of the vulcano and calculate its area. To accomplish this, we</p> <p>first zoom in to the vulcano area by using the zoom-in tool which we already know from the earlier tutorials. Then select the button marked with \u201c4\u201d in Figure 7. This button allows us to create a new spatial object - in this case a Polygon as we are editing a polygon shapefile. The symbol would differ in case we would edit a point or a line\u2013shapefile. After selecting the button, start digitizing the circumference of the vulcano crater by navigating the mouse cursor over the edges of the crater and performing a left\u2013click, then move the mourse cursor a bit further and perform another left\u2013click and so on until you have surrounded the whole crater (see Figure 8). When you are happy with your polygon, perform a right\u2013click to finish the polygon. QGIS will ask you to enter an id - you can either enter a number or just click \u201cOK\u201d. For the moment this option is not yet relevant.</p> <p> </p> Figure 8: Polygon surrounded the whole crater. <p>After finishing the polygon, the transparent colour of the \u201cpolygon-in-progress\u201d will change to a solid colour (see Figure 9). In case you do not like this format of the Polygons, you can switch the colour, or add transparency using the \u201cSymbology\u201d tab in the \u201cProperties\u201d window as you have learned in the earlier Tutorials. Be aware that you can also adapt the transparency of only the fill-colour while keeping the colour of the Outline solid (try to find out how this works!). If you are happy with your newly ceated Polygon click the button marked with \u201c3\u201d in Figure 7 to save the edits you made. If you do not want to add any further objects click button marked with \u201c2\u201d again to stop the editing mode.</p> <p> </p> Figure 9: Creating a new Polygon over the crater area of the vulcan. <p>In case you think that your Polygon is not accurate enough and you would like to correct some of the points between which the Polygon is spanned (this points are called \u201cnodes\u201d), QGIS offers a tool to adapt the shape of Polygons. This function is available when pressing the button marked with \u201c7\u201d in Figure 7. So let\u2019s try this out.</p> <p>First activate the editing mode as already learnt, then select the \u201cNode\u201d Tool (button 7) and then click on the Polygon you want to edit. In our case we only have a single Polygon. Once the Polygon has been selected, all nodes appear as rectangles and can now be rearranged / moved by putting the mouse cursor over them clicking and holding the left mouse\u2013button and draging them to the desired position - see Figure 10</p> <p> </p> Figure 10: Editing Nodes of a Polygon. <p>Now you are able to create new spatial objects and adapt the shape of an existing object. Next, we will have a quick look on the other buttons illustrated in Figure 7. First we will try to create a Polygon element of a circle. To do this, we</p> <p>click the button marked with \u201c5\u201d. Then we click somewhere in main visualization window of QGIS to set the starting point, a second time to set the ending point and a third time to set the point of maximum distance from the \u201cbaseline\u201d. Then QGIS will create an element of a circle as illustrated in Figure 11</p> <p> </p> Figure 11: The newly created element of a circle Polygon. <p>In our case this new polygon does not make too much sense. So we would like to delete it again. In order to this,</p> <p>we first select the \u201cSelect Feature\u201d button as highlighted in Figure 11 and then click on the newly created element of a circle Polygon. By clicking on it, it will be selected and turn its colour to yellow - see Figure 12 . To delete the element, we can either click on the button marked with \u201c8\u201d in Figure 7 or simply press the \u201cdel\u201d or \u201centf\u201d key on the keyboard.</p> <p> </p> Figure 12: Selecting the newly created element of a circle Polygon. <p>Now the polygon should disappear again. The remaining buttons are typically used less frequently, but are still very useful in some occasions. In brief, the button marked with \u201c6\u201d in Figure 7 allows to move complete spatial objects around after they have been selected with the \u201cSelect Feature\u201d tool. The buttons marked with \u201c9\u201d, \u201c10\u201d and \u201c11\u201d offer the possibilities to \u201ccut out\u201d, \u201ccopy\u201d and \u201cpaste\u201d polygons. To find out how this works,</p> <p>play around a bit with the buttons and try to create a situation which looks similar to Figure 13</p> <p> </p> Figure 13: Situation after copy and pasting the original polygon two times and shifting the pasted Polygons to new locations."},{"location":"qgis/05-digitizing/#buffer-analysis","title":"Buffer analysis","text":"<p>In this section, we will for the first time use a tool of QGIS that is not included in the standard processing tools and can only be found using the processing toolbox. Normally, the processing toolbox is already opened when opening QGIS (see box marked on the right part of Figure 14). In case it is not visible, it can be opened by selecting \u201cProcessing\u201d and then \u201cToolbox\u201d from the main menu of QGIS as also shown in Figure 14.</p> <p> </p> Figure 14: The processing toolbox. <p>Finding the correct tool that is able to conduct the action we want to perform on our data is not always easy. The best option is to directly know the name of the tool. This is similar to learning vocabulary in a foreign language. In case you know the name of the tool that you want to use, you can simply type in its name in the field marked with \u201c1\u201d in Figure 15. Alternatively, you can browse through the available tools by opening the menus in the \u201cProcessing Toolbox window\u201d. Typically, the tools are sorted according to their input data type, that is there are separate tools for raster datasets and vector datasets.</p> <p> </p> Figure 15: The processing toolbox. <p>You can find further tools including the most commonly applied ones in the main menu of QGIS where you can find the two menu sections called \u201cVector\u201d and \u201c Raster\u201d which contain plenty of options to process each datatype. It is highly recommended to also try out some of these tools and find out yourself what they are doing. In most cases there is also some further information given once the tool is started.</p> <p>The best way to learn to handle a GIS is to first learn the basics (for example using these Tutorials) but then also try out a lot on your own! Don\u2019t be shy!</p> <p>But back to our polygon. The first analysis tool we want to apply to our newly created Polygon is the \u201cbuffer-tool\u201d. It will create a zone of equidistance around an existing spatial feature. This will become fully clear once you see the results. So in order to create a buffer-Polygon around our existing Polygon, we</p> <p>write the word \u201cbuffer\u201d in the area marked with \u201c1\u201d in Figure 15. From the multiple options appearing we select the tool \u201cBuffer vectors\u201d from the \u201cGDAL/OGR toolbox\u201d and the \u201c[OGR] Geoprocessing\u201d menu (marked with \u201c2\u201d in Figure 15). By double clicking the tool, we can open a new window which allows us to specify the settings for the new buffer polygon we will create. In this window, we primarily have to define the buffer distance - in this case we set the distance to 500 - and we have to specify an output file. The corresponding fields are marked in Figure 16 with \u201c1\u201d and \u201c2\u201d. Then we click \u201crun\u201d and a new Shapefile containing the newly created buffer Polygon will be created and added to the QGIS project.</p> <p> </p> Figure 16: The processing toolbox. <p>After re-arranging the layers in the layer window section of QGIS, the new situation should look as shown in Figure 17. You can see that the new Polygon surrounds the old Polygon with a fixed distance of 500 m. It is important to consider that the buffer distance we defined in the preceding step is always in map units. In our case we used a UTM coordinate reference systems which is a metric system. So the defined buffer distance will be in meters. In case we would apply a buffer on a dataset projected in latitutde and longitude, the buffer distance would be in degree! So in case you experience that even with a small buffer distance the resulting buffer shapefiles become really large, it is likely that this relates to a problem of the buffer distance unit.</p> <p> </p> Figure 17: The processing toolbox."},{"location":"qgis/05-digitizing/#calculating-the-area-of-polygons-using-the-field-calculator-tool","title":"Calculating the area of Polygons using the Field Calculator tool","text":"<p>In this section, we will learn how to calculate the area of spatial polygon objects stored in a Shapefile. The same procedure can also be used to calculate lengths of Polylines and the x,y-coordinates of Points stored in Shapefiles. In our case we will calculate the area of the crater Polygon we have created earlier. To do this, we perform a right\u2013click on the \u201cPolygon_tut5\u201d layer in the layer window of QGIS and select the \u201cOpen Attribute Table\u201d option (see Figure 18).</p> <p> </p> Figure 18: Opening the attribute table. <p>This will open the new window displayed in Figure 19. Here we will now</p> <p>click the \u201cOpen Field calculator\u201d button marked with \u201c1\u201d.</p> <p> </p> Figure 19: The attribute table. <p>This will open another new window as seen in Figure 20. This new window represents the \u201cField calculator\u201d tool which is a powerful tool to update the attribute table of any vector layer and add new information to it. We will now use it to add a new columns to the attribute table of the Shapefile that contains the crater Polygon. As we can see in Figure 19, this Polygon currently contains only a single Polygon. We will later see other attribute tables with a lot more objects.</p> <p>To now add the area of our crater Polygon, we</p> <p>select \u201cCreate a new field\u201d, then we define an \u201cOutput field name\u201d by typing in \u201carea\u201d in the field marked with \u201c1\u201d in Figure 20. Next, we have to define the \u201cOutput field type\u201d. Here we click on the drop\u2013down\u2013menu marked with \u201c2\u201d and select \u201cDecimal number (real)\u201d. After selecting this option, the \u201cPrecision\u201d field marked with \u201c3\u201d gets activated.</p> <p>This field together with the field \u201cOutput field length\u201d defines how many digits can be stored in the new columns of the attribute table. This is similar to defining the cell format in Excel. In our case we want the area to be a decimal number which means that we can also have digitis behind the comma. As you remember from the thoretical lecture, the option \u201cWhole number (integer)\u201d can only store whole numbers like 1, 2, 3, 34, 789 etc., while a \u201cDecimal number (real)\u201d field is able to store decimal numbers such as 45.3 or 648.99932. The number of digits behind the comma are defined with the \u201cPrecision field\u201d while Output field lengths defines the number of total digits (digits before and after the comma together). So in our case,</p> <p>we will set the \u201cOutput field lengths\u201d to 15 and the \u201cPrecision\u201d to 2.</p> <p>A short summary what the other \u201cOutput field types\u201d mean is given in Table 1.</p> <p>Table 1: Output field types | Field type | Brief description | |--|--| | Whole number (integer) | This field type can store whole numbers (numbers without commas) between 2,147,483,648 and 2,147,483,647. Larger or smaller values cannot be stored | | Whole number (integer 64bit) | This field type is identical with \u201cWhole number (integer) but its value range is larger. It can stores numbers between 9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 | | Decimal number (real) | This is the field type that can store any numbers with decimals. | | Text (string) | This field type will store everything as text. Applying mathmatical functions will not work with this field type - even if only numbers are stored in the column. | | Date | This field type will only store Dates.</p> <p> </p> Figure 20: Opening the attribute table. <p>We have now defined how the output column of the attribute table that will store the \u201carea value\u201d of our Polygon should look like. Now we have to tell QGIS that it should calculate the area of the Polygon. To do this,</p> <p>we open the menu marked with \u201c4\u201d in Figure 20 and then double-click the option \u201c$area\u201d which will then also appear in the \u201cExpression\u201d section on the left, which has been empty so far.</p> <p>After conducting all these steps, the \u201cField Calculator\u201d window should look like shown in Figure 21. If this is the case, click \u201cOK\u201d and the window will disappear.</p> <p>If we now have another look at the attribute table of the \u201cPolygon_tut5\u201d Layer, we will see that a new column has been added to the attribute table that contains the area of the Polygon (see Figure 22). In our case the value is given in square meters as the defined UTM coordinate system is a metric system. For the Polygon created in this Tutorial the area is 249400.03 square meters. This value is likely to differ in your case, eventhough it should be similar.</p> <p> </p> Figure 21: Opening the attribute table. <p> </p> Figure 22: Opening the attribute table. <p>As a last step for this section, we will transform the area value given in square\u2013meters to square kilometers. Do this we will again use the field calculator tool:</p> <p>Open the attribute table of \u201cPolygon_tut5\u201d Layer, then click the \u201cField calculator\u201d button. Define a new field called \u201carea_km\u201d, select \u201cDecimal number (real)\u201d as \u201cOutput field type\u201d and set the \u201cOutput field length\u201c to 15 and \u201cPrecision\u201d to 5.</p> <p> </p> Figure 23: Field calculator. <p>All these steps should already be familiar. However, now a new aspect comes into to play. While we used the tool or command \u201c$area\u201d in the first application of the \u201cField calculator\u201d to calculate the area, we will this time use the just calculated \u201carea\u201d field as input to the \u201cExpression\u201d section, where we will define the function to transform the values given in square meters to values in square kilometers. To achieve this:</p> <p>we first open the menu called \u201cFields and Values\u201d as marked with \u201c1\u201d in Figure 23. Then we double\u2013click the entry \u201carea\u201d which is the column in the attibute table that we have just created. The \u201carea\u201d variable will now appear in the \u201cExpression\u201d editor to the left. We will now add the formula to transform square meters to square kilometers by first clicking the \u201cDivision operator\u201d marked with \u201c2\u201d in Figure 23 and then entering \u201c1000000\u201d as 1000000 square meter equal 1 square km. We then press \u201cOK\u201d.</p> <p>This will add another column to the attribute table that contains the area of the Polygon in square kilometers as seen in Figure 24.</p> <p> </p> Figure 24: Another column has been added to the attribute table."},{"location":"qgis/05-digitizing/#exercise","title":"Exercise","text":"<p>In Figure 23 you can see two red circles. The first circle in the West marks the area where a river connects with the sea. The second circle in the East marks the area where the river start to become hard to identify in the satellite image.</p> <p> </p> Figure 25: Start and end point for the Polyline to be created in the exercise. <p>To train the just learned skills you should now complete the following exercise:</p> <ol> <li> <p>Load the raster dataset \u201cS2_Neapel_sm2.tif\u201d. Adapt the visualization settings if you want.</p> </li> <li> <p>Create a new Shapefile of type \u201dLine\u201d.</p> </li> <li> <p>Digitize a spatial line object between the two red circles as shown in Figure 25. Follow the course of the river while digitizing the line object.</p> </li> <li> <p>Calculate the length of the river segment you have digitized in meters and kilometer.</p> </li> <li> <p>Adapt the visualization of newly created spatial line object and give the line a deep blue colour and a line width of 5 pixels.</p> </li> <li> <p>Zoom to the Polyline object you have created and export the current view by selecting \u201cImport/Export\u201d -&gt; \u201cExport Map to Image\u201d from the main menu of QGIS (Figure 26). This will be the proof that you have completed this Tutorial.</p> </li> </ol> <p></p>"},{"location":"qgis/06-selections/","title":"Spatial and semantic selection","text":"<p>Abstract</p> <p>After completing this tutorial you will know how to perform a spatial selection and a selection based on the contents of the attribute table of Shapefiles / vector files. Developed with QGIS version - Bialowieza 3.22.5</p> <p>In this Tutorial we will a new Shapefile named gis.osm_roads_free_1 that you can download here</p> <p>Don't forget to unzip the Shapefile.</p>"},{"location":"qgis/06-selections/#performing-a-spatial-selection-spatial-query","title":"Performing a spatial selection / spatial query","text":"<p>In this tutorial we will first learn how to perform a spatial selection, which means selecting a subset of spatial features of a vector shapefile based on their location. Then we will learn how we can select spatial features based on information stored in the attribute table.</p> <p>To start,</p> <p>we again load the raster dataset \u201cS2_Neapel_sm2.tif\u201d located in the \u201cDatasets/S2\u201d folder and adapt the visualization settings to have a balanced view of all classes by using the channels R=3, G=2, B=1 and loading new max / min values using the \u201cSymbology\u201d-tab in the properties window.</p> <p>Following the already known procedures, we will now create an empty Point shapefile by</p> <p>selecting the menu \u201cLayer\u201d then \u201cCreate Layer\u201d and \u201cNew Shapefile Layer\u201d. Be careful to select the correct coordinate reference system and select \u201cPoint\u201d as Shapefile Type. Then we will zoom into the area of the vulcano and create a new Point in the just created Point-Shapefile that is located in the center of the vulcano - by now you should already know how to accomplish this. We will then save our edits and stop the editing mode.</p> <p>This should lead to a similar situation as shown in Figure 1. Next, we will load the Shapefile \u201cgis.osm_roads_free_1\u201d by</p> <p>starting the dialogue to load a Shapefile (as already learned in Tutorial 2) and then navigating to the folder where you have saved the file provided above, select the file, and confirm with \u201copen\u201d.</p> <p> </p> Figure 1: Adding a point to the center of the crater. <p>This will result in the situation shown in Figure 2. The newly loaded Shapefile contains information on the position and type of the transportation network of the area. We now assume that our vulcano is in the mood for some chaos and erupts. Due to the magma flow all roads in a distance of 5000 m from the crater get destroyed. To be able to plan restoration measures and support emergency activities, we want to automatically select all roads in a distance of 5000 m from the crater center.</p> <p> </p> Figure 2: Loaded road network layer.    <p>We will accomplish this, using a spatial selection which is also called a \u201cspatial query\u201d. In QGIS this requires two steps. First, we need to create a buffer around the crater center point, which we have created as first step of this Tutorial. Then we can automatically identify all spatial features of the \u201c\u201cgis.osm_roads_subset\u201d layer that intersect with the buffer polygon.</p> <p>So as first step,</p> <p>use the buffer tool, you already know, to create a buffer with a distance of 5000 m around the point located in the center of the crater. After adapting the visualization settings of the Buffer (increase thickness of the outline to 2; set filling to transparent; change outline colour to red) you should see a situation as shown in Figure 3</p> <p> </p> Figure 3: Buffer in red over the road network layer.    <p>Next, we will learn two approaches to select all spatial features of the road network that are located within the buffer zone of the crater. For the first option, we will use</p> <p>the \u201cselect by location\u201d tool. This tool can be found in the toolbox under \u201cVector selection\u201d -&gt; \u201cSelect by Location\" as seen in Figure 4.</p> <p> </p> Figure 4: Opening the \u201cSpatial Query\u201d dialogue.    <p>this will open up a new dialogue as shown in Figure 5. In the new dialogue, we will parameterize the settings. We have to define the vector file from which we want to select some spatial features \u2013 in this case the road network layer \u2013 and we have to define the vector file which contains the spatial features which are used to define the area for selecting the spatial features - in our case the 5000 m buffer layer. We also have to define how the two vector files should interact to decide which features get selected. In this case we select \u201cintersect\u201d \u2013 this will select all spatial features of the road network layer that intersect with the buffer polygon. Finally, we select \u201cCreating new Selection\u201d to cancel all eventually earlier performed selections within the road network layer. If we now press \u201cRun\u201d we should create a situation as shown in Figure 6. As you can see, all roads located within the buffer are now selected and hence marked with yellow colour.</p> <p> </p> Figure 5: The \u201cSpatial query\u201d dialogue.    <p> </p> Figure 6: Situation after performing the spatial query."},{"location":"qgis/06-selections/#extracting-the-selected-features-to-a-new-shapefile","title":"Extracting the selected features to a new Shapefile","text":"<p>Now there are two option to proceed. We could either perform some additional analyses on the selected feature while keeping them in the original Shapefile. Or alternatively, we could store the selected features in a new Shapefile and then continue our analyses with this new layer. We will follow the latter approach here. So, to store the selected features to a new Shapefile, we will</p> <p> </p> Figure 7: Saving the selected features to a new Shapefile.    <p>first close the spatial query dialogue. Then we will perform a right click on the \u201cgis.osm_roads_free_1\u201d layer and from the appearing menu we will select \"Export\" and then \u201cSave Selected Features As...\u201d (see Figure 7). This will open up a new window as shown in Figure 8. Here, we will define an output name (field marked with \u201c1\u201d in Figure 8 and activate the checkbox \u201cSave only selected features\u201d (if not already activated) to store only the spatial features that have just been selected with the spatial query. After pressing \u201cOK\u201d the new Shapefile will be stored and added to the list of layers. After de-activating the \u201cgis.osm_roads_subset\u201d layer and dragging the newly created layer to the top of the layer window section, you will see a situation as shown in Figure 9.</p> <p> </p> Figure 8: The \u201cSave As...\u201d dialogue.    <p> </p> Figure 9: Situation after the selected spatial features have been saved to a new Shapefile."},{"location":"qgis/06-selections/#clipping-instead-of-selecting","title":"Clipping instead of selecting","text":"<p>An alternative to the just described work-flow of first selecting the Polygons within the buffer and then to save the selected features as a new Shapefile, is to directly clip-out all spatial features located within the buffer zone. We will now follow this approach by applying the \u201cClip\u201d tool. We can open the corresponding dialogue by</p> <p>selecting \u201cVector\u201d -&gt; \u201cGeoprocessing Tools\u201d -&gt; \u201cClip\u201d from the main menu of QGIS as shown in Figure 10. This will open the \u201cClip tool\u201d shown in Figure 11. Here, we have to define the \u201cInput Layer\u201d from which we want to create a subset, and the \u201cClip Layer\u201d which will be used to define the spatial area for which a subset of the \u201cInput Layer\u201d will be created. In our case the \u201cgis.osm_roads_free_1\u201d layer will be the \u201cInput Layer\u201d and the \u201cBuffer layer\u201d will be the Clip Layer. We additionally define an output name (\u201cClipped\u201d) for the new Shapefile and press \u201cRun\u201d. </p> <p>Then a new Shapefile will be created. After rearranging the layers a bit and changing the visualization settings, it becomes clear that this process has led to almost the same results as the preceding workflow. In Figure 12, the two Shapefiles are positioned on top of each other with one of the two layers having an outline with a larger line width. You can see that the two Shapefiles extracted using the Buffer-Shapefile with two different approaches match perfectly within the buffer zone, but the result from the first procedure has some road segments that expand over the buffer zone. This is because in the first procedure we did not use the buffer to cut intersecting line segments but we selected the \"complete\" line segments which intersected in any point with the buffer zone.</p> <p> </p> Figure 10: Opening the \u201cClip\u201d tool. <p> </p> Figure 11: The \u201cClip\u201d tool dialogue. <p> </p> Figure 12: The two extracted subsets of the road network using the buffer Shapefile match perfectly. One of the two subsets is displayed in a wide orange line, and the second subset in a more narrow red line."},{"location":"qgis/06-selections/#performing-a-query-on-the-attribute-table","title":"Performing a query on the attribute table","text":"<p>We have now a Shapefile containing all roads that have been affected by the eruption of the vulcano. Now we would like to have a closer look at the road types that have been affected. To do this, we will first open the attribute table of one of the two Shapefiles containing only the roads located in the buffer zone. We open the attribute table by</p> <p>performing a right\u2013click on the corresponding layer and selecting \u201cOpen attribute table\u201d. This will open the attribute table as shown in Figure 13. The attribute table has 10 columns in total.</p> <p> </p> Figure 13: The attribute table of the road layer. <p>Here, we will focus on the column named \u201cfclass\u201d which contains information about the type of road. Let us assume that the type of road is important for estimating the cost to restore the path systems after the eruption of the vulcano as well as to prioritize restoration works.</p> <p>So in the next step, we will create two more subsets from the Shapefile containing all affected roads. First, we will extract all spatial features that belong to the class \u201csecondary\u201d \u2013 which relate to the largest affected roads in the area. Then, we will extract all spatial features belonging to the classes containing the word \u201ctrack\u201d \u2013 there are in total 5 classes which contain the word \u201ctrack\u201d. Tracks are important for recreational activities and tourism.</p> <p>So let us first create a subset of all \u201csecondary\u201d roads. To do this, we</p> <p>will perform a selection based on the fclass column using the tool \u201cSelect features using an expression\u201d (marked with \u201c1\u201d in Figure 13). After clicking on the tool a new dialogue will appear which looks similar to the \u201cField calculator\u201d we already got to know in Tutorial 5 (see Figure 14). With this tool, we can automatically select all features of the vector file that match a user\u2013defined rule. In the given case we will set this rule to \u201cfclass\u201d = \u2019secondary\u2019 as shown in 14. To enter this rule, we first open the menu called \u201cFields and Values\u201d marked with \u201c1\u201d in Figure 14. Then we perform a double\u2013click on the entry \u201cfclass\u201d as this is the column of the attribute table which we want to use to perform our selection. Now, \u201cfclass\u201d will appear in the \u201cExpression\u201d field on the left marked with \u201c4\u201d. To illustrate all unique entries of this column of the attribute table, we click the \u201call unique\u201d button marked with \u201c2\u201d. If the \"All UNique\" button is not shwoing, you might have to additionally press \"Show Values\"-button first.  Now all different classes listed in the \u201dfclass\u201d column will appear. Next, we click the \u201c=\u201d sign marked with \u201c3\u201d and then we double\u2013click the entry \u2019secondary\u2019 marked with \u201c5\u201d. We then press \u201cSelect Features\u201d to query all entries of the attribute table and select all entries where our rule matches.</p> <p> </p> Figure 14: The select features by expression tool. <p>As we can see from the results, there is only a single entry in the column \u201cfclass\u201d that belongs to the class \u201csecondary\u201d. This single spatial feature is a roundabout close to lower left border of the buffer zone (see Figure 15). It might be hidden below the outline of the buffer polygon. You can for sure find it, if </p> <p>perform a right-click on the layer with the selected feature and use the \"Zoom to Selection\" option to zoom the current view to the selected polygon</p> <p>As this is a rather small subset, we will try to additionally select all entries of the fclass column that belong to the class \u201ctertiary\u201d which is the next smaller category of roads. To do this,</p> <p>we re\u2013open the attribute table and the \u201cSelect features using an expression\u201d. This time we will set the rule to \u201cfclass\u201d = \u2019secondary\u2019 OR \u201cfclass\u201d = \u2019tertiary\u2019 (see Figure 16). Then we press \u201cselect\u201d and close the tool and the attribute table. The \u201cOR\u201d can either be directly typed into the \u201dExpression\u201d field or it can be found from the menu \u201cOperators\u201d.</p> <p> </p> Figure 15: Only a single spatial feature got selected. <p> </p> Figure 16: Adapting the selection rule to increase the subset. <p>Now several more roads got selected as can be seen in Figure 17. We can now save this subset by</p> <p>**performing a right\u2013click on the layer containing the spatial attributed located in the buffer zone and selecting \"Export\" -&gt; \u201cSave Features As...\u201d. Then we select an Output filename, make sure that the option \u201cSave only selected features\u201d is activated and press \u201cOK\u201d. ALternatively, you can directly use the \"Save Selected Features AS...\" button then the \"Save only selected features\u201d button should already be activated **</p> <p> </p> Figure 17: Spatial location of all \u201csecondary\u201d and \u201ctertiary\u201d roads within the buffer zone. <p>As a final step of this Tutorial we will save an additional subset with a slighly more complex rule. To do this, we</p> <p>re\u2013open the attribute table of the Shapefile containing the spatial features located in the buffer zone. Then we open the \u201cSelect features using an expression\u201d tool as done before. Instead of naming a single class of the \u201cfclass\u201d column we will this time select all classes that contain the text-part \u201ctrack\u201d. To do this, we will set the rule to \u201cfclass\u201d LIKE \u2019%track%\u2019 (see Figure 18). The operator \u201cLIKE\u201d can also be found in the \u201coperator\u201d menu as marked with \u201c1\u201d in Figure 18. This operator will search for all entries in the fclass column that contain the text\u2013part \u201ctrack\u201d and will select it. The \u201c%\u201d\u2013sign is a placeholder for any textparts that can come before or after the text\u2013part \u2019track\u2019. Then we press \u201cSelect\u201d.</p> <p> </p> Figure 18: Using the \u201cLIKE\u201d operator to construct a more complex selection rule. <p>With these settings a total of 109 spatial features gets selected (your total number of features might slightly differ depending how your center point for the crater and the corresponding buffer zone was defined). The locations of the selected features are shown in Figure 19. If we open the attribute table and scroll down a bit, we can see that all entries of the flcass column that contain the text\u2013part \u201ctrack\u201d got selected, including for example the classes \u201ctrack\u201d, \u201ctrack_grade1\u201d, \u201ctrack_grade2\u201d and so on (see Figure 20).</p> <p> </p> Figure 19: Locations of all spatial features containing the text\u2013part \u201ctrack\u201d in their fclass label. <p> </p> Figure 20: All classes containing the text\u2013part \u201ctrack\u201d got selected in the attribute table."},{"location":"qgis/06-selections/#exercises","title":"Exercises","text":"<p>To further practice the just learned skills, you should now complete the following exercises:</p> <ol> <li> <p>Build a subset of all spatial elements belonging to the class \u201cfootway\u201d as defined in the \u201cfclass\u201d column of the road\u2013layer within the buffer zone</p> </li> <li> <p>Create a subset of all spatial elements belonging to the class \u201cresidential\u201d and having a length longer than 150 m.</p> </li> <li> <p>Adapt the visualization of the two newly created subsets. All footway-elements should be in red colour and with a line width of 3 points; all residential-elements should be in green colour and with a line width of 5 points. Only the satellite image and the two newly created subsets should be active in the display.</p> </li> <li> <p>Zoom to the buffer area and export the current view by selecting \u201cProject\u201d -&gt; \u201cSave as Image\u201d from the main menu of QGIS. This will be the proof that you have completed this Tutorial.</p> </li> </ol>"},{"location":"qgis/07-elevation/","title":"Working with elevation raster datasets","text":"<p>Abstract</p> <p>After completing this tutorial you will know how to work with raster files containing elevation data. You will be able to calculate an aspect image, a slope image and know how to set height thresholds. Furthermore, you will learn how a raster file can be clipped to a desired extent and how an elevation raster can be transformed to height contour lines and how labels can be added to a vector file. Last but not least, you will learn how to re\u2013project raster files in QGIS to adapt their coordinate reference systems. Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/07-elevation/#reprojecting-and-cutting-a-raster-to-a-desired-extent","title":"Reprojecting and cutting a raster to a desired extent","text":"<p>In this tutorial we will learn how we can use a raster dataset containing elevation information to extract additional information concerning for example the exposition also referred to as aspect (which direction a certain pixel or area is facing) or the steepness (slope) of a certain location in the raster dataset. In this Tutorial we will make use of a elevation dataset provided by United States Geological Survey (USGS). This dataset stems from a satellite mission called ASTER. The data of ASTER was transformed to an almost global elevation dataset by analysing a huge amount of satellite images that were collected from differing view angles (typically more than 10 and in some cases over 30 satellite images for each location of the Earth). Elevation datasets can also be collected from other sources including field data (for example using traditional survey techniques which is rather time-intensive or GPS which is faster but also less precise as the z-position generally works not as accurate as x- and y-position using standard GPS devices) and remote sensing data as for example airborne laserscanning or since recently also airborne photogrammetry using aerial images. The currently most accurate, spatially continuous elevation datasets can be collected with laserscanning devices mounted on airplanes or helicopters (we will hear about this in the theoretic lectures after the  christmas break).</p> <p>However, as stated before, in this tutorial we will use the freely available ASTER datasets with a pixel size of approximately 30 m.</p> <p>As a first step</p> <p>we again load the raster dataset \u201cS2_Neapel_sm2.tif\u201d located in the \u201cDatasets/S2\u201d folder and adapt the visualization settings to have a balanced view of all classes by using the channels R=3, G=2, B=1 and loading new max / min values using the \u201cSymbology\u201d-tab in the properties window. Then we add the ASTER dataset which is called \u201cASTGTM2_N40E014_dem.tif\u201d and which can be downloaded here:</p> <p>https://drive.google.com/file/d/1TjHeuPUX_SLzBFrQqblocHJOUJg45UTG/view?usp=share_link</p> <p>This will lead to the situation shown in Figure 1. There are now two problems that we need to address. The first problem is not directly apparent, but currently the ASTER dataset and the satellite image have differing coordinate systems. This could lead to some problems when both images are used jointly in a geoprocessing tool. Hence, as a first step, we will reproject the ASTER dataset to the same coordinate reference system as the satellite image.</p> <p> </p> Figure 1: After loading the two raster datasets.    <p>Furthermore, as you can see in Figure 1 the elevation dataset covers an area that is larger than the satellite image and hence overlaps it completely. We will address this problem in a second step by clipping the ASTER dataset. But let us start with the reprojection.</p> <p>To re\u2013check whether the ASTER dataset really has a different coordinate reference system (CRS) than the satellite image we can</p> <p>perform a right\u2013click on the \u201cASTGTM2_N40E014_dem\u201d layer and select \u201cProperties\u201d. Then we select the \u201cSource\u201d tab and as seen in Figure 2, the current CRS is set to EPSG 4326. If we now check the same entry for the \u201cS2_Neapel_sm2\u201d layer, we will see that here the CRS is set to EPSG 32633. This is also the CRS defined for the current QGIS project as seen in the bottom right of the QGIS project (next to the little world globe). We close the window by pressing \u201ccancel\u201d and then start the \u201cReproject\u201d tool by selecting \u201cRaster\u201d -&gt; \u201cProjections\u201d -&gt; \u201cWarp (Reproject)...\u201d from the main menu in QGIS as shown in Figure 3</p> <p> </p> Figure 2: The coordinate system of the ASTER elevation dataset.    <p> </p> Figure 3: Opening the \u201cWarp\u201d tool. <p>This will open a new dialogue as seen in Figure 4. Here we can reproject the ASTER elevation data by</p> <p>first selecting the \u201cASTGTM2_N40E014_dem\u201d layer as input file in the field marked with \u201c1\u201d. After selecting the ASTER layer, the field \u201cSource CRS\u201d is automatically updated to match the CRS of the selected layer. Then we set an output file in the field marked with \u201c2\u201d and we need to specify a target CRS in the field marked \u201c4\u201d. In this case, we will select the CRS with the EPSG code 32633 which is the same CRS as currently defined for the satellite image. After defining the correct Target CRS we press \u201cOK\u201d and QGIS will re-project the raster and add it as a new layer. If you now check the CRS of the new layer by performing a right\u2013click, selecting \u201cProperties\u201d and the \u201cGeneral\u201d tab, you will see that the CRS is now also set to 32633.</p> <p> </p> Figure 4: Parameterizing the \u201cWarp\u201d tool. <p>As next step, we will clip the re-projected elevation dataset to match roughly the extent of the satellite image. To do this we</p> <p>select \u201cRaster\u201d -&gt; \u201cExtraction\u201d -&gt; \u201cClip Raster by Extent\u201d from the main menu in QGIS as shown in Figure 5. This will open a new dialogue as shown in Figure 6. In the given case we have to define three variables. We have to select the \u201cASTGTM2_N40E014_dem\u201d layer as input dataset in the field marked with \u201c1\u201d. Then we have to define an output filename in the field marked with \u201c2\u201d. Finally, we have to define the clipping extent by drawing a rectangle in the QGIS window after pressing the drop down menu (marked with \u201c3\u201d in Figure 5) and selecting \"draw on canvas\". We now draw a rectangle in the main visualization window which matches roughly the extent of the satellite image as seen in Figure 6. Then we press \u201cOK\u201d to clip the raster.</p> <p>It of course helps to drag the satellite image above the elevation dataset in the \u201clayer window\u201d section of QGIS for drawing the rectangle as the satellite image is otherwise fully covered by the elevation dataset. Please make also sure that you select the re\u2013projected elevation dataset as input file as otherwise an error message might appear that originates from the differing CRS systems, eventhough this might not be apparent from the error message.</p> <p> </p> Figure 5: Opening the \u201cclip\u201d tool. <p> </p> Figure 6: Parameterizing the clip-tool in QGIS."},{"location":"qgis/07-elevation/#calculating-slope-and-aspect-images-from-a-digital-terrain-model","title":"Calculating slope and aspect images from a digital terrain model","text":"<p>We have just successfully re\u2013projected and clipped our elevation dataset. Next, we will calculate a slope and an aspect image from the elevation dataset. We will start with calculating a slope image by,</p> <p> </p> Figure 7: Searching and selecting the \u201cSlope\u201d tool in the processing toolbox of QGIS. <p>selecting \u201cProcessing\u201d -&gt; \u201cToolbox\u201d from the main menu in QGIS to open the Processing Toolbox window (in case it is not already open). Then we will type \u201cslope\u201d into the search field of the Processing Toolbox window (marked with \u201c1\u201d in Figure 7) and select the tool \u201cslope\u201d as marked with \u201c2\u201c in Figure 7. In the new dialogue, we select the re\u2013projected and clipped elevation dataset as input file, define an output file and leave all other settings as they are (see Figure 8). We then confirm by pressing \u201crun\u201d.</p> <p> </p> Figure 8: Parameterizing the \u201cslope\u201d tool in QGIS. <p>The newly created slope image should now appear in the main visualization window of QGIS (see Figure 9). The slope image shows the steepness of the terrain for each pixel of the raster dataset. If you compare the patterns of the slope image with the satellite scene, you will see that for example most of the urban areas are located in rather flat areas, while the mountainous areas and the vulcano have notably higher slopes.</p> <p> </p> Figure 9: The slope image for study area. <p>We can now calculate the aspect image accordingly, by</p> <p>typing \u201caspect\u201d into the search field of the Processing Toolbox window (marked with \u201c1\u201d in Figure 10) and select the tool \u201caspect\u201d as marked with \u201c2\u201c in Figure 10. In the new dialogue, we select the re\u2013projected and clipped elevation dataset as input file (see field marked with \u201c1\u201d in Figure 11), define an output file and leave all other settings as they are (see Figure 11 except for the option \u201cReturn 0 for flat (instead of -9999)\u201d as marked with \u201c2\u201d which we activate by checking the box. We then confirm by pressing \u201crun\u201d.</p> <p> </p> Figure 10: Searching and opening the \u201caspect\u201d tool in the processing toolbox of QGIS. <p> </p> Figure 11: Parameterizing the \u201caspect\u201d tool. <p>The newly created \u201caspect\u201d image should now appear in main visualization window of QGIS. As you can see in Figure 12, the aspect image is a quite nice visualization of the terrain situation within the area as for examples valleys show contrasing aspect values for each side of the valley which are typically facing opposite directions and hence become very clearly visible in the aspect image. This is particularly well visible in the southern and eastern parts of the image where mountainous terrain is dominating the landscape.</p> <p> </p> Figure 12: The aspect image of the study area."},{"location":"qgis/07-elevation/#extracting-contour-lines-from-the-digital-terrain-model","title":"Extracting contour lines from the digital terrain model","text":"<p>Currently our elevation data is stored in a raster layer dataset. On the one hand side this advantageous as we have a height value for each position in out test area. However, on the negative side, we cannot display the satellite image and the height information at the same time as only one raster dataset can be efficiently displayed at one time. A well-known alternative to an elevation raster dataset are height iso-lines also called contour lines which are frequently applied in topographic maps. In QGIS there is an option to automatically create contour lines from the elevation raster dataset. We will now make use of this option by</p> <p>selecting \u201cRaster\u201d -&gt; \u201cExtraction\u201d -&gt; \u201cContour...\u201d from the main menu of QGIS as shown in Figure 13. In the new dialogue we select the re\u2013projected and clipped raster file as Input file (field marked with \u201c1\u201d in Figure 14), define an output file for the contour lines (field marked with \u201c2\u201d), we set the height interval to 50 m (field marked with \u201c3\u201d). We can change the \u201cAttribute name\u201d (marked with \u201c4\u201d) if we want to. We then press \u201cOK\u201d to calculate the contour lines.</p> <p> </p> Figure 13: Opening the \u201cContour\u201d tool in QGIS. <p> </p> Figure 14: Parameterizing the \u201cContour\u201d tool. <p>This will create the contour lines as illustrated in Figure 15. However, with the given illustration, the contour lines do not yet carry a lot information. We can see which pixels in the image have identical height values but we do not yet see where high and low values are. Hence, we will now add some labels to the contour lines indicating the height of the corresponding contour line.</p> <p> </p> Figure 15: The contour lines extracted from the elevation dataset. <p>To add labels to the contour lines vector file, we</p> <p>right\u2013click on the contour lines layer and select \u201cProperties\u201d. Then, we select the \u201cLabels\u201d tab from the menu on the left. This will lead to the dialogue window shown in Figure 16. In this window we will first change the drop down menu marked with \u201c1\u201d to the option \u201cSingle labels\u201d. Next, we have to define the column of the attribute table which contains the labels we want to show in the map. We do this by selecting the entry \u201cELEV\u201d using the drop down menu marked with \u201c2\u201d. We can additionally change the size of the label\u2013text and the colour using the options marked with \u201c3\u201d and \u201c4\u201d. We then press \u201cOK\u201d.</p> <p> </p> Figure 16: Adding labels to the contour lines extracted from the elevation dataset. <p>This will result in the situation depicted in Figure 17 where we can now see the contour lines with labels indicating their height.</p> <p> </p> Figure 17: Contour lines with labels added."},{"location":"qgis/07-elevation/#applying-thresholds-to-a-raster-file","title":"Applying thresholds to a raster file","text":"<p>As final step of this Tutorial, we will learn how to apply thresholds to raster files using the elevation data as an example. We will use the raster calculator tool to accomplish this. Thresholds are used to define all areas located above or below a certain value. In our example these will be elevation heights, however, in theory thresholds can be set for any raster file.</p> <p> </p> Figure 18: Opening the \u201craster calculator\u201d. <p>we will now learn two approaches for setting thresholds. We will first</p> <p>open the raster calculator by selecting \u201cRaster\u201d -&gt; \u201cRaster Calculator...\u201d from the main menu in QGIS as shown in Figure 18. Now the \u201craster calculator\u201d tool will be opened as seen in Figure 19. We will now create our first threshold image by composing a rule (here called expression) which defines the threshold we want to apply. To do this we first define an output file using the field marked with \u201c2\u201d, then we double-click the clipped and re\u2013projected elevation data layer listed in the \u201cRaster Bands\u201d section marked with \u201c1\u201d. When double-clicking the layer, it will appear in the \u201cRaster calculator expression\u201d section marked with \u201c3\u201d. We will now complete the expression by first clicking the \u201cgreater than\u201d button marked with \u201c4\u201d and then entering the digits \u201c50\u201d into the expression window. With this expression, all pixels in the re\u2013projected and clipped elevation raster with values above 50 m will be set to 1 and all pixels with values below 50 m will be set to 0. To check whether this works, we press the \u201cOK\u201d button.</p> <p> </p> Figure 19: Defining a threshold rule in the \u201craster calculator\u201d. <p>This will lead to the situation shown in Figure 20 where we can see that a binary raster image has been created where all pixels in the rasterfile have either a value of 0 or 1. We can clearly see, that especially the areas around the vulcano and the areas in the South and East \u2013 from which we know that they are rather mountainous \u2013 were found to have elevations above 50 m as indicated by the white colour which stands for a value of 1.</p> <p>Be aware that it could also happen that you see a completely grey output image. In this case you might have to adapt the symbology of the raster and define a minimum value of 0 and a maximum value of 1. You should already be familiar with the steps you have to conduct to accomplish this.</p> <p> </p> Figure 20: The resulting binary mask showing all areas with elevation above 50 m. <p>One thing, that we could see critical in the current binary image is that we make no difference between areas on land and in the sea. In the elevation dataset, all areas covered by sea have a fixed elevation value of 0. So in the next step, we will apply another threshold but this time we want to extract all areas that are located higher than 0 m and lower than 50 m. To do this,</p> <p>re\u2013open the raster calculator tool as learned above. This time we set the threshold expression as indicated in Figure 21. We then press \u201cOK\u201d.</p> <p>This will lead to a new situation as shown in 22. We can now see that especially the central part of the image and some parts along the coast fulfill the criteria of having an elevation between 0 and 50 m. We now might be interested to overlay this information with our satellite image. Currently, the raster layer is just black and white and we can only activate and deactivate the layer to see which areas in the satellite scene are located between 0 and 50 m. In the following we will learn a more elegant approach for visualizing both datasets together.</p> <p> </p> Figure 21: Defining a slightly more complex threshold rule. <p> </p> Figure 22: Resulting binary image when applying the slightly more compley rule."},{"location":"qgis/07-elevation/#converting-raster-datasets-to-vector-polygons","title":"Converting raster datasets to vector polygons","text":"<p>One way to mark all areas of the satellite image located at elevations between 0 and 50 m is to first transform the threshold raster layer to a polygon file and then only keep the Polygons that have a value of 1 (that means, they match the rule defined above of having a location between 0 and 50 m). To do this, we</p> <p>select \u201cRaster\u201d -&gt; \u201cConversion\u201d -&gt; \u201cPolygonize (Raster to Vector)...\u201d from the main menu in QGIS as shown in Figure 23. In the new dialogue shown in Figure 24, we only have to define an output file and then press \u201cOK\u201d.</p> <p> </p> Figure 23: Opening the tool to \u201cPolygonize Raster to Vector files\u201d. <p> </p> Figure 24: Parameterizing the \u201cPolygonize Raster to Vector\u201d tool. <p>This will create a Shapefile that matches the patterns of the raster layer. Polygons will be composed by stitching all spatially connected pixels having either a value of 0 or a value of 1 together. The corresponding resulting polygon layer can be seen in Figure 25.</p> <p> </p> Figure 25: The polygon layer created with the \u201cPolygonize Raster to Vector\u201d tool. <p>In Figure 26 you can see the same file after the visualization settings of the Polygon vector layer have been adapted. This view can be reached by</p> <p>right\u2013clicking the newly created polygon layer and selecting \u201cProperties\u201d and then clicking the \u201cSymbology\u201d tab. Here, we now select the \u201dCategorized\u201d display option from the drop\u2013down menu marked with \u201c1\u201d in Figure 27. We then select \u201cDN\u201d in the \u201cColumn\u201d field marked with \u201c2\u201d and press classify (marked with \u201c3\u201d) which will display the two different values of the DN column in the attribute table which was created based on the digital numbers (DN) of the raster layer which we transformed to Polygons in the preceeding step. We can now adapt the colours of both categories by double clicking the squares in the \u201cSymbol\u201d column of the section marked with \u201c4\u201d and as learned in Tutorial 2. Here, the colour for the outline and filling of the Polygons with value 0 were set to transparent to make them visually disappear. Polygons with a DN value of 1 were set to a transparent red. Try to accomplish this on your own by adapting the visualization settings in the \u201cStyle tab\u201d of the \u201cProperties dialogue\u201d as learned in the earlier Tutorials.</p> <p> </p> Figure 26: Polygon layer with adapted visualization settings. <p> </p> Figure 27: Visualization settings of the polygon vector layer."},{"location":"qgis/07-elevation/#exercises","title":"Exercises","text":"<p>To further practice the work with elevation datasets, try to identify the top height of the vulcano by using the Info\u2013Button of the main menu of QGIS which you already know from Tutorial 4. Report the approximate top height in a Word-Document.</p> <p>Furthermore, let us assume that a certain endemic plant species of this region of Italy only grows in altitudes between 300 and 800 m. To identify the potential habitat of this species in our study area, create a Polygon layer that marks all areas located between an elevation of 300 and 800 m. Adapt the visualization settings of this Polygon by changing the color to green and set the transparency to 50 percent. Then make sure that only the satellite image and the just created Polygon are activated in the current display (Polygon on top of the satellite image). Then zoom to the full extent of the satellite image and export the current view by selecting \u201cProject\u201d -&gt; \u201cSave as Image\u201d from the main menu of QGIS. This will be the proof that you have completed this Tutorial.</p>"},{"location":"qgis/08-map-making/","title":"Making a map","text":"<p>Abstract</p> <p>After completing this tutorial you will know how to create basic maps in QGIS with an appropriate legend, a north arrow, a coordinate grid and a scale. Developed with QGIS version - Bialowieza 3.22.5</p>"},{"location":"qgis/08-map-making/#preparing-the-data-for-the-map-reprojecting-and-cutting-a-shapefile-to-a-desired-extent","title":"Preparing the data for the map: Reprojecting and cutting a Shapefile to a desired extent","text":"<p>In this tutorial we will learn how to create basic maps in QGIS. As a first step</p> <p>we again first load the raster dataset \u201cS2_Neapel_sm2.tif\u201d and adapt the visualization settings to have a balanced view of all classes by using the channels R=3, G=2, B=1 and loading new max / min values using the \u201cSymbology\u201d- tab in the properties window. Then we additionally load the \u201cgis.osm_landuse_a_free_1\u201d layer provided in one of the earlier tutorials.</p> <p>This will lead to the situation shown in Figure 1.</p> <p> </p> Figure 1: The two loaded datasets. <p>For creating the map, we would like the applied datasets to cover the same extent. So as next step, we will clip the Shapefile so that its extent matches the extent of the satellite image. To accomplish this, we will </p> <p>select \u201cProcessing\u201d -&gt; \u201cToolbox\u201d from the main menu in QGIS to open the Processing Toolbox window (in case it is not already open). Then we will type \u201cclip vector\u201d into the search field of the Processing Toolbox window (marked with \u201c1\u201d in Figure 2) and select the tool \u201cclip vectors by extent\u201d as marked with \u201c2\u201c in Figure 2. In the new dialogue, we select \u201cgis.osm_landuse_a_free_1\u201d layer as input layer and then press the \u201c...\u201d button marked with \u201c1\u201d in Figure 3. This will open a another menu from which we select the first option \u201cCalculate from Layer\u201d. In the newly opened window, we then select the satellite image \u201cS2_Neapel_sm2 [EPSG:32633]\u201d. We define an output file and click \"Run\".</p> <p> </p> Figure 2: Loading the clip vector tool from the Processing toolbox. <p> </p> Figure 3: Calculating the clip extent from a layer. <p>After re\u2013arranging the layers to put the clipped Shapefile on top of the other layers, the main visualization window of QGIS should look as shown in Figure 4. The colours are of course likely to differ. In Figure 7 we can now see that the Shapefile was clipped to the extent of the satellite image.</p> <p> </p> Figure 4: The clipped Shapefile on top of the satellite image. <p>Be aware that the land-cover layer at the moment is still in the geographic coordinate system (EPSG code: 4326). While this is not absolutely problematic in this tutorial since QGIS is able to reproject the file \"on-the-fly\" you can still reproject the vector layer to UTM if you prefer to have all data in the same coordinate reference system. You should already be familiar with this process from the last tutorial.</p>"},{"location":"qgis/08-map-making/#preparing-the-data-for-the-map-adapting-the-visualization-settings-of-the-shapefile","title":"Preparing the data for the map: Adapting the visualization settings of the Shapefile","text":"<p>As a next step, we have to prepare all the contents and visualization settings that we would like to integrate into our final map. In our case, we will display only the clipped and re\u2013projected Shapefile as main information source to create a land\u2013cover map and use the satellite image in the background. As next steps, we will therefore adapt the visualization settings of the Shapefile by selecting a categorized visualization setting in the \u201cSymbology\u201d tab of the \u201cProperties dialogue\u201d. We then manually adapt the colour of all land\u2013use classes so that they reasonably well match their meaning. For example, it might be a good idea to assign a green colour to vegetation classes. The basic process to accomplish this should already be known from Tutorial 2.</p> <p>So, as a next step, try to adapt the visualization settings of the Shapefile in a way that the main visualization window of QGIS looks similar as seen in Figure 5.</p> <p> </p> Figure 5: Situation after adaping the visualization options of the Shapefile containing the land\u2013use\u2013classes."},{"location":"qgis/08-map-making/#starting-the-print-composer-dialogue","title":"Starting the print composer dialogue","text":"Figure 6: Opening the print composer dialogue. <p>We are now ready to initiate the preparation of a map. In QGIS all functions to create a map are hidden in the \u201cprint Layout\u201d-Tool which can be accessed from the main menu of QGIS. We will now try this by</p> <p>selecting \u201cProject\u201d -&gt; \u201cNew Print Layout...\u201d from the main menu of QGIS as illustrated in Figure 9. This will first open a pop\u2013up window (Figure 7) which will ask you for the name of your new map. We will enter \u201cmap1\u201d here and confirm by clicking \u201cOK\u201d. This will open a new window depicting a completely new graphical user interface as shown in Figure 8.</p> <p> </p> Figure 7: Entering a name for the new print layout project/map. <p> </p> Figure 8: Overview over the print composer user interface. <p>This new graphical user interface provides all functionalities to compose a map based on the geodata displayed in the QGIS project. In Figure 8 an overview over the main sections of the print composer tool is given.</p> <p>The area marked with \u201c1\u201d provides general tools to start composing a new map, store or duplicate a current map project and save a current project as a template. Furthermore, some options to export the current display to a file are provided.</p> <p>The tools in the area marked with \u201c2\u201d allow to refresh the current contents displayed in the map and to zoom within the map itself (not in the map contents).</p> <p>The tools marked with \u201c3\u201d allow to navigate and adapt the extent of the displayed map contents.</p> <p>The tools marked with \u201c4\u201d allow to add items to the map including for example a North arrow, the current geodata displayed in the main visualization window of QGIS, a legend, etc.</p> <p>The section marked with \u201c5\u201d provides additional information for all items that are currently included in the map composer project. To access the options of a item, the item has to selected in the main visualization area of the print composer tool (white area marked with \u201c6\u201d).</p>"},{"location":"qgis/08-map-making/#adding-items-to-the-map","title":"Adding items to the map","text":"<p>We will now start composing our map by first of all adding the current visualization of the QGIS project to the map. We will do this by</p> <p>selecting the \u201cadd map\u201d button marked with \u201c1\u201d in Figure 9 and then drawing a rectangle in the main visualization area of the map composer tool as shown in Figure 12.</p> <p> </p> Figure 9: Adding a map to the print composer view. <p>This will add the current QGIS project visualization to the map as shown in Figure 10. This map item can now be seen as a \u201cplaceholder\u201d that will always show the current visualization of the QGIS project if the view is updated. It will not update itself automatically. In Figure 13 you can see that the actual map content is not fully filling out the frame of the map\u2013item we have just created. We can address this problem by on the one hand side moving the map contents within the map\u2013item frame by using the tool marked with \u201c1\u201d in Figure 10 and on the other hand by adapting the current scale of the map. This can be achieved by first selecting the map\u2013item in the main visualization window and then selecting the \u201citem properties\u201d tab as marked with \u201c2\u201d in Figure 10. Then we can change the scale by changing the number given in the field marked with \u201c4\u201d. The smaller we make this number, the more we will zoom into the map. We can try this by</p> <p>changing the current value of around 137.000 to 50.000. After changing the value we have to press the \u201cUpdate preview\u201d button marked with \u201c3\u201d in Figure 13 to refresh the current view of the map.</p> <p> </p> Figure 10: Adapting the displayed extent of the geodata in the print composer view <p>The \u201cUpdate preview\u201d button has is a quite important tool. You will have to use it always if you change something in the map contents. That is, if you decide to activate or deactivate some of your geodata in the main visualization window of QGIS and you want to see this also in the print\u2013composer view, you will always have to use the \u201cUpdate preview\u201d button.</p> <p>The situation after changing the scale to 50.000 is shown in Figure 11. You can see that, as expected, the displayed extent has shrinked notably, but at the same time, the level of detail has increased.</p> <p> </p> Figure 11: Situation after adapting the scale of the map <p>As next step, we will add a grid displaying the coordinates of the map. To do this,</p> <p>we again first select the map\u2013item in the main visualization window of the map composer, then select the item properties tab as before to change the scale of the map\u2013item. Here, we will scroll down a bit until we reach the section \u201cGrids\u201d marked with the red frame in Figure 12. We open the section and first of all press the green + button (marked with \u201c1\u201d in Figure 12) to add a grid. We can then adapt the properties of the grid by clicking the \"Modify Grid\" button (marked with \"2\" in Figure 12). In the situation shown in Figure 13 we selected \u201cFrame and annotations only\u201c as \u201cGrid type\u201d. This is a rather discreet solution as the grid is only depicted outside of the map. You can play around some more with the differing grid types and see which one you prefer. Furthermore, it is important to select the interval at which grid cells or annotations are set. In the given example the x and y intervals were set to 1000 map units, with map units being meter (area marked with \u201c3\u201d in Figure 13). Please be aware that the map units are only meters if the CRS of the project is set to EPSG 32633 (the crs of the Sentinel-2 image). If the project CRS is currently set to EPSG 4326, you might not see a grid at all since then 1000 as interval would mean 1000\u00b0 and hence there would no coordinate marked at all since the geographic coordinates only range from 0 to 180 degrees. If this would be the case for you, you can adapt the CRS in the map view by clicking the button marked with \"5\" in Figure 13. The frame style can be adapted using the area marked with \u201c4\u201d.</p> <p> </p> Figure 12: Adding a grid and drawing coordinates around the map. <p> </p> Figure 13: Adding a grid and drawing coordinates around the map. <p>To get a feeling for the multitude of available settings, it is best to play around with the different grid types and frame styles and just have a look how the displayed map changes. What is still missing in your map, are the coordinate themselves. To add these, you have to scroll down a bit further in the \u201cItem properties\u201d tab. Then you will find the option to activate the \u201cDraw coordinates\u201d check\u2013box as marked with \u201c1\u201d in Figure 16. In the same section you will find options to activate and de\u2013activate the coordinates for certain sides of the map (area marked with \u201c2\u201d in Figure 16). Generally, it is sufficient to draw the coordinates for one x and one y axis. Further down, it is possible to define the precision of the coordinate. While it makes sense to give precision with decimals for example when using a geographic coordinate system with latitude and longitude values, it in most cases does not make sense in metric coordinate systems such as UTM as most maps will typically not be resolved in sub-meter resolutions. In the example, the value was therefore set to 0.</p> <p> </p> Figure 14: Parameterizing the displayed coordinates <p>Next, we will add a North arrow and a scale bar to our map. We can do this by</p> <p>selecting the buttons marked with \u201c1\u201d and \u201c2\u201d in Figure 15. Simply click on of the button and then click within the main visualization section of the print composer. You can later adapt the properties of the North arrow and the scale bar by selecting them and adapting the settings displayed in the \u201cItem Properties\u201d section as done before for the map\u2013item.</p> <p> </p> Figure 15: Adding a North arrow and a scale bar. <p>Please be aware, that the North arrow in QGIS is not connected to the geoinformation contained in the data. It basically is just a grapical arrow that you draw in any direction. So please make sure that you use it appropriately.</p>"},{"location":"qgis/08-map-making/#adding-a-legend-to-the-map","title":"Adding a Legend to the map","text":"<p>We will now have a closer look on how to add and adapt a legend to our map. For adding the legend</p> <p>we select the \u201cadd legend\u201d button marked with \u201c1\u201d in Figure 16 and then draw a rectangle at the position where we want to locate the Legend as shown in Figure 16.</p> <p> </p> Figure 16: Adding a legend. <p>This will lead to the situation shown in Figure 17. As you can see, the basic version of the Legend already looks quite suitable. Nevertheless, we might want to adapt a few points related to the displayed contents and the design. For example, we can see that at the bottom of the legend, there is an extra entry for the satellite image stating \u201cS2_neapel_sm2\u201d. This is not really very informative for a potential user of the map. Furthermore, the sub-title of the Legend currently reads \u201cClipped (extent)\u201d which also should be changed to a more meaningful information.</p> <p> </p> Figure 17: After adding the legend. <p>We will now address these two points by</p> <p>first selecting the legend in the main visualization window and then opening the \u201cItem properties\u201d tab. Then we scroll down to the entry \u201cLegend items\u201d marked with \u201c1\u201d in Figure 18. Here we will first of all change the name of the section showing the land\u2013use\u2013classes which is currently named \u201cClipped extent\u201d (it might differ in your case). We do this by double\u2013clicking the field marked with \u201c2\u201d in Figure 18, this will open die pop\u2013up window marked with \u201c3\u201d. Here, we will now change the title to \u201cLand\u2013use\u2013classes\u201d and confirm with \u201cOK\u201d.</p> <p> </p> Figure 19: Adapting sub\u2013headings in the legend. <p>In Figure 21 you can see that the sub-heading has now changed from \u201cClipped (extent)\u201d to \u201cLand\u2013Use\u2013Classes\u201d (see red box marked with \u201c1\u201d). Next, we will delete the entry in the legend that was created for the satellite data. To do this, we</p> <p>first uncheck the option \u201cAuto update\u201d as marked with \u201c2\u201d in Figure 19. If the \u201cAuto update\u201d function is activated, the legend will always display the legend entries for all layers currently activated in the QGIS project. For manually adapting the legend, it has to be de\u2013activated. Next, we select the entry \u201cS2_Neapel_sm2\u201d (marked with \u201c3\u201d) and then we press the red minus button marked with \u201c4\u201d to drop the corresponding entry from the legend.</p> <p>In the same way, you could also manually add an entry to the legend by clicking the plus button marked with \u201c5\u201d which will then open a pop\u2013up window with all all available layers that are currently not included in the Legend. If you scroll a bit further down in the \u201cItem properties\u201d window you will see that there are many further options to adapt the layout of the Legend. You can change the font type, the font size and in how many Columns the legend entries are arranged. Feel free to play around with these options and have a look how they affect the layout of your Legend.</p> <p> </p> Figure 19: Dropping and adding items from the Legend."},{"location":"qgis/08-map-making/#finalizing-the-map","title":"Finalizing the map","text":"<p>We now have a map with the most important properties present. We will now finalize the map by adding some information on the data source, a title, and the applied coordinate reference system. To add a title we will</p> <p>use the \u201cAdd new label\u201d button marked with \u201c3\u201d in Figure 20. Then we can change the displayed text in the field marked with \u201c1\u201d and increase the font size by clicking the button marked with \u201c2\u201d. After re\u2013arranging the text a bit in the main visualization window, we can reach a situation similar as shown in Figure 20.</p> <p> </p> Figure 20: Adding a title to the map <p>We can now add in the same way the data source and the applied coordinate reference system. There is currently no option in QGIS to do this automatically. You can try to accomplish this on your own to create a map that looks similar as shown in Figure 23.</p> <p> </p> Figure 21: The final map."},{"location":"qgis/08-map-making/#exporting-the-map","title":"Exporting the map","text":"<p>If we are happy with the layout of our map we can now export the map by</p> <p>either selecting \u201cLayout\u201d -&gt; \u201cExport as Image\u201d / \u201cExport as PDF\u201d / \u201cExport as SVG\u201d or by clicking the three buttons on the far right of the section marked with \u201c1\u201d in Figure 11.</p> <p>Exporting as image allows you to easily embed the map into a text-document (e.g., Word) while PDF is a good solution if you want to send the map without any further information to somebody. The \u201cSVG\u201d format is a pure vector format which has big advantages if your map only consists of vector files as you can then zoom in the exported map without any quality loss.</p>"},{"location":"qgis/08-map-making/#exercise","title":"Exercise","text":"<p>This Tutorial only covers the most basic functionalities for creating a map in QGIS. As you have already seen from the many options available in the \u201cItem properties\u201d sections of each item that can be added in the print\u2013composer, there are many more ways to adapt your data to create an informative and eye\u2013pleasing map. It is highly encouraged to try out some of the options on your own to get acquainted with all the possibilities the map composer has to offer.</p> <p>Please play around a bit more with the different map options and try to design a map which you find visually pleasing and then export the map as pdf and upload the map to Blackboard to proof that you have finished the Tutorial.</p>"},{"location":"qgis/09-spatial-interpolation/","title":"Spatial interpolation","text":"<p>Abstract</p> <p>After completing this tutorial you will know how to to derive a continuous surface of estimates from discrete points with measured values. This process is called interpolation. </p>"},{"location":"qgis/09-spatial-interpolation/#loading-datasets-and-reprojecting","title":"Loading Datasets and Reprojecting","text":"<p>In this tutorial we will learn how to interpolate punctual precipitation and elevation measurements. We will make use of a precipitation dataset provided by the \"Centro Funzionale Multirischi della Protezione Civile Regione Campania\u00a7. This dataset contains measurements of annual precipitation from the year 2021 in mm/year. We will also use global elevation data provided by United States Geological Survey (USGS) and a dataset representing the NUTS (Nomenclature of territorial units for statistics) and Statistical regions provided by Eurostat.</p> <p>You can access the precipitation dataset and a shapefile of the outline of the land-masses of the study area here:</p> <p>https://drive.google.com/file/d/1xEZ7rflbptivMOpsOzOYHFQcQ4sePr_P/view?usp=share_link</p> <p>If we load the dataset in a common text-editor, the file should look as shown in Figure 1:</p> <p> </p> Figure 1: The precipitation csv file. <p>We can see that the file contains 6 columns including the X and Y coordinates of the measurement stations, an ID, the annual precipitation value recorded at this station, the name of the station and it elevation.</p> <p>We will now load this data into QGIS, along with the Sentinel-2 satellite image.</p> <p>To do this,</p> <p>we again first load the raster dataset \u201cS2_Neapel_sm2.tif\u201d and adapt the visualization settings to have a balanced view of all classes by using the channels R=3, G=2, B=1 and loading new max / min values using the \u201cSymbology\u201d- tab in the properties window. Then we additionally load the points stored in the file \u201cdata_interpolation.csv\"</p> <p>To load a text file as spatial layer in QGIS, we select \u201cLayer\u201d -&gt; \u201cAdd Layer\u201d -&gt; \u201cAdd Delimited Text Layer...\u201d from the main menu in QGIS as shown in Figure 1. This will open a new dialogue as shown in Figure 2.</p> <p> </p> Figure 2: Loading a csv file. <p>We now first select the \u201cdata_interpolation.csv\u201d as input file in the field marked with \u201c1\u201d. Next we choose the file format \"CSV\" in the area marked with \"2\". This will tell QGIS how the individual columns in the csv-file are separated. Afterwards we set the Geometry Definition. The csv file contains point coordinates and we hence select the corresponding option (marked with \"3\"). To tell QGIS where the points are located, we have to define a x-field containing the x-coordinates (Longitude) and the y-field containing the y-coordinates (Latitude). Finally we set the coordinate reference system to EPSG:4326 - WGS 84 (see area marked with \"5\") and click Add. We select the EPSG:4326 system since the points in the csv file are stored as geographic coordinates.</p> <p> </p> Figure 3: Adding a delimited Text. <p>This should lead to a situation as depicted in Figure 4.</p> <p> </p> Figure 4: After loading the two datasets. <p>We now have two datasets with different projections which we need to change in the next step to prepare the data for interpolation.</p> <p>To reproject the point data stored in the geographic coordinate system, we select \u201cVector\u201d -&gt; \u201cData Management Tools\u201d -&gt; \u201cReproject Layer...\u201d from the main menu in QGIS as shown in Figure 5. This will open a new dialogue as shown in Figure 5.</p> <p> </p> Figure 5: Reprojecting a vector layer. <p>Here we can reproject the precipitation data by</p> <p>first selecting the \u201cdata_interpolation\u201d layer as input file in the field marked with \u201c1\u201d. After selecting the layer,  we set an output file in the field marked with \u201c3\u201d in Figure 6 and we need to specify a target CRS in the field marked \u201c2\u201d. In this case, we will select the CRS with the EPSG code 32633 which is the same CRS as currently defined for the satellite image. After defining the correct Target CRS we press \u201cOK\u201d and QGIS will re-project the point-vector layer and add it as a new layer. If you now check the CRS of the new layer by performing a right\u2013click, selecting \u201cProperties\u201d and the \u201cGeneral\u201d tab, you will see that the CRS is now also set to 32633.</p> <p> </p> Figure 6: Reproject layer."},{"location":"qgis/09-spatial-interpolation/#idw-interpolation","title":"IDW Interpolation","text":"<p>Wer are now ready to interpolate the precipitation values provided in the csv-file. We will use the extent of the satellite image as area for the interpolation. Interpolation results can vary significantly based on the method and parameters you choose. QGIS in its standard installation provides two interpolation methods: Triangulated Irregular Network (TIN) and Inverse Distance Weighting (IDW). For the first part of the tutorial we are using the IDW method.</p> <p>First from the Processing Toolbox search and locate the \"Interpolation\" -&gt; \"IDW interpolation\" tool as shown in Figure 7. (Remember in the main menu click \"Processing\" -&gt; \"Toolbox\" in case the toolbox is now shown). Double-click to launch it. </p> <p> </p> Figure 7: Processing Toolbox. <p>In the new dialogue window we</p> <p>first select the \u201cdata_interpolation_reproject\u201d layer as input file in the field marked with \u201c1\u201d in Figure 8. After selecting the interpolation layer,  we select the interpolation attribute \"Precipitat\" marked with \"2\" and click on the plus symbol to add it to the attribute window below. Next we set the \"Distance coefficent P\" marked with \"3\". </p> <p>P is a important coefficcent in this method, because weights are proportional to the inverse of the distance (between the data point and the prediction location) raised to the power value P. So as mentioned above the result is dependent on this parameter.  As a result, as the distance increases, the weights decrease rapidly. The rate at which the weights decrease is dependent on the value of P. If P = 0, there is no decrease with distance, and because each weight is the same, the prediction will be the mean of all the data values in the search neighborhood. As P increases, the weights for distant points decrease rapidly. If the P value is very high, only the immediate surrounding points will influence the prediction.</p> <p>After setting P (you may try some different values for that) we set the extent (marked with \"4\" in Figure 8). For this we calculate the extent from our satellite image. Next you can set the Pixel size marked with \"5\". Note that the pixel size will affect the calculation time. Before you run the algorithm you can name an output file in the field marked with \"6\".</p> <p> </p> Figure 8: IDW Interpolation dialogue. <p>The IDW interpolation tool will then output a black and white interpolated raster surface onto the map area as shown in Figure 9. Based on your P value and your pixel size it may look different.</p> <p> </p> Figure 9: IDW interpolation result. <p>The next step is to clip the interpolation result to the land mass since we did not have any precipitation observation for the sea and we could assume that precipitation patterns differ over the sea. </p> <p>To clip the interpolation layer </p> <p>we load the \"Campania_boundaries.shp\" as learned in earlier tutorials. </p> <p>This should lead to a situation as depicted in Figure 10.</p> <p> </p> Figure 10: After loading the campania boundaries. <p>Next we select \u201cRaster\u201d -&gt; \u201cExtraction\u201d -&gt; \u201cClip Raster by Mask Layer...\u201d from the main menu in QGIS as shown in Figure 11.</p> <p> </p> Figure 11: Opening the clipping tool. <p>In the new dialogue window we</p> <p>first select the \u201cprecipitation_idw_p5\u201d layer as input file in the field marked with \u201c1\u201d in Figure 11. After selecting the input layer,  we select the Mask layer \"Campania_boundaries\" marked with \"2\" in Figure 12. As you can see in Figure 12 we are lucky that both layer have the same CRS, else we would have to reproject the layers before. Next we save the file in the field marked with \"3\" as a geoTIFF file.  Now click \"Run\"</p> <p> </p> Figure 12: Clip Raster by Mask Layer. <p>The new clipped layer will be added to the canvas and only shows the land mass as depicted in Figure 13.</p> <p> </p> Figure 13: Clipped Raster. <p>To make the visual appearance more pleasing, we can customize the symbology. To do it, right click the clipped raster result and select Properties (Or simply you can double click the layer name). The Layer Properties window will appear as shown in Figure 14. Select the Symbology tab marked with \"1\". In the Band Rendering option change the Render type to Singleband pseudocolor. (marked with \"2\") Then you can set your color ramp marked with \"3\". The color should fit to the object which is shown in a map. To classify you can set a classification mode (marked with\"4\") and the number of classes (marked with \"5\"), just explore if you want.</p> <p>After modifying the colour ramp values to reflect the range of values in a suitable way click \u2018apply\u2019 and \u2018ok\u2019 and you will now have coloured map of the IDW interpolation surface for precipitation in mm/year as shown in Figure 14.</p> <p> </p> Figure 14: Symbology. <p> </p> Figure 15: Result of the IDW interpolation."},{"location":"qgis/09-spatial-interpolation/#tin-interpolation","title":"TIN Interpolation","text":"<p>Next, we will also try the second interpolation method which is available in the base-installation of QGIS, that is the Triangulated Irregular Network (TIN) method. This time we will not interpolate the precipitation data but the elevation point data which is also stored in the csv-file.</p> <p>First from the Processing Toolbox search and locate the \"Interpolation\" -&gt; \"TIN interpolation\" tool as shown in Figure 16.</p> <p> </p> Figure 16: Processing Toolbox. <p>In the new dialogue window we</p> <p>first select the \u201cdata_interpolation_reproject\u201d layer as input file in the field marked with \u201c1\u201d in Figure 17. After selecting the interpolation layer,  we select the interpolation attribute \"Elevation\" (area marked with \"2\" in Figure 16) and click on the plus symbol to add it to the attribute window below. As a interpolation method we keep \"linear\". We set the extent by clicking the button marked with \"3\" to the extent from our satellite image. Next you can set the Pixel size marked with \"4\". Last we save the output as a .tif file by defining the filename in the field marked with \"5\" and run the algorithm.</p> <p> </p> Figure 17: TIN Interpolation dialogue. <p>The TIN interpolation tool will then output a black and white interpolated raster surface onto the map area as shown in Figure 18.</p> <p> </p> Figure 18: TIN interpolation result. <p>In the next step we clip the land mass like we did before with the IDW interpolation. You should already know how to accomplish this by now. The new clipped layer will be added to the map area and only shows the land mass and the interpolated triangles as depicted in Figure 19.</p> <p> </p> Figure 19: Clipped Raster. <p>Now we can customize the symbology as we did for the output layer of the IDW interpolation. Feel free to modify the symbology as you like. One option is shown in Figure 20.</p> <p> </p> Figure 20: Result of the TIN interpolation."},{"location":"qgis/09-spatial-interpolation/#exercise","title":"Exercise","text":"<p>Run each interpolation method for the input layers for which you did not yet run it and play around a bit more with the settings. Have a look at the outputs and discuss which method with which settings you believe provides \"most realistic looking\" results. Prepare a simple map (using the skills you acquired in the last tutorial) containing the view of what you would consider best interpolation result you obtained during your trial runs.</p> <p>If you want to compare your results to a more sophisticated climate interpolation dataset, you can search for the so called \"WorldClim\" dataset and download the corresponding file for \"annual precipitation\", load it to QGIS and compare it with your own result.</p>"},{"location":"schuelerpraktikum/handout/","title":"Handout","text":""},{"location":"schuelerpraktikum/handout/#zeitplan","title":"Zeitplan","text":"<p>9:00: Treff</p> <p>9:00 - 10:00: Gespr\u00e4ch</p> <p>10:00 - 10:30 : Einf\u00fchrung in Google Earth</p> <p>10:30 - 12:00: Projektarbeit</p> <p>12:00 - 12:30: Mittagpause</p> <p>12:30 - 14:00: Projektarbeit</p> <p>14:00 - 15:00: Druck und Praktikumsprotokoll</p>"},{"location":"schuelerpraktikum/handout/#einfuhrung-in-google-earth","title":"Einf\u00fchrung in Google Earth","text":"<p>Unser Praktikumsziel ist es eine Karte zu Landnutzungs und Landver\u00e4nderungs eines Gebietes zu erstellen. Hierf\u00fcr verwenden wir Google Earth Pro. Google Earth Pro ist eine Software, die einen virtuellen Globus darstellt. Sie kann Satellitenbilder mit Informationen \u00fcberlagern und auf der Erde anzeigen. Es folgt eine kleine Einf\u00fchrung die die wichtigsten Werkzeuge dieses Programmes vorstellt. Wenn weitere Fragen enstehen, sind wir f\u00fcr Sie da.</p>"},{"location":"schuelerpraktikum/handout/#zeitliche-und-raumliche-orientierung-in-google-earth","title":"Zeitliche und r\u00e4umliche Orientierung in Google Earth","text":"<p>Mit der Suchfunktion, oben links in der Seitenleiste, k\u00f6nnen Sie ein Gebiet Ihrer Wahl fokusieren.</p> <p></p> <p>In der Statusleiste, unten rechts im Fenster, k\u00f6nnen sie verschiedene Informationen wie das Aufnahmedatum und die Koordinaten herausfinden.</p> <p></p>"},{"location":"schuelerpraktikum/handout/#historische-bilder","title":"Historische Bilder","text":"<p>Mit dem Historische Bilder Werkzeug, oben links im Fenster , k\u00f6nnen sie \u00e4ltere Aufnahmen aufrufen. Verwenden sie daf\u00fcr den Regler und verschieben ihn auf der Zeitachse.</p> <p></p>"},{"location":"schuelerpraktikum/handout/#digitalisieren","title":"Digitalisieren","text":"<p>Um ein Gebiet zu markieren, kann das Polygon Werkzeug verwendet werden.</p> <p></p> <p>Wenn sie das Werkzeug anklicken erscheint ein neues Fenster . Hier k\u00f6nnen sie den Namen ihrer Markierung festlegen. Vergeben sie Aussagekr\u00e4ftige Namen.</p> <p></p> <p>Ihr Mauszeiger wird zu einem Fadenkreuz mit dem sie nun eine Gebiet markieren k\u00f6nnen. Daf\u00fcr spannen sie mit mehreren Klicks eine Markierung auf.</p> <p></p> <p>Um dieses Polygon zu speichern, rufen sie das zuvor ge\u00f6fnete Fenster auf und best\u00e4tigen sie mit ok. Das k\u00f6nnen Sie f\u00fcr mehrere Gebiete und Zeitr\u00e4ume durchf\u00fchren. Sodass Sie am Ende eine Sammlung von Markierungen haben. Dabei sollten die Markierung immer stets mit der Projektidee im Hinterkopf gemacht werden. Sie sollten also im Zusammenhang eine Aussage besitzen.</p> <p></p>"},{"location":"schuelerpraktikum/handout/#projektarbeit","title":"Projektarbeit","text":"<p>Unser Praktikumsziel ist es eine Karte zu Landnutzungs und Landver\u00e4nderungs eines Gebietes zu erstellen.  Einige Fragen die Sie sich vorher stellen sollten sind:</p> <ul> <li>F\u00e4llt Ihnen ein Gebiet ein, das Sie zu dem Thema n\u00e4her untersuchen m\u00f6chten? (Falls nicht, haben wir auch eine Idee)</li> <li>Welche bestandteile ver\u00e4ndern sich in diesem Gebiet?</li> <li>Wie kann man diese ver\u00e4nderung am besten darstellen?</li> </ul> <p>Sind diese Fragen beantwortet, k\u00f6nnen Sie loslegen und den Anleitungsschritten im oberen Teil folgen.  </p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/","title":"Calculating semivariograms and Autocorrelograms","text":""},{"location":"spatial_autocorrelation/spatial_autocorrelation/#overview","title":"Overview","text":"<p>In this lecture you will learn how to calculate a semivariogram and an autocorrelogram for a transect and you will get to know a function in R to derive a variogram from a raster image. The code-examples are mostly based on a Tutorial taken from the book \"Learning Landscape Ecology\" that is also available in ILIAS.</p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>In this tutorial we will use one of the landscape metric-layers that we calculated in one of the earlier Tutorials as well as a Shapefile which contains the transect for which we will calculate the semivariogram and the autocorrelogram.</p> <p>The data are available here:</p> <p>https://drive.google.com/open?id=1ni4CKdlRaFO6JoJWuI_9qDb6R2GBE2S4</p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/#step-1-getting-familiar-with-the-dataset","title":"Step 1: Getting familiar with the dataset","text":"<p>We will now first have a look at the data that we are working with. So please download the dataset given at the link above, unzip the files, and then open the QGIS project by double-clicking the file</p> <p>overview.qgz</p> <p>Now QGIS should open and show the following:</p> <p></p> <p>As you can see we only have to datasets displayed: The landscape metric showing the proportional forest cover from 0 to 1 (100%) and a transect that intersects the raster in East-West direction.</p> <p>In the following we will now extract the raster values for all pixels that the line intersects and use these pixel values to calculate a semivariogram and an autocorrelogram for the proportional forest cover.</p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/#step-2-calculating-the-semivariogram","title":"Step 2: Calculating the Semivariogram","text":"<p>We already learned in today's theoretical lecture how we calculate the mean semivariance \u00ce\u00b3 for a lag distance of h. It is actually a quite simple formula where we first calculate the squared difference of all point pairs (z(i) and z(i+h)) that can be derived at a given lag-distance h. We then sum these squared differences and divide the sum by two times the number of point pairs at the given lag-distance (2N(h)):</p> <p> </p> <p>A short reminder: the lag-distance is the distance between two points (or pixels). If we have a pixel size of 100 m then a lag distance of 100 m would mean that directly neighboring pixels are paired. If the lag distance would be 300 m then each pixel would be paired with pixels that are located 3 pixels away (in other words, there are two pixels inbetween the two pixels that will be paired). Remember also this graph:</p> <p> </p> <p>By comparing the semi-variances of point pairs with different lag-distances, we can quantify/depict how the spatial distance influences the correlation between points. Remember, the semi-variance will be low (values show low variance and are hence very similar) for highly correlated values, while it will be high for point-pairs with low correlation.</p> <p>Before we proceed with the calculation of the semi-variance, we will have to load our datasets by running the following code:</p> <pre><code># load required packages (as usual, please install missing packages)\nrequire(raster)\nrequire(rgdal)\nrequire(usdm)\n\n# set working directory that contains the data\nsetwd(\"D:/Multiskalige_FE/5_Practicals/Tag_4\")\n\n# load tif file containing landscape metric (here prop. forest area in a 500 x 500 m area)\nimg &lt;- stack(\"prop_forest_area.tif\")\n\n# load shapefile (polyline) that contains the transect for which we want to calculate\n# the semivariogram and the autocorelogram\nshp &lt;- readOGR(\".\", \"transect_ka\")\n</code></pre> <p>Next, we will intersect the raster-file with the transect and extract the values of the raster file for all pixels along the transect. We use the \"unlist()\" function as the extract command in this case will return a list. </p> <pre><code># overlay the shapefile-transect with the image and derive the raster values\n# as the extract command delivers a list, we use the unlist command to \n# decompose the list to a vector file\npr_for&lt;- unlist(extract(img, shp))\n</code></pre> <p>We can now have a look at the extracted values by running:</p> <pre><code>pr_for\n</code></pre> <p>This will show us:</p> <p> </p> <p>These will be the values for which we calculate our semi-variogram. To do this, we will now first derive the spatial resolution of our image as this will determine the rythm of our lag-distances. It would not make sense to select for example a lag distance of 1 m if our pixel size is 10 m as we would not be able to build pairs with pixels that are only 1 m apart.</p> <pre><code># get the pixel size of the image using the res() command of the raster package\nres_img &lt;- res(img)[1]\nres_img\n</code></pre> <p>This will return a value of 500 which indicates that our raster dataset has a spatial resolution of 500 m. That means that our lag-distances will be 500, 1000, 1500, 2000,... and so on.</p> <p>We calculate a vector with the corresponding values using the following code:</p> <pre><code># create a vector file with the same length as the extracted values of the transect\n# which indicates the position on the transect. As each pixel is 500 m large, we use\n# steps of 500 m.\ntr_pos &lt;- seq(res_img, length(pr_for)*res_img, res_img)\n</code></pre> <p>These values at the same time indicate the position of each pixel on the transect.</p> <p>We will now calculate the semi-variance for the different lag-distances. Based on the function available in R, this requires several steps and the calculation might not be 100% intuitive at the first glance. However, when putting some thought into it, it should become quite clear.</p> <p>First, we calculate the distance of each pixel to all other pixels on the transect by running:</p> <pre><code># calculate the lag-distances between each point\nlag &lt;- dist(tr_pos)\nlag\n</code></pre> <p>This will result in a quite bix matrix looking like that:</p> <p></p> <p>You can interpret this like this: the column named 1 represents the first pixel on the transect. In the rows you can then see the lag distance to each of the pixels that follows. The second column represents the second pixel on the transect, the third column the third pixel and so on. This matrix will help us later on to identify all point pairs with a unique lag distance. </p> <p>Next, we calculate the semivariance for all point pairs by running:</p> <pre><code>varTP &lt;- dist(pr_for)^2*.5\nvarTP\n</code></pre> <p>This will result in a matrix with the same structure as our lag-matrix, we have just calculated, but of course the values are different.</p> <p>It is important to understand that we now already have all important inputs together to calculate the mean semivariances for all lag-distances. The two things that are still missing are: </p> <ol> <li>we have to split our varTP matrix to be able to treat the semi-variances for each lag-distance individually</li> <li>we have to calculate the mean semi-variance for each lag distance (the N in the formular has not been considered yet).</li> </ol> <p>We accomplish this by first running:</p> <pre><code># split the seminvariance values up depending on what spatial lag they occur at    \nTP.split&lt;-split(varTP,lag)     \nTP.split\n</code></pre> <p>Here we can now see the semi-variances for each lag-distance. In the figure below the last few entries are shown where we can see that the number of point pairs constantly decreases and that for the largest lag-distance (22000 m) only one point pair is available:</p> <p></p> <p>Next, we calculate the mean semi-variance for each lag-distance by running:</p> <pre><code># compute the mean semivariance at each spatial lag\nTP.gamma &lt;- sapply(TP.split,mean) \nTP.gamma\n</code></pre> <p>This simply calculates the mean value for each of the lines of values depicted in the preceeding figure.</p> <p>This will result in one value (the mean semi-variance) for each lag-distance:</p> <p></p> <p>Now we have all the information to plot our semi-variogram by simply plotting the mean semivariance over the lag-distance.</p> <p>The corresponding code looks like this:</p> <pre><code># extract the values of the unique spatial lags\nlag.uni&lt;- as.numeric(names(TP.gamma))\n# visually examine the variogram for the landscape metric and the transect\nplot(lag.uni,TP.gamma,xlab='Spatial Lag (m)',ylab='Semivariance Forest prop. [%]',type='o') \nabline(v=max(lag)/2,lwd=2,col='dodgerblue',lty=2)\n</code></pre> <p>The will lead to this graph:</p> <p></p> <p>We have now plotted the semi-variogram across all possible lag-distances, however, as we discussed before, the large lag-distances have only very few points left and they might hence have a very limited reliability. Typically it is recommended to only consider lag-distances up to half of the maximum lag-distance. The corresponding lag-distance is marked with the blue dashed line in the graph.</p> <p>If we compare this graph with the original raster dataset, we can interpret the semi-variogram a bit. The maximum semivariance is reached at a lag-distance of 2500 m (or five pixels) - i we have a look at the raster dataset we can see that there are several elements of the landscape along the transect that are approximately 5 pixels long. There is a almost forest-free zone 6 pixels at the Eastern start of the transect, then there is a fully forest covered area which also covers 5 pixels, afterwards there is another forest-free zone of 4-5 pixels followed again by a sparsely forested areas with a length of about 6 pixels. At lag-distances smaller than these landscape element sizes, the correlation between the values will be high (the semi-variance low) while at larger lag-distances, they will get small.</p> <p>This matches the curve depicted in the semi-variogram. Hence, at the given spatial grain of 500 m, the landscape elements along our transect tend to change every 2500 m and even though there are some more fluctuation afterwards, we could be quite sure that if we take some sort of field measurements and make sure that each maesurement is at least 2500 m away from all other measurements, there should be no problem with spatial autocorrelation in the models we build from these data. </p> <p></p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/#step-3-calculating-the-autocorrelogram","title":"Step 3: Calculating the Autocorrelogram","text":"<p>In this part of the tutorial, we will calculate the autocorrelogram. We will here take a slightly different approach and prepare a function to calculate autocorrelation along a simple transect. More detailed explanations of the function are given in the comments of the code. The function looks like this:</p> <pre><code># The name of the function is \"a.cor\" and the it only requires one input variable x where\n# x is a vector containing the regular measurements along the transect\na.cor&lt;-function(x){\n ## This function computes autocorrelation of the variable x.\n ## It is assumed that x is sampled along a linear, uniformly-spaced transect.\n ## This function is not appropriate for computing spatial autocorrelation for \n ## more complex spatial arrangements of data.\n\n # first compute the total size of x \n len&lt;-length(x)  \n # create an empty output variable  \n r&lt;-rep(NA,len-2) \n # loop through all the possible spatial lags (h)\n for(h in 1:(len-2)){ \n     # compute the autocorrelation at each lag\n     # in this case the correlation would be a simple Pearson's correlation\n     # by using clever subsetting of the vector files, the correlation will always\n     # be calculated for the correct point pairs\n     r[h] &lt;- cor(x[1:(len-h)],x[(1+h):len]) \n  }\n # print the output variable (which will be the value to be returned by the function)\n r \n}\n</code></pre> <p>If we run the code above, R will not yet perform an actual analysis yet, but will simple create the a new function called \"a.cor\"which is also visible in the environment window in RStudio (at the very bottom normally):</p> <p></p> <p>We will now apply this function to our vector containing the proportional forest cover values along the transect:</p> <pre><code># now that we have our function we can compute the autorcorrelation for all possible lags\ncorrel&lt;-a.cor(pr_for)\n</code></pre> <p>This will return the correlation for all possible lag-distances of the given vector. Be aware that in this case, the code is not considering real metric distances but simply positions in the vector. As we are working with regular distances (each measurement on the transect is equally far away from the next measurement), this does not affect the results.</p> <p>This has to be considered when finally plotting the autocorrelogram. We use the variable tr_pos containing the lag-distances (created in Step 2) to define the lag distances on the x-axis. We can then plot the autocorrelogram using the following code:</p> <pre><code># plot the autocorrelogram \n# we use tr_pos[1:43] as for the way we calculate the spatial autocorrelation no value is avaiable for the first and last lag-distances\nplot(tr_pos[1:43],correl,xlab='Spatial lag (m)',ylab='Autocorrelation',main='Forest Proportion',type='o')\nabline(v=max(tr_pos)/2,col='dodgerblue',lty=2,lwd=2)\nabline(h=0)\n</code></pre> <p>This will result in the following graph:</p> <p></p> <p>As we can see, the curve is very similar to the semi-variogram but mirrored. One thing that might have to be discussed, is the fact that correlations can be positive and negative and hence the optimal lag-distance at which no spatial autocorrelation occurs anymore might be interpreted differently in this graph (the curve starts fluctuating around 0 at approximately 3500-4000 m instead of the maximum semi-variance that was achieved at 2500 m.</p>"},{"location":"spatial_autocorrelation/spatial_autocorrelation/#step-4-calculating-a-semivariogram-for-a-raster-file","title":"Step 4: Calculating a Semivariogram for a Raster-file","text":"<p>In the preceeding steps, we calculated the semivariogram and the autocorrelogram in a rather \"manual\" way, which helps to understand what steps are required to produce the final graphs. On the negative side, the methods we used above are only suitable for a 1D-transect. However, in remote sensing we are typically working with raster datasets and it is of course also possible to calculate variograms for 2D-environments. Then, the pixel-pairs are not only created in the 1D space but in the 2D space. The remaining calculations are the same.</p> <p>In R, there is a package that allows to calculate Variograms for single-band raster layers. The code is really simple:</p> <pre><code>## calculate a variogram from a raster using the usdm package\n## the function has some additional settings that can be checked using\n## ?Variogram\n## in many cases the standard settings should be ok\nvar_ras &lt;- Variogram(img[[1]])\nplot(var_ras)\n</code></pre> <p>Running this code, will lead to:</p> <p></p> <p>As we can see, this variogram looks a lot smoother than the semi-variogram we computed for the transect. This might be due to the fact, that by considering more pixels in the raster, the number of point pairs is a lot higher and the semi-variogram is less influenced by the the particular landscape structure along the transect. When checking the information provided for the function Variogram() (by typing):</p> <pre><code>?Variogram\n</code></pre> <p>you will find out that the function actually is not using all pixels to calculate the semi-variogram but takes a random sample of pixels, representative of the raster layer. You can change the amount of pixels used during that step. It is also possible to change the lag-interval. In the standard setting, the pixel size is used, similarly as we did in the 1D-example above. However, it is possible to also use larger intervals. This might be relevant for analysing very high resolution images where not all possible lag-distances may have to be considered to get a meaningful diagram.</p> <p>This was the last part of the Tutorial and in ideal case, you will now have a better understanding what semi-variograms and auto-correlograms are and how they are computed. In the course, we will not get into more details about this topic, but this could be one setion of the course that could also be examined with more details in small experiment or literature search to hand in as final assignment.</p>"},{"location":"treespeciesclassification/treespeciesclassification/","title":"Classification of tree species using hyperspectral data","text":""},{"location":"treespeciesclassification/treespeciesclassification/#overview","title":"Overview","text":"<p>In this lecture you will learn how to use hyperspectral data in combination with a support vector machines (SVM) algorithm to create a tree species map from a hyperspectral HyMap image using a supervised classification. The learned steps will include:</p> <ul> <li>Loading a hyperspectral  image</li> <li>Visualizing a hyperspectral image and vegetation spectra extracted from pixels</li> <li>Conduct a supervised SVM classification using the original HyMap bands</li> <li>Applying a PCA transformation to the Hyperspectral image (feature extraction) </li> <li>Conduct a supervised SVM classification using the PCA components as input</li> <li>Apply an additional feature selection to the PCA components and conduct a supervised SVM classification using an automatically selected subset of the PCA components</li> </ul> <p>The datasets applied in this tutorial are available here:</p> <p>https://drive.google.com/file/d/1OkOcvNTDGR5PcBhress0pbwMP5wPqVui/view?usp=sharing</p>"},{"location":"treespeciesclassification/treespeciesclassification/#datasets-used-in-this-tutorial","title":"Datasets used in this Tutorial","text":"<p>In this tutorial we will make use of an airborne hyperspectral or imaging spectroscopy image that was collected with the HyMap sensor (HyMap_125bands_Karlsruhe2.tif). This dataset is comparable to a multispectral image but contains a lot more bands which continuously cover the spectra wavelengths regions between approximately 400 and 2400 nm. The HyMap image shows a forested area in the North of the German city Karlsruhe. The dataset has been described with more details in the following publications: </p> <p>Fassnacht, F. E.; Neumann, C.; Forster, M.; Buddenbaum, H.; Ghosh, A.; Clasen, A.; Joshi, P. K.; Koch, B. (2014). Comparison of feature reduction algorithms for classifying tree species with hyperspectral data on three central european test sites. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7 (6), 2547\u20132561. doi:10.1109/JSTARS.2014.2329390</p> <p>Ghosh, A.; Fassnacht, F. E.; Joshi, P. K.; Koch, B. (2014). A framework for mapping tree species combining Hyperspectral and LiDAR data: role of selected classifiers and sensor across three spatial scales. International journal of applied earth observation and geoinformation, 26, 49\u201363. doi:10.1016/j.jag.2013.05.017</p> <p>Additionally, a point-Shapefile is provided which contains sample points (reference positions) for 5 tree species (50 points per species, 250 in total) (tree_species_KA.shp). These reference positions were collected using visual interpretation of high-resolution images in combination with reference tree species maps provided by the local forest administration. These reference tree species maps are also provided as tif-files (Reference_information.tif; Reference_information2.tif). The latter can used for comparison with the classification maps produced in the tutorial. </p>"},{"location":"treespeciesclassification/treespeciesclassification/#step-1-loading-an-visualizing-the-hyperspectral-hymap-image-and-the-reference-dataset","title":"Step 1: Loading an visualizing the hyperspectral HyMap image and the reference dataset","text":"<p>As first step, load all necessary R packages by executing the following code:</p> <pre><code>require(raster)\nrequire(e1071)\nrequire(caret)\nrequire(rgdal)\nrequire(matrixStats)\nrequire(RStoolbox)\nrequire(factoextra)\nrequire(VSURF)\n</code></pre> <p>R will give you a warning message in case a package is not installed yet. If this is the case, please install the packages either through the main menu of Rstudio by selecting \"Tools\" =&gt; \"Install packages\" and then following the appearing dialogue, or by entering the corresponding R code to install the packages into the console. E.g., to install the package \"raster\" use the code:</p> <pre><code>install.packages(\"raster\")\n</code></pre> <p>After all packages are successfully installed, we will load the hyperspectral image and the shapefile containing the reference information. You should already be familiar with the corresponding code in R from earlier practicals of the course.</p> <pre><code># change directory (depends on where you stored your data)\nsetwd(\"D:/Diplomado/Tut_superv_class_hyper/2_data\")\n\n# load hyperspectral image\nhym_img &lt;- stack(\"HyMap_125bands_Karlsruhe2.tif\")\n\n# load reference data\nref &lt;- readOGR(\".\", \"tree_species_KA\")\n</code></pre> <p>After loading the hyperspectral image, we can obtain some basic information about the data using some standard commands of the Raster package:</p> <pre><code># we can now obtain some information about the image using the following commands:\n\n# number of colums of the hyperspectral image\nncol(hym_img)\n# number of rows of the hyperspectral image\nnrow(hym_img)\n# number of bands of the hyperspectral image\nlength(hym_img@layers)\n# summary information of all bands\nhym_img@layers\n# summary information of a specific band, here band number 5\nhym_img@layers[5]\n# check the geographic extent of the image\nextent(hym_img)\n# check the defined coordinate system\ncrs(hym_img)\n</code></pre> <p>While we do not exlicitly need these commands right now, it is still important to know them because you will regularly confront situations where you need them for processing your images in an effective way. Next, we will plot our hyperspectral image (hym_img) as well as the reference data stored in the loaded shapefile (ref).  You can see in the code below, that we will select the bands number 21, 14 and 7 to plot a RGB-composit of the hyperspectral image. This leads to an Color-Infrared-View of the image because the band 21 is located in the NIR, the band 14 in the red region and band 7 in the green region. We will furthermore plot the reference data on top of the image using the species information to color-code each sample. The species information is stored in the attribute table of the Shapefile in the column named \"id\" which can be accessed with the setting col=ref@data$id.</p> <pre><code># plot CIR view of hyperspectral image\nplotRGB(hym_img, r=21, g=14, b=7, stretch=\"hist\")\n# add reference points\npar(new=T)\nplot(ref, col=ref@data$id, add=T)\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>In the given plot, coniferous stands are depicted in green and broadleaved stands in red. This is because broadleaved stands have a higher reflectance in the near-infrared region than coniferous stands. You can also see that the reference points are depicted in different colors and are mostly crowded in individual forest stands. This is due to the fact, that these stands contain mostly a single species and can hence serve as reliable reference areas to collect samples that we will use to train the algorithm. In total, we consider five tree species, that we will introduce later on. Already now, we can see that one species (Fagus sylvatica) is not occurring in pure stands (this can be seen because pure stands appear just in green or just in red colors). You can see that all the dark blue samples are occurring in rather heterogeneous stands with mixed green and red areas.</p> <p>As next step, we will now extract the spectral values of the HyMap image at each of the 250 reference point locations. So we will have 50 spectral signatures for each tree species. To do this we run:</p> <pre><code># extract spectral signatures at the reference data points\nref_data_tr &lt;- extract(hym_img, ref)\n</code></pre> <p>Depending on the performance of your computer, this will take a bit of time, as the image has quite a lot of bands. Once, we have extracted the values, we will transform the resulting data matrix into a data frame by running:</p> <pre><code>ref_data_tr &lt;- as.data.frame(ref_data_tr)\n</code></pre> <p>Now, we can have a look at the extracted spectral signature by running the plot command in a loop to plot all spectral signatures into the same plot window:</p> <pre><code># plot all spectra and color-code with species\ndev.off()\nfor (i in 1:nrow(ref_data_tr)){\n\n  par(new=T) \n  plot(1:125, ref_data_tr[i,], type=\"l\", col=ref@data$id[i], ylim=c(0,6000), ylab=\"Reflectance\", xlab=\"HyMap band\")\n\n}\n</code></pre> <p>This will result in the following image:</p> <p></p> <p>What is not optimal in this graph is that the x-axis does not show the wavelengths, but the band number of the HyMap sensor. This can be fixed by providing the center-wavelengths of HyMap instead as an array instead of the simple sequence from 1 to 125 (the code part is: 1:125) as done at the moment. However, because it is not really relevant for this tutorial, we will not spend more time on this for now.</p> <p>In the plot, we used the species information to color-code the spectra, but as you can see this graph is quite chaotic, and it is hard to see where the spectra of one species ends and the spectra of another species start. All in all, there seems to be quite a heavy overlap between the spectral signatures of the five species. So let us try to make this plot a bit clearer by plotting the mean spectral signature of each species plus its standard deviations.</p> <p>We will need a bit more code to do this. There are definitely ways to code this with less lines of code, however, the solution given below makes the logical flow quite clear and may be easier to understand for people who are not yet professionals in R. For detailed information, please read the comments in the code.</p> <pre><code>##################################\n# plot mean + sd of each species\n##################################\n\n# The species information stored in the Shapefile is coded with numbers. Below you can see which species\n# belongs to which number code.\n\n# species:\n# id = 1 = Quercus robur/petreae (Common/Trembling Oak)\n# id = 2 = Pinus sylvestris (Pine) \n# id = 3 = Quercus rubra (Red Oak)\n# id = 4 = Fagus sylvatica (European beech)\n# id = 5 = Pseudotsuga menziesii (Douglas fir)\n\n# in the first step, this information about the species will be attached to the dataframe\n# containing the spectral signatures at the reference plot locations:\n\nref_data_tr$id &lt;- ref@data$id\n\n# now we are ready to calculate the mean and standard deviation (sd) spectral signatures of each species \n# to save the mean and sd signatures, we create an empty list object    \nmeansd &lt;- list()\n\n# then we run a loop in which we first build a subset of the spectral signatures dataframe so that the\n# subset only contains the spectra of a single species.\nfor (i2 in 1:5){\n\n  # build subset of the dataframe where the species id = i2 \n  sp &lt;- ref_data_tr[ref_data_tr$id == i2,]\n  # from the remaining 50 spectral signatures of a single species, calculate the column mean and sd\n  means &lt;- colMeans2(as.matrix(sp[,1:125]))\n  sds &lt;- colSds(as.matrix(sp[,1:125]))\n  # bind the two arrays containing the mean and sd values\n  fin &lt;- cbind(means, sds)\n  # save them to the list\n  meansd[[i2]] &lt;- fin\n  # repeat with next species\n\n}\n\n# now we are able to plot the mean and sd values of the five species\n\n# close any currently open plot window\ndev.off()\n# plot an \"empty\" plot by setting the color to white. This is a trick to avoid overlapping axes-titles in the for-loop below\nplot(1:125, meansd[[1]][,1], type=\"l\", col=\"white\", ylim=c(0,6000), ylab=\"Reflectance [10000=100%]\", xlab=\"# Band\")\n# add a legend indicating the species names\nlegend(\"topright\", legend=c(\"Quercus robur\", \"Pinus sylvestris\", \"Quercus rubra\", \"Fagus sylvatica\", \"Pseudotsuga menziesii\"), col=c(1,2,3,4,5), lty=c(1,1,1,1,1))\n\n# plot the mean spectral signature as well as two additional signatures which show the mean - sd and mean + sd to create an interval in which most of the spectral signatures of the species are located.\n\nfor (i3 in 1:5){\n\n\n  par(new=T)\n  # plot mean spectral signature\n  plot(1:125, meansd[[i3]][,1], type=\"l\", col=i3, ylim=c(0,6000), add=T, lwd=2, axes=F, ann=F)\n  par(new=T)\n  # plot mean spectral signature + sd values\n  plot(1:125, meansd[[i3]][,1]+meansd[[i3]][,2], type=\"l\", col=adjustcolor(i3, alpha.f=0.5), ylim=c(0,6000), add=T, lty=2, axes=F, ann=F)\n  par(new=T)\n  # plot mean spectral signature - sd values\n  plot(1:125, meansd[[i3]][,1]-meansd[[i3]][,2], type=\"l\", col=adjustcolor(i3, alpha.f=0.5), ylim=c(0,6000), add=T, lty=2, axes=F, ann=F)\n\n\n}\n</code></pre> <p>This rather long code will lead to the following plot:</p> <p></p> <p>This plot is a lot clearer. We can see the mean spectral signatures of all broadleaved tree species (Quercus robur, Quercus rubra and Fagus sylvatica) have a higher reflectance amplitude than the two coniferous species (Pinus sylvestris and Pseudotsuga Menziesii). We can also see that the SD-values of the spectral signatures of the individual species overlap quite notably. This suggests that the classification might not be that easy. But let us explore, what can be achieved.</p>"},{"location":"treespeciesclassification/treespeciesclassification/#step-2-tree-species-classification-using-the-original-hymap-bands","title":"Step 2: Tree species classification using the original HyMap bands","text":"<p>We will now prepare and run the first classification approach using all 125 bands of the HyMap image. For this, we first prepare two variables. One contains all the spectral signatures of the training data (trainval) and one that contains the corresponding response value (the information to which tree species the sample belongs - coded as a number between 1 and 5) (treespec).</p> <pre><code>############################################\n# prepare classification using original bands\n############################################\ntrainval &lt;- ref_data_tr[,1:125]\ntreespec &lt;- ref_data_tr$id\n</code></pre> <p>As we can see, we obtain both of these variables from the ref_dara_tr dataframe which contains the spectral signature in columns 1 to 125 and the reference data in column 126 (the latter can also be directly accessed via the column name).</p> <p>Now we are ready to start the classification. As you might already know, machine learning algorithms such as support vector machines, typically require a parameter tuning. That is, we try to identify the optimal settings of the classification algorithm by splitting the dataset into several parts and then use some of these parts to train the classifier (with a set of parameters) and then validate them with another part which has not been used during training. By repeatedly varying the parameters, we can find a combination of parameters, that performs exceptionally well.</p> <p>In the case of SVM we can vary two parameters: gamma and cost. Gamma defines how flexible the so-called hyperplane is allowed to be. The hyperplane is basically the separation-\"line\" between the different classes in the feature space. On the other hand, cost describes how strongly the classifier punishes a wrongly classified sample. If cost and/or Gamma is too high, there is a risk of overfitting - however, by applying datasplits during the grid search, overfitted models will lead to bad performances. By using an automated grid-search which varies the gamma and cost values within a user-defined range, it is possible to automatically search for a good gamma/cost combination in R. The corresponding code looks like this (this might take a while to run, as a lot of different models are examined here): </p> <pre><code># set a seed to allow for reproducing the results\nset.seed(1173)\n# set a range of gamma and cost values to be tested in the parameter tuning\ngammat = seq(.1, .9, by = .1)\ncostt = seq(1,128, by = 12)\n# check the parameters to be tested\ngammat\ncostt   \n# run the parameter tuning\ntune1 &lt;- tune.svm(trainval, as.factor(treespec), gamma = gammat, cost=costt)\n# plot the results of the parameter tuning\nplot(tune1)\n</code></pre> <p>As you can see we will test 9 different values for gamma and 11 different cost-values. In theory, it would of course be possible to test even more combinations but the ones selected here are working quite well from our experience. However, feel free to try out some higher and lower values if you are interested in the results. The code above will lead to the following plot:</p> <p></p> <p>This plot summarizes the performances obtained with the examined gamma and cost values. The legend is showing the error rate. So that means, the higher we set gamma, the larger the errors were during the parameter tuning. On the other hand, cost did not have a notable effect on the parameter tuning in the given example.</p> <p>We will now extract the best identified gamma and cost value by running:</p> <pre><code>gamma &lt;- tune1$best.parameters$gamma\ncost &lt;- tune1$best.parameters$cost\n</code></pre> <p>Then we are ready to train the SVM classification. We will train two different models, one model in which all available data will be used for training the model (maximizing the available information) and a second model which is additionally applying a 10-fold cross-validation which we can use to get an idea of how well the classification is able to classify the reference samples correctly.</p> <pre><code># train the model with all available samples\nmodel &lt;- svm(trainval, as.factor(treespec), gamma = gamma, cost = cost, probability = TRUE)\n# train model with 5-fold cross-validation to get first impression on accuracies\nmodel2 &lt;- svm(trainval, as.factor(treespec), gamma = gamma, cost = cost, probability = TRUE, cross=10)\n</code></pre> <p>This should run quite fast and we can not have a look at the model results by running:</p> <pre><code>summary(model2)\n</code></pre> <p>This should show something like this:</p> <p></p> <p>So we can see that we have a mean overall accuracy of approximately 72%. This is not bad but also not really good. We can now also apply this classification model to the full image by running:</p> <pre><code># set output directory to save the classification map   \nsetwd(\"D:/1_tree_species_Karlsruhe/2_data/results\")\n# apply the classification model to the hyperspectral image using the predict function\nsvmPred &lt;- predict(hym_img, model, filename=\"tree_spec_map.tif\", na.rm=TRUE, progress='text', format='GTiff', datatype='INT1U',overwrite=TRUE)\n</code></pre> <p>This process may take a few minutes depending on the speed of your computer. We can then plot the predicted map using:</p> <pre><code># plot the resulting tree species map\nplot(svmPred)\nlegend(\"topright\", legend=c(\"1 = Quercus robur\", \"2 = Pinus sylvestris\", \"3 = Quercus rubra\", \"4 = Fagus sylvatica\", \"5 = Pseudotsuga menziesii\"))\n</code></pre> <p>This will result in the following tree species map:</p> <p></p> <p>On the first glance, this map looks quite plausible. We can see that many of the stands from which we collected the training data (and we hence know, that they are composed of a single species) appear quite homogeneous in the classification map. The quality of the map could be examined with more details by loading the map into QGIS and compare it to the reference maps provided with the tutorial materials and maybe also by comparing the map with additional high-resolution Google or Bing maps which can be visualized in QGIS as well. </p>"},{"location":"treespeciesclassification/treespeciesclassification/#step-3-tree-species-classification-using-pca-bands","title":"Step 3: Tree species classification using PCA bands","text":"<p>One way to improve the accuracy of supervised classifications, particularly if working with hyperspectral data are feature extraction methods as they allow to compress the feature space and hence reduce colinearity of predictors. In the following we will apply the well-known principal component analysis (PCA) to the hyperspectral image to reduce the original 125 bands to a smaller number of bands carrying most of the variability contained in the image.</p> <p>To apply a PCA to a raster dataset, we can use the rasterPCA function of the RStoolbox package. The function actually uses only a subset of pixels to calculate the PCA transformation and then only applies the transformation to the full raster stack. In the example below, we use 1000 sample points. The more points are used, the longer the PCA calculation may last. We also set the spca parameter to TRUE to scale all the bands (this is not absolutely necessary but may be reasonable to do in our case as for example vegetation spectra have differing reflectance value ranges in the visual and near-infrared region; by scaling all value ranges of the bands, such constant differences are smoothed out). If you are interested whether this has any effect, you can also re-run the code later and switch off the spca parameter. To run the PCA in R we execute the following code (this may take a while!):</p> <pre><code>############################################\n# prepare classification using PCA\n############################################\n\npca &lt;- rasterPCA(hym_img, nSamples=5000, spca=T)\n</code></pre> <p>From the resulting pca object, we can extract the transformation model:</p> <pre><code>pca_ras &lt;- pca$map\n</code></pre> <p>As well as the new raster stack containing the PCA components (125 components/raster layers sorted from high to low information content)</p> <pre><code>pca_mod &lt;- pca$model\n</code></pre> <p>To check how much of the overall variability the individual components are carrying, we can have a look at an eigenvalue scree plot using the fviz-eig function from the factoextra package:</p> <pre><code>fviz_eig(pca_mod)\n</code></pre> <p>This will result in the following plot:</p> <p></p> <p>As we can see, the first seven components seem to already carry the vast majority of the variability in the hyperspectral image. Starting from the 8th component, the information content seems to be rather low. However, we can also check this by plotting the individual components. We can for example compare the first three components with the last three components by running:</p> <pre><code>x11()\ndev.off()\npar(mfrow=c(2,3))\nplot(pca_ras[[c(1:3, 123:125)]])\n</code></pre> <p>this will result in the following plot:</p> <p></p> <p>As we can see, the first three PCs show quite a lot of variation related to the image contents. PC3 does not show too many patterns, due to a few outlayer value in the urban area (the green dot) - but PC3 actually still does contain a lot variation (this would become visible if the image stretched would be adapted). On the other hand, the last three PCs seem to only show random noise. Based on the combination of the eigenvalue plot above and this visual examination we can now decide how many of the PCs we want to use in our classification. For now, we will simply select the first 15 components assuming that most of the variability in the image is covered by these components. Hence, we extract the values of the first 15 PCs from the reference sample locations using:</p> <pre><code>trainval_pca &lt;- extract(pca_ras[[1:15]], ref)\n</code></pre> <p>Then, we run the same SVM classification as we did before, including also the parameter tuning:</p> <pre><code>set.seed(1173)\n# parameter tuning\ngammat = seq(.1, .9, by = .1)\ncostt = seq(1,128, by = 12)\ntune2 &lt;- tune.svm(trainval_pca, as.factor(treespec), gamma = gammat, cost=costt)\nplot(tune2)\n# extract best parameters\ngamma2 &lt;- tune2$best.parameters$gamma\ncost2 &lt;- tune2$best.parameters$cost\n\n# train the model with all available samples\nmodel_pca &lt;- svm(trainval_pca, as.factor(treespec), gamma = gamma2, cost = cost2, probability = TRUE)\n# train model with 10-fold cross-validation to get first impression on accuracies\nmodel_pca2 &lt;- svm(trainval_pca, as.factor(treespec), gamma = gamma2, cost = cost2, probability = TRUE, cross=10)\nsummary(model_pca2)\n</code></pre> <p>This will produce the following output (you will additionally see the plot from the parameter tuning, but you are already familiar with this step, so I will not repeat it here):</p> <p></p> <p>As we can see, the classification accuracy using only the first 15 PCA components as input is slightly better than the accuracy we obtained using all hyperspectral bands. Your results might vary slightly, depending on how you set your seed value in the function set.seed().</p> <p>Finally, let us also produce a prediction map for this classification approach by running the following code:</p> <pre><code># set output directory\nsetwd(\"D:/1_tree_species_Karlsruhe/2_data/results\")\n# apply classifier to full image    \nsvmPred_pca &lt;- predict(pca_ras[[1:15]], model_pca, filename=\"tree_spec_map_pca.tif\", na.rm=TRUE, progress='text', format='GTiff', datatype='INT1U',overwrite=TRUE)\n</code></pre> <p>We can also have a look at this map by running:</p> <pre><code>dev.off()\nplot(svmPred_pca)\nlegend(\"topright\", legend=c(\"1 = Quercus robur\", \"2 = Pinus sylvestris\", \"3 = Quercus rubra\", \"4 = Fagus sylvatica\", \"5 = Pseudotsuga menz.\"))\n</code></pre> <p>Which will result in:</p> <p></p> <p>This map looks quite similar as the one from the preceeding classification. This is no surprise as the classification accuracies were also similar.</p>"},{"location":"treespeciesclassification/treespeciesclassification/#step-4-tree-species-classification-using-a-combination-of-feature-selection-vsurf-and-feature-extraction-pca","title":"Step 4: Tree species classification using a combination of feature selection (VSURF) and feature extraction (PCA)","text":"<p>In this final step of the Tutorial, we will now add another step. We will use the first 30 components of the PCA as our starting input dataset. Then we will run a feature selection algorithm on these 30 components and use the selected components to train the SVM classification.</p> <p>First we select the first 30 components of the PCA raster stack and extract the corresponding values:</p> <pre><code>set.seed(23)\npca_ras2 &lt;- pca_ras[[1:30]]\ntrainval_pca2 &lt;- extract(pca_ras2, ref)\n</code></pre> <p>Then we run the feature selection algorithm VSURF. This algorithm is based on Random Forest and in some of our recent studies it performed quite well. Some more detailed descriptions on VSURF can be found in Genuer, R., Poggi, J.-M., Tuleau-Malot, C., 2015. VSURF: an r package for VariableSelection using random forests. R J. R Found. Statist. Comput. 7 (2), 19\u201333. Be aware that I set the option parallel to TRUE and ncores = 3. This means in this case, R will use 3 CPUs/cores to run the algorithm. In case your computer only has one core/CPU, you have to set parallel to FALSE. If you do not know how many cores your computer has, you can also try to run the code and if it fails, you can reduce the number of cores or deactivate the parallel setting.</p> <pre><code>vsurf_pca &lt;- VSURF(trainval_pca2, as.factor(treespec), ntree=500, parallel = T, ncores = 3)\n</code></pre> <p>The resulting vsurf_pca object contains three sets of selected variables. In the following we will focus on the predictor set optimized for prediction (see Tutorial 2 of this module for more information). The column ids of this set of selected variables can be accessed with the command:</p> <pre><code>vsurf_pca$varselect.pred\n</code></pre> <p>If we run it, we can see the following output:</p> <p></p> <p>We can see that the first three PCs got selected but also some lower ranked PCs like 26 and 27.</p> <p>As next step, we will build a subset of our predictor feature space currently containing 30 PCs to a new dataframe containing only the 11 PCs selected by VSURF. For this we run:</p> <pre><code>trainval_vsurf &lt;- trainval_pca2[,vsurf_pca$varselect.pred]\n</code></pre> <p>These predictors are then used in the SVM classification workflow as we already know it from STEP 2 and 3:</p> <pre><code># run parameter tuning\nset.seed(1173)\ngammat = seq(.1, .9, by = .1)\ncostt = seq(1,128, by = 12)\ntune3 &lt;- tune.svm(trainval_vsurf, as.factor(treespec), gamma = gammat, cost=costt)\nplot(tune3)\n\n# take best parameters\ngamma3 &lt;- tune3$best.parameters$gamma\ncost3 &lt;- tune3$best.parameters$cost\n\n\n# train the model with all available samples\nmodel_vsurf &lt;- svm(trainval_vsurf, as.factor(treespec), gamma = gamma3, cost = cost3, probability = TRUE)\n# train model with 5-fold cross-validation to get first impression on accuracies\nmodel_vsurf2 &lt;- svm(trainval_vsurf, as.factor(treespec), gamma = gamma3, cost = cost3, probability = TRUE, cross=10)\nsummary(model_vsurf2)\n</code></pre> <p>This will result in the following output:</p> <p></p> <p>As we can see, we could increase the classification accuracy by almost 10% with this additional feature selection step. This is quite a lot! As last step, we can now also produce the corresponding classification map by running:</p> <pre><code># set output directory to save classification map\nsetwd(\"D:/1_tree_species_Karlsruhe/2_data/results\")\n# apply classifier to full image\nsvmPred_vsurf &lt;- predict(pca_ras2[[vsurf_pca$varselect.pred]], model_vsurf, filename=\"tree_spec_map_vsurf.tif\", na.rm=TRUE, progress='text', format='GTiff', datatype='INT1U',overwrite=TRUE)\n</code></pre> <p>And plot the map by running:</p> <pre><code>dev.off()\nplot(svmPred_vsurf)\nlegend(\"topright\", legend=c(\"1 = Quercus robur\", \"2 = Pinus sylvestris\", \"3 = Quercus rubra\", \"4 = Fagus sylvatica\", \"5 = Pseudotsuga menz.\"))\n</code></pre> <p>Which will result in the following map:</p> <p></p> <p>We have now created three tree species maps using our hyperspectral image and the reference data. Feel free to have a closer look at the maps and think about how they differ and which one is agreeing best with the reference maps as well as with the visual impression when comparing the maps with high-resolution Google and Bing images in QGIS.</p>"},{"location":"treespeciesclassification/treespeciesclassification/#exercise","title":"Exercise","text":"<p>If you want to practice a bit more with the code, try to run another classification applying the VSURF variable selection to the original 125 bands of HyMap. How does this affect the classification accuracy?</p>"}]}